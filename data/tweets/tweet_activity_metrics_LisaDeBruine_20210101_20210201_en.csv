"Tweet id","Tweet permalink","Tweet text","time","impressions","engagements","engagement rate","retweets","replies","likes","user profile clicks","url clicks","hashtag clicks","detail expands","permalink clicks","app opens","app installs","follows","email tweet","dial phone","media views","media engagements","promoted impressions","promoted engagements","promoted engagement rate","promoted retweets","promoted replies","promoted likes","promoted user profile clicks","promoted url clicks","promoted hashtag clicks","promoted detail expands","promoted permalink clicks","promoted app opens","promoted app installs","promoted follows","promoted email tweet","promoted dial phone","promoted media views","promoted media engagements"
"1355500244381949952","https://twitter.com/LisaDeBruine/status/1355500244381949952","@page_eco I‚Äôm really interested in why it wasn‚Äôt immediately obvious to absolutely everyone that people travelling with children would have to be an exception to the window to aisles pattern.","2021-01-30 12:56 +0000","215.0","4.0","0.018604651162790697","0.0","1.0","1.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355498871959515139","https://twitter.com/LisaDeBruine/status/1355498871959515139","@VerbingNouns @AbstractCat I did get me looking at yarns again and now I desperately want to buy some of the blue/purple/pink mixes, but I‚Äôve only just started my first lace knitting project and at the rate I‚Äôm going, I won‚Äôt be finished for years.","2021-01-30 12:51 +0000","80.0","2.0","0.025","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355498083199688706","https://twitter.com/LisaDeBruine/status/1355498083199688706","@VerbingNouns @AbstractCat Haha, my reading comprehension is terrible this morning :) No bowls, just yarn.","2021-01-30 12:48 +0000","59.0","3.0","0.05084745762711865","0.0","1.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355495917454036994","https://twitter.com/LisaDeBruine/status/1355495917454036994","@VerbingNouns I‚Äôve loved every yarn I‚Äôve bought from @AbstractCat (I favour the shiny superwash merino, but they have a variety)

https://t.co/wCQpCeFNQw https://t.co/7hatHKjR4f","2021-01-30 12:39 +0000","592.0","45.0","0.07601351351351351","0.0","1.0","1.0","2.0","3.0","0.0","2.0","0.0","0","0","0","0","0","36","36","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355494815165771783","https://twitter.com/LisaDeBruine/status/1355494815165771783","@paul_msg @MaartenvSmeden @ingorohlfing @Sam_D_Parsons @LeonidTiokhin @ERC_Research @wellcometrust OMG! How can more than a *tiny* percentage of people have ‚Äúbest in conference‚Äù papers? Especially for ECRs, who probably had funding for 1-2 conferences a year during PhD/postdoc years. And massively biased against those who can‚Äôt travel b/c caring, health, or citizenship.","2021-01-30 12:35 +0000","90.0","11.0","0.12222222222222222","0.0","1.0","2.0","0.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355492440162054145","https://twitter.com/LisaDeBruine/status/1355492440162054145","@MaartenvSmeden @ingorohlfing @Sam_D_Parsons @LeonidTiokhin @ERC_Research @wellcometrust Ugh. That‚Äôs terrible. I know panelists are often asked to judge research they can‚Äôt understand without years of study, but that still doesn‚Äôt make them useful or fair. I wonder what other biases crop up when people judge papers outside of their expertise solely by reading them?","2021-01-30 12:25 +0000","215.0","2.0","0.009302325581395349","0.0","0.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355489829744685061","https://twitter.com/LisaDeBruine/status/1355489829744685061","@MaartenvSmeden @ingorohlfing @Sam_D_Parsons @LeonidTiokhin Government and charity funders could help solve this by mandating that papers funded by their grants are published only on their own open-access platforms. Who would turn down @ERC_Research or @wellcometrust funding for a chance at a Nature paper?","2021-01-30 12:15 +0000","292.0","7.0","0.023972602739726026","0.0","1.0","4.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355476186797920259","https://twitter.com/LisaDeBruine/status/1355476186797920259","@MaartenvSmeden @ingorohlfing @Sam_D_Parsons I don‚Äôt understand why this myth persists that prestige journals have better peer review. @LeonidTiokhin explains in this piece how they had to hire someone to do code review because the reviewers at NHB never bothered (for a computational model paper!)

https://t.co/v3wB26R0Bw","2021-01-30 11:21 +0000","1314.0","74.0","0.0563165905631659","3.0","2.0","12.0","4.0","15.0","0.0","38.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355314796292399105","https://twitter.com/LisaDeBruine/status/1355314796292399105","@ingorohlfing @Sam_D_Parsons The Redditors took advantage of a vulnerability in the system; they didn‚Äôt just boycott stock trading. Maybe a smallish number of academics could do something similar by manipulating the metrics big journals use to evidence their value. But there would be collateral damage.","2021-01-30 00:40 +0000","398.0","15.0","0.03768844221105527","0.0","2.0","4.0","3.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355235907473993728","https://twitter.com/LisaDeBruine/status/1355235907473993728","‚ÄúA game of multiplayer spreadsheets‚Äù ü§£ 

(I love how straightforwardly @marcusdipaola explains the news and think it‚Äôs really valuable even if you aren‚Äôt his target audience of middle schoolers with learning disabilities)

https://t.co/nIDdZS3KKW","2021-01-29 19:26 +0000","1532.0","14.0","0.009138381201044387","0.0","0.0","3.0","0.0","6.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355066349110910982","https://twitter.com/LisaDeBruine/status/1355066349110910982","@AdamGruer @cantabile Seems like an AI trash fire. 
Just checked mine and they describe my most popular R package as an HTML project (because of the docs?) and correctly identify webmorph as my most forked project, which is written in PHP, which they say I have no expertise in.","2021-01-29 08:12 +0000","213.0","7.0","0.03286384976525822","0.0","1.0","2.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1355061776665219072","https://twitter.com/LisaDeBruine/status/1355061776665219072","@zerdeve That film is gorgeous.","2021-01-29 07:54 +0000","744.0","7.0","0.009408602150537635","0.0","1.0","2.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354762938163326978","https://twitter.com/LisaDeBruine/status/1354762938163326978","@LewisLawGroup @BeatSaber I love no fail in multi! Almost everyone leaves a game if they fail before the last few seconds otherwise.","2021-01-28 12:07 +0000","139.0","1.0","0.007194244604316547","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354702517582626817","https://twitter.com/LisaDeBruine/status/1354702517582626817","@EveForster https://t.co/lAL9m81wt3","2021-01-28 08:07 +0000","629.0","88.0","0.13990461049284578","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","85","85","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354200439986806786","https://twitter.com/LisaDeBruine/status/1354200439986806786","@bechhof If you have high enough data point density to need them, they‚Äôre better than massive overplotting.","2021-01-26 22:51 +0000","173.0","2.0","0.011560693641618497","0.0","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354199250649964545","https://twitter.com/LisaDeBruine/status/1354199250649964545","(And yes, I am also worried that people might use my simulation code to perpetuate more sophisticated fraud than this one. I still think the benefits of helping researchers simulate data for legit reasons outweighs that cost.)","2021-01-26 22:47 +0000","1727.0","51.0","0.029530978575564564","0.0","1.0","9.0","5.0","0.0","0.0","36.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354198240296656897","https://twitter.com/LisaDeBruine/status/1354198240296656897","And by ‚Äúthis‚Äù, I don‚Äôt (just) mean fraud. A student today realised after plotting her data that there was an impossible value on a scale, which uncovered a subtle problem in the score-calculating code.","2021-01-26 22:43 +0000","1836.0","43.0","0.023420479302832243","0.0","2.0","17.0","1.0","0.0","0.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354196568354811906","https://twitter.com/LisaDeBruine/status/1354196568354811906","This is why we need to normalise plots that include data points, not just summary stats and trend lines. https://t.co/XarqAJ7mEI","2021-01-26 22:36 +0000","12901.0","386.0","0.029920161227811798","11.0","2.0","79.0","18.0","0.0","0.0","276.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354122097942024193","https://twitter.com/LisaDeBruine/status/1354122097942024193","@ed_hagen I‚Äôve run into that one before! Totally maddening when I‚Äôm trying to convert code originally written in another language that doesn‚Äôt do that.","2021-01-26 17:40 +0000","160.0","3.0","0.01875","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354085399463927809","https://twitter.com/LisaDeBruine/status/1354085399463927809","@sharoz @bmwiernik I ‚ù§Ô∏è tidyverse for my own analysis code and for teaching, but for package development I just end up with too many dependencies (and I still haven‚Äôt fully wrapped my head around quosures).

It‚Äôs something I need to take a week to tackle someday.","2021-01-26 15:14 +0000","244.0","9.0","0.036885245901639344","0.0","1.0","4.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354083697679605766","https://twitter.com/LisaDeBruine/status/1354083697679605766","@fiona_jordan Sounds like Mrs. Engle should be a coauthor on all this or share half the PhD!","2021-01-26 15:08 +0000","470.0","12.0","0.02553191489361702","0.0","1.0","4.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354078393378234378","https://twitter.com/LisaDeBruine/status/1354078393378234378","@IvanZ_1900 Yup! You just need to trim the results after or they'll keep the whitespace:

df %&gt;%
  separate_rows(fav2, sep = "","") %&gt;%
  separate_rows(fav2, sep = ""and"") %&gt;%
  mutate(fav2 = trimws(fav2))","2021-01-26 14:47 +0000","37.0","6.0","0.16216216216216217","0.0","0.0","0.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354035382392913921","https://twitter.com/LisaDeBruine/status/1354035382392913921","@john_t_ormerod I love purrr, but I'm trying to avoid too much tidyverse in this package. I'm currently totally rewriting it because a bunch of things broke since the last big tidyverse updates (and it was one of my first packages and just sucks).","2021-01-26 11:56 +0000","65.0","4.0","0.06153846153846154","0.0","0.0","2.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354034843827527680","https://twitter.com/LisaDeBruine/status/1354034843827527680","@AchimZeileis Thank you for the reminder! I swear I wrote a detailed tweet recently about why df[[1, 1]] isn't a thing and I should have remembered this. https://t.co/6t3TZ7EA0E","2021-01-26 11:53 +0000","137.0","3.0","0.021897810218978103","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","38","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354034067667382273","https://twitter.com/LisaDeBruine/status/1354034067667382273","@john_t_ormerod The actual code needs to pull unique values from a column that the user specified by name or index, then iterate over the values to filter all matching rows from that table and knit an Rmd using those values. 

But I Iove seq_along for vectors that might be 0 length.","2021-01-26 11:50 +0000","105.0","5.0","0.047619047619047616","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354031898058776576","https://twitter.com/LisaDeBruine/status/1354031898058776576","So this code works totally differently if the user has a data frame or a tibble:

for (x in tb[, 1]) {
  print(x) # iterates once
}

for (x in df[, 1]) {
  print(x) # iterates 6 times
}

Is there an ideal pattern for dealing with this type of issue?","2021-01-26 11:42 +0000","2481.0","50.0","0.02015316404675534","0.0","7.0","3.0","2.0","0.0","0.0","38.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1354031896162930693","https://twitter.com/LisaDeBruine/status/1354031896162930693","Today's #rstats (and #tidyverse) frustration: I spent an hour debugging a function because I forgot that bracket notation results in different data types for data.frames versus tibbles:

df &lt;- data.frame(a = 1:6)
tb &lt;- tibble(a = 1:6)

df[ ,1] # vector
tb[ ,1] # data frame","2021-01-26 11:42 +0000","5241.0","131.0","0.024995229917954588","3.0","2.0","19.0","2.0","0.0","2.0","103.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353979135606075393","https://twitter.com/LisaDeBruine/status/1353979135606075393","@micahgallen They‚Äôd better, or I‚Äôm not turning up dressed to any meeting today. (I got new sweatpants yesterday, my first new clothes in over a year, and I‚Äôm so excited!)","2021-01-26 08:12 +0000","775.0","10.0","0.012903225806451613","0.0","0.0","6.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353976084879056897","https://twitter.com/LisaDeBruine/status/1353976084879056897","Why is it when I wake up at 3am (because a fox was screaming outside my window) it takes more than an hour to get back to sleep, but when my alarm goes off in the morning, I can fall fast asleep and have a fully formed dream in the 9 minutes between snooze alarms?","2021-01-26 08:00 +0000","11576.0","486.0","0.04198341395991707","3.0","4.0","89.0","36.0","0.0","0.0","354.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353856765885079553","https://twitter.com/LisaDeBruine/status/1353856765885079553","@hadleywickham Thanks! It‚Äôs usually the case that there‚Äôs a tidyverse function that does what I want, the trick is finding them all! I‚Äôm trying not to code after midnight, though, so I‚Äôll have a look at that tomorrow. https://t.co/IHUA7HUFdw","2021-01-26 00:06 +0000","567.0","20.0","0.03527336860670194","0.0","0.0","2.0","3.0","0.0","0.0","7.0","0.0","0","0","0","0","0","228","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353851004849184770","https://twitter.com/LisaDeBruine/status/1353851004849184770","@jeffreymgirard I prefer this when I have no idea how many items people might put in their list. Otherwise I have to deal with extra and fill arguments to separate, and then gather/pivot_longer and filter out NAs.","2021-01-25 23:43 +0000","219.0","3.0","0.0136986301369863","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353850417004867586","https://twitter.com/LisaDeBruine/status/1353850417004867586","I think students hate this when they ask me a specific question about their data and I respond by giving them a toy data set and the solution for that (the example I actually sent had a *lot* more comments). But I hope it's effective pedagogy.","2021-01-25 23:41 +0000","1322.0","14.0","0.01059001512859304","0.0","0.0","3.0","1.0","0.0","0.0","9.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353849480811081728","https://twitter.com/LisaDeBruine/status/1353849480811081728","Quick #rstats example from a student question tonight about how to deal with columns with multiple answers:

df = data.frame(
  id = 1:2,
  fav = c(""red, green"", ""black and grey"")
)

# split on comma or ""and""
df$fav2 = strsplit(df$fav, ' *(,|and) *')

tidyr::unnest(df, fav2) https://t.co/oJAQbt83M8","2021-01-25 23:37 +0000","12051.0","756.0","0.06273338312173264","3.0","4.0","28.0","25.0","1.0","2.0","158.0","0.0","0","0","0","0","0","535","535","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353414185716244480","https://twitter.com/LisaDeBruine/status/1353414185716244480","@micahgallen @chrisdc77 Or get an oculus and take up beat saber. It‚Äôs a pretty compelling alternative to cardio. https://t.co/6bYlHpe7OT","2021-01-24 18:47 +0000","176.0","3.0","0.017045454545454544","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","51","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1353277985080680451","https://twitter.com/LisaDeBruine/status/1353277985080680451","@SueReviews I re-dye mine at home every 2-4 weeks. I tend to use manic panic. I quite like a variegated look, but if you want it solid use a similar but darker colour (purple on top of pink is perfect).","2021-01-24 09:46 +0000","690.0","23.0","0.03333333333333333","0.0","1.0","1.0","14.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352997282321473537","https://twitter.com/LisaDeBruine/status/1352997282321473537","@hansijzerman @ravenscimaven That‚Äôs why I tagged you!","2021-01-23 15:11 +0000","155.0","2.0","0.012903225806451613","0.0","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352997158757289984","https://twitter.com/LisaDeBruine/status/1352997158757289984","@hansijzerman @ravenscimaven Cool! Do you address any of this in your new book?","2021-01-23 15:10 +0000","121.0","3.0","0.024793388429752067","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352995191322501120","https://twitter.com/LisaDeBruine/status/1352995191322501120","@ravenscimaven Paging @hansijzerman: are there regional differences in thermoregulation? Do they have any genetic components or mainly development in response to the environment and/or cultural?","2021-01-23 15:02 +0000","762.0","15.0","0.01968503937007874","0.0","1.0","2.0","3.0","0.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352973333919358979","https://twitter.com/LisaDeBruine/status/1352973333919358979","@westwoodsam1 @LilyBaileyUK https://t.co/MG2fCNSIgW","2021-01-23 13:35 +0000","217.0","31.0","0.14285714285714285","0.0","0.0","3.0","0.0","28.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352960825573699584","https://twitter.com/LisaDeBruine/status/1352960825573699584","@FlamIainGo Good luck! I did c25k a decade ago, thinking I was a person who could *never* be a runner. I‚Äôve not kept it up regularly (I enjoy cycling more), but now I know I can take up running again whenever I want. (The first few are hard, but you‚Äôll be amazed at the speed of improvement.)","2021-01-23 12:46 +0000","33.0","3.0","0.09090909090909091","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352908234693214208","https://twitter.com/LisaDeBruine/status/1352908234693214208","@westwoodsam1 @LilyBaileyUK Somebody sent me the Bernie mittens knitting pattern last night!","2021-01-23 09:17 +0000","5775.0","28.0","0.0048484848484848485","0.0","1.0","10.0","13.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352625682124312578","https://twitter.com/LisaDeBruine/status/1352625682124312578","@djnavarro I didn‚Äôt see your session in the list! So sorry I missed it.","2021-01-22 14:34 +0000","866.0","2.0","0.0023094688221709007","0.0","0.0","0.0","2.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352625359406170115","https://twitter.com/LisaDeBruine/status/1352625359406170115","So excited to try out the bindCache() function for #rstats #shiny apps presented by @winston_chang at #rstudioglobal 

You can cache data or images within or across sessions! This will make some of my apps *so* much faster  üí´","2021-01-22 14:33 +0000","3072.0","24.0","0.0078125","4.0","0.0","4.0","8.0","0.0","2.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352588282509611008","https://twitter.com/LisaDeBruine/status/1352588282509611008","@bmwiernik Multilingual captions are so great! I love being able to see speakers present in their most comfortable language.

The 12-hour repeating schedule made it easy to fit this into my life.

Spatial chat was actually pretty fun. It's kind of like gathertown without the 8-bit graphics.","2021-01-22 12:05 +0000","6800.0","37.0","0.005441176470588235","1.0","1.0","12.0","1.0","0.0","0.0","22.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352556274798493696","https://twitter.com/LisaDeBruine/status/1352556274798493696","@DrGBuckingham @PsychScientists @Matt_Craddock @emilynordmann just got one, too. I have an original Quest and my son has the Quest2 (at his dad's house).","2021-01-22 09:58 +0000","295.0","2.0","0.006779661016949152","0.0","1.0","0.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352531440995590144","https://twitter.com/LisaDeBruine/status/1352531440995590144","@DrVeronikaCH @djnavarro I can‚Äôt make any more time commitments, but these materials might be of interest. They were developed for a workshop on teaching mixed models in Julia to a group of R users. I wrote my simulation tutorial after learning Julia for a week. 

https://t.co/ELShA0NjDj","2021-01-22 08:19 +0000","1121.0","37.0","0.03300624442462088","1.0","1.0","3.0","1.0","10.0","0.0","21.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352528219954679808","https://twitter.com/LisaDeBruine/status/1352528219954679808","@icymi_r @dalejbarr @JackEdTaylor This was part of the @SocSciScotland @beautiful_hack workshop to introduce coding to social science and humanities postgrads, led by @UofGPsychology postgrads @JackEdTaylor @_R_Lai_ @menimagerie @CarolynBot @eolasinntinn @ShannonMcNee2 @AnnaHenschel 

https://t.co/aCXid84Mtd https://t.co/9xAu5uJBOR","2021-01-22 08:07 +0000","1180.0","52.0","0.04406779661016949","3.0","0.0","9.0","7.0","6.0","0.0","13.0","0.0","0","0","0","0","0","14","14","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352408708349890563","https://twitter.com/LisaDeBruine/status/1352408708349890563","@ChelseaParlett üòÜ I‚Äôm pretty sure my students are sick of hearing ‚ÄúLet‚Äôs simulate it and find out!‚Äù whenever they ask me a question.","2021-01-22 00:12 +0000","1016.0","14.0","0.013779527559055118","0.0","1.0","4.0","6.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352405589364772867","https://twitter.com/LisaDeBruine/status/1352405589364772867","@hspter I sometimes feel like a fraud writing tutorials right after a concept has finally clicked for me, but you‚Äôve articulated exactly why those are often my most useful ones.","2021-01-21 23:59 +0000","568.0","9.0","0.01584507042253521","1.0","1.0","2.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352400689180385280","https://twitter.com/LisaDeBruine/status/1352400689180385280","@richard_vogg Great talk! I missed the blog URL and can‚Äôt find it with a web search.","2021-01-21 23:40 +0000","348.0","10.0","0.028735632183908046","0.0","2.0","2.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352396751068655622","https://twitter.com/LisaDeBruine/status/1352396751068655622","Excited for @ChelseaParlett‚Äôs #rstudioglobal lightning talk on Using Guided Simulation Exercises to Teach Data Science with R https://t.co/cbNXLGx6yD","2021-01-21 23:24 +0000","3488.0","45.0","0.012901376146788992","1.0","1.0","9.0","3.0","0.0","2.0","20.0","0.0","0","0","0","0","0","547","9","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352393145535885318","https://twitter.com/LisaDeBruine/status/1352393145535885318","Another great talk at #rstudioglobal by @minebocek 

The gradethis package is now also on my list to learn. I love how the code scaffolding works. 

https://t.co/86FsMwyS7o","2021-01-21 23:10 +0000","1327.0","23.0","0.01733232856066315","0.0","0.0","5.0","2.0","8.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352386667588558850","https://twitter.com/LisaDeBruine/status/1352386667588558850","I‚Äôm really excited to play with learnr after @yabellini‚Äôs fantastic talk!

I also learned about @metadocencia, which has Spanish R resources.

https://t.co/VnNVzvEiO6

I ‚ù§Ô∏è that the talks at #rstudioglobal are multilingual and you can get English, Spanish or Chinese subtitles!","2021-01-21 22:44 +0000","2967.0","60.0","0.020222446916076844","5.0","1.0","24.0","16.0","4.0","2.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352338561689931783","https://twitter.com/LisaDeBruine/status/1352338561689931783","I also want to argue against tick-box solutions like mandatory preregistration or unevaluated badges. I‚Äôd be keen to know what people see as the priorities for an open science committee that can have influence on APA journal policy.","2021-01-21 19:33 +0000","1876.0","24.0","0.01279317697228145","0.0","2.0","11.0","2.0","0.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352338560142221314","https://twitter.com/LisaDeBruine/status/1352338560142221314","I‚Äôm excited to join this committee! I‚Äôd like to help make citing research software easier and more common, remove barriers for ECRs, and help put in place systems for letting researchers share all aspects of their work in accessible and interoperable ways. https://t.co/JYrcJL14te","2021-01-21 19:33 +0000","5530.0","83.0","0.015009041591320072","2.0","1.0","44.0","8.0","0.0","0.0","28.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352332304312623109","https://twitter.com/LisaDeBruine/status/1352332304312623109","@JamesEBartlett @dalejbarr I didn‚Äôt know that one either! I may end up revising some of the code in faux::unique_pairs() (which lists all the unique pairings of a vector).","2021-01-21 19:08 +0000","434.0","4.0","0.009216589861751152","0.0","1.0","2.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352316029016354819","https://twitter.com/LisaDeBruine/status/1352316029016354819","@OtherFoovian @jarrenls To be clear, I didn‚Äôt overhaul the curriculum, I just posted the link! It was a big team effort involving @dalejbarr @clelandwoods @emilynordmann @McAleerP @PatersonHelena @Eavanmac @pimpmymemory and others","2021-01-21 18:04 +0000","120.0","11.0","0.09166666666666666","0.0","1.0","5.0","0.0","1.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352298199252414467","https://twitter.com/LisaDeBruine/status/1352298199252414467","TIL about the interesting concept of off-label function use from @hadleywickham at #rstudioglobal

I caught a ridiculous example of this in my {faux} code the other day: I'd used as.vector(as.matrix(x)) just to remove the names from a vector x!","2021-01-21 16:53 +0000","18524.0","209.0","0.011282660332541567","1.0","1.0","31.0","14.0","5.0","5.0","152.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352010756334743553","https://twitter.com/LisaDeBruine/status/1352010756334743553","@JamesEBartlett @JimGrange @seriousstats @xmjandrews I mainly recommend they read @dalejbarr‚Äôs book if they (almost inevitably) didn‚Äôt have a strong background in GLM from another institution. 

https://t.co/Z7FVMjyNBV","2021-01-20 21:50 +0000","1175.0","41.0","0.03489361702127659","1.0","1.0","5.0","2.0","23.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352010456437841927","https://twitter.com/LisaDeBruine/status/1352010456437841927","@JamesEBartlett @JimGrange @seriousstats @xmjandrews My MSc Data Skills course is also 10 weeks to get them up to speed in R and reproducible data processing, so they only get a single lecture on GLM. I‚Äôm thinking about moving it earlier and reinforcing it more in the data processing chapters.","2021-01-20 21:49 +0000","239.0","8.0","0.03347280334728033","0.0","2.0","3.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1352007151691116546","https://twitter.com/LisaDeBruine/status/1352007151691116546","@seriousstats @JimGrange @JamesEBartlett @xmjandrews I totally agree that GLM should be the basis of inferential stats teaching, but at some point you do have to teach them how to interpret the most common analyses in the literature so they aren‚Äôt baffled by t-tests and ANOVAs when reading.","2021-01-20 21:36 +0000","162.0","15.0","0.09259259259259259","0.0","1.0","4.0","2.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351945926777200643","https://twitter.com/LisaDeBruine/status/1351945926777200643","@tmurphEpi I've put a draft of the workshop on my blog and linked to the data so far (which I'll update periodically).

https://t.co/WxXpxlnrpd","2021-01-20 17:33 +0000","41.0","3.0","0.07317073170731707","0.0","0.0","1.0","0.0","2.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351945080660221954","https://twitter.com/LisaDeBruine/status/1351945080660221954","@RabiaAliKhan2 The zoom workshop is only for UofG students for now (I'd be open to doing a separate public one if people are interested). But the materials are linked below. I'll update that draft with anything that came up during the workshop that needs clarification.

https://t.co/WxXpxlnrpd","2021-01-20 17:29 +0000","33.0","4.0","0.12121212121212122","0.0","0.0","0.0","1.0","3.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351944572994252803","https://twitter.com/LisaDeBruine/status/1351944572994252803","Thanks to everyone who participated! The (pretty rough) draft materials for the workshop are on my blog now. Let me know if you find errors or have suggestions. I'll leave the experiment up indefinitely as a demo and add to the data files.

https://t.co/WxXpxlnrpd https://t.co/c7z1lsY1iS","2021-01-20 17:27 +0000","1579.0","10.0","0.006333122229259025","0.0","0.0","0.0","1.0","7.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351868218655309825","https://twitter.com/LisaDeBruine/status/1351868218655309825","@zortea_tiago Or converting to semi-wide (10 dv columns)

data_w10 &lt;- pivot_wider(
  data = data_l,
  names_from = B,
  values_from = dv
) https://t.co/muO0XT3u0X","2021-01-20 12:24 +0000","190.0","17.0","0.08947368421052632","0.0","1.0","1.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","11","11","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351863925659332610","https://twitter.com/LisaDeBruine/status/1351863925659332610","@asek47 @daph_ling This sort of finding always reminds me that pictures of faces are also not faces. They are objects that share almost all of the relevant visual features with faces. So it's unsurprising that you can create other objects that also share relevant properties.","2021-01-20 12:07 +0000","84.0","4.0","0.047619047619047616","0.0","0.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351858572427227138","https://twitter.com/LisaDeBruine/status/1351858572427227138","@tmurphEpi @MichelleAKline @_R_Lai_ Preprint: https://t.co/vK1lpxkgCw
Shiny app: https://t.co/izPxqzf50D","2021-01-20 11:46 +0000","51.0","7.0","0.13725490196078433","0.0","1.0","2.0","0.0","2.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351857757952094210","https://twitter.com/LisaDeBruine/status/1351857757952094210","@zortea_tiago Converting from long to wide (3/3)

data_w2 &lt;- pivot_wider(
  data = data_l,
  names_from = A:B,
  names_sep = ""."",
  values_from = dv
) https://t.co/uIhErvzT4D","2021-01-20 11:43 +0000","186.0","8.0","0.043010752688172046","0.0","1.0","1.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351857544571006976","https://twitter.com/LisaDeBruine/status/1351857544571006976","@zortea_tiago Converting from wide to long (2/3)

data_l &lt;- pivot_longer(
  data = data_w,
  cols = A1_B1:A10_B6,
  names_to = c(""A"", ""B""),
  names_sep = ""_"",
  values_to = ""dv""
) https://t.co/zjpmW3BjfM","2021-01-20 11:42 +0000","164.0","11.0","0.06707317073170732","0.0","1.0","3.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","2","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351857344972541954","https://twitter.com/LisaDeBruine/status/1351857344972541954","@zortea_tiago Here's a simple simulated example of a 10x6 within subject design (1/3)

data_w &lt;- faux::sim_design(within = c(10, 6)) https://t.co/RhBIqI8GAo","2021-01-20 11:41 +0000","147.0","9.0","0.061224489795918366","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","4","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351675975801647106","https://twitter.com/LisaDeBruine/status/1351675975801647106","@__iine_ You‚Äôre always free to not respond to a question (and non-response is one of the things the student is looking at).","2021-01-19 23:40 +0000","469.0","9.0","0.019189765458422176","0.0","1.0","3.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351654147788038152","https://twitter.com/LisaDeBruine/status/1351654147788038152","@zortea_tiago Does this help? https://t.co/NzFx9wVLKD

If not, I'd be curious to see your example. I like solving complex wrangling problems and it might be useful to others to blog about.","2021-01-19 22:13 +0000","459.0","21.0","0.0457516339869281","0.0","1.0","4.0","7.0","5.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351653502016217093","https://twitter.com/LisaDeBruine/status/1351653502016217093","@kirbyconrod https://t.co/J3bE9VDwkR","2021-01-19 22:11 +0000","711.0","17.0","0.02390998593530239","0.0","0.0","5.0","10.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351649437148442624","https://twitter.com/LisaDeBruine/status/1351649437148442624","@fiona_jordan I should do that for one of the demo analyses:

Do fiber arts enthusiasts have more positive attitudes towards spiders? https://t.co/FuZE2DyvlF","2021-01-19 21:55 +0000","250.0","8.0","0.032","0.0","1.0","6.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351646983799377930","https://twitter.com/LisaDeBruine/status/1351646983799377930","If you participated before 21:30 UK time on Tuesday, feel free to try again. I'd changed some website code so you didn't have to enter gender and age data at the start of a study (which is the normal default) and this caused guest IDs to not record so data were not saving. https://t.co/KKsiMP8ibF","2021-01-19 21:45 +0000","1579.0","23.0","0.014566181127295756","0.0","0.0","4.0","1.0","0.0","0.0","14.0","0.0","0","0","0","0","0","235","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351645918672678912","https://twitter.com/LisaDeBruine/status/1351645918672678912","If you have 1.3 minutes (the median completion time), please help my project student investigate what types of gender demographic questions are most inclusive and easiest to answer. They specifically need more non-binary and genderqueer respondents. 

https://t.co/4SjpFFhfj1 https://t.co/NFCoa0evAC","2021-01-19 21:41 +0000","76721.0","2608.0","0.033993300400151194","287.0","12.0","165.0","200.0","1064.0","0.0","746.0","0.0","0","0","0","0","0","9837","134","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351633547363233794","https://twitter.com/LisaDeBruine/status/1351633547363233794","@deborahapthorp It‚Äôs an open source data collection platform I started developing for my own lab 15 years ago and we use for student projects now at @UofGPsychology and also the first project from the @PsySciAcc 

https://t.co/gnBrWdMn91","2021-01-19 20:52 +0000","144.0","17.0","0.11805555555555555","0.0","0.0","2.0","1.0","2.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351603232540389381","https://twitter.com/LisaDeBruine/status/1351603232540389381","@BernieDogs4 @SiouxsieW Did you get the mood Q before or after the cute animals?","2021-01-19 18:51 +0000","83.0","2.0","0.024096385542168676","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351603088721915913","https://twitter.com/LisaDeBruine/status/1351603088721915913","@tmurphEpi @_R_Lai_ I‚Äôll probably also do a blog post featuring these data as prep for a paper on the advantages of machine-readable study descriptions (all experimentum study parameters are exportable in JSON format)","2021-01-19 18:51 +0000","126.0","2.0","0.015873015873015872","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351602692444082177","https://twitter.com/LisaDeBruine/status/1351602692444082177","@tmurphEpi After I do the workshop next week with our students (lots are using experimentum for their theses) @_R_Lai_ and I will update the experimentum manual with the top tips and link to the data files.","2021-01-19 18:49 +0000","337.0","15.0","0.04451038575667656","0.0","2.0","4.0","4.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351595779631276035","https://twitter.com/LisaDeBruine/status/1351595779631276035","@vizowl You prompted me to double-check how it‚Äôs working on a phone and the rating buttons keep the highlight between trials on the iPhone. I‚Äôve fixed it twice before, but looks like it‚Äôs time for another go! (web development is like trying to hit a moving target)","2021-01-19 18:21 +0000","295.0","2.0","0.006779661016949152","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351592827185197056","https://twitter.com/LisaDeBruine/status/1351592827185197056","@Suzyiam @SiouxsieW Same :) I was an avid crocheter before, but took up knitting during lockdown and got obsessed with brioche hats.","2021-01-19 18:10 +0000","20.0","1.0","0.05","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351591533208809481","https://twitter.com/LisaDeBruine/status/1351591533208809481","@Suzyiam @SiouxsieW I made that questionnaire while sitting on the couch next to my knitting box full of hats https://t.co/PkWBm5gSFh","2021-01-19 18:05 +0000","219.0","30.0","0.136986301369863","0.0","4.0","4.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","19","19","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351582626222628870","https://twitter.com/LisaDeBruine/status/1351582626222628870","I'm running a workshop next week on wrangling Experimentum data in #rstats with tidyverse. If anyone has 5 minutes to complete 2 short questionnaires and a silly experiment with some adorable animal photos, you can help us make a demo data set here:

https://t.co/YtFvKf8MBX https://t.co/SZqkSfT6Ql","2021-01-19 17:29 +0000","32398.0","975.0","0.030094450274708317","31.0","23.0","79.0","42.0","405.0","1.0","267.0","0.0","0","0","0","0","0","127","127","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1351130156354711557","https://twitter.com/LisaDeBruine/status/1351130156354711557","@charliejhadley Really loving Fight Club https://t.co/XH7ePiQI8H","2021-01-18 11:31 +0000","545.0","17.0","0.031192660550458717","0.0","1.0","2.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","169","7","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350991308463202312","https://twitter.com/LisaDeBruine/status/1350991308463202312","@jephjacques Thanks for the reminder. I unsubbed when sorting my finances after divorce, but things are back on track and your comics have consistently brought me joy for nearly two decades now.","2021-01-18 02:20 +0000","615.0","16.0","0.026016260162601626","0.0","0.0","6.0","7.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350795437620436995","https://twitter.com/LisaDeBruine/status/1350795437620436995","@dsquintana I guess that‚Äôs an efficient way for the reviewer to convey that they don‚Äôt have the expertise to assess the methods and so rely on flawed heuristics and their opinions should no longer be taken seriously ü§∑","2021-01-17 13:21 +0000","2834.0","83.0","0.02928722653493296","0.0","2.0","39.0","14.0","0.0","0.0","28.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350615469833785346","https://twitter.com/LisaDeBruine/status/1350615469833785346","@StuartJRitchie @DrGBuckingham Ah, that‚Äôs a meme I don‚Äôt know! I‚Äôm mainly on some combo of queer, fiber arts, sea shanty, data science tiktok.","2021-01-17 01:26 +0000","584.0","19.0","0.032534246575342464","0.0","1.0","5.0","0.0","0.0","0.0","13.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350614659053867016","https://twitter.com/LisaDeBruine/status/1350614659053867016","@DrGBuckingham It‚Äôs probably filmed at half speed then sped up. It‚Äôs easier to get the lip synch tight that way, but can cause the uncanny valley effect.","2021-01-17 01:23 +0000","719.0","3.0","0.004172461752433936","0.0","1.0","0.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350475034842771456","https://twitter.com/LisaDeBruine/status/1350475034842771456","It also needs to have clearer explanation of what sorts of studies do and don‚Äôt benefit from (analysis) preregistration. Unless politics has a stricter and narrower definition of ‚Äúexperimental‚Äù than psychology does. This won‚Äôt be trivial to articulate.","2021-01-16 16:08 +0000","1458.0","7.0","0.004801097393689987","0.0","0.0","2.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1350474250210172937","https://twitter.com/LisaDeBruine/status/1350474250210172937","Without *really* clear guidance on what components a useful preregistration needs to have, this policy will be somewhere between useless and harmful. https://t.co/eNZlG4ZhC7","2021-01-16 16:05 +0000","9521.0","188.0","0.019745825018380424","5.0","1.0","27.0","13.0","0.0","0.0","142.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349758121330298883","https://twitter.com/LisaDeBruine/status/1349758121330298883","@ukslim @innerspacegirl @looks_last Yup, those‚Äôll be the ‚Äúother non-desert things‚Äù ;)

(and now I really want some Yorkshire puddings)","2021-01-14 16:39 +0000","127.0","2.0","0.015748031496062992","0.0","0.0","0.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349755853348499459","https://twitter.com/LisaDeBruine/status/1349755853348499459","@innerspacegirl @looks_last They‚Äôre probably using the British sense of pudding, which is just another term for any desert (and some other non-desert things), not the creamy chocolate whip. https://t.co/91FCnnviOr","2021-01-14 16:30 +0000","3168.0","48.0","0.015151515151515152","0.0","3.0","4.0","2.0","0.0","0.0","16.0","0.0","0","0","0","0","0","850","23","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349739776333627397","https://twitter.com/LisaDeBruine/status/1349739776333627397","@thatjohn @rahaeli Try this one ü•¶ 

https://t.co/NkW3SUGZmK","2021-01-14 15:26 +0000","220.0","2.0","0.00909090909090909","0.0","0.0","0.0","0.0","1.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349737983243554817","https://twitter.com/LisaDeBruine/status/1349737983243554817","@_ColinFay I love R because of my dreams and I‚Äôm going on my own to get a new one. https://t.co/0t3O4KXPhQ","2021-01-14 15:19 +0000","762.0","18.0","0.023622047244094488","0.0","0.0","7.0","2.0","0.0","0.0","5.0","0.0","0","0","0","0","0","286","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349731190178156550","https://twitter.com/LisaDeBruine/status/1349731190178156550","It‚Äôs not my core area, and I‚Äôm so behind on reading, but I‚Äôm putting it on my reading list because I know these three authors will have produced something really thought provoking. https://t.co/ovqgSlefkO","2021-01-14 14:52 +0000","2948.0","19.0","0.006445047489823609","0.0","0.0","11.0","3.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349490227497365505","https://twitter.com/LisaDeBruine/status/1349490227497365505","@dh4gan https://t.co/T1BCHv36EW","2021-01-13 22:55 +0000","251.0","1.0","0.00398406374501992","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349472899112071168","https://twitter.com/LisaDeBruine/status/1349472899112071168","@djnavarro I feel like prereg increases in usefulness as data become more difficult to collect (so you can‚Äôt tweak and repeat) and predictions are less precise (like y increases with x, but little precision beyond that), but I can also convince myself of the opposite in some circumstances.","2021-01-13 21:46 +0000","935.0","9.0","0.009625668449197862","0.0","0.0","1.0","1.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349471917527470081","https://twitter.com/LisaDeBruine/status/1349471917527470081","@djnavarro What do you think is the best way to communicate and teach under what circumstances prereg improves research and under what circumstances it isn‚Äôt necessary (or even harmful)?","2021-01-13 21:42 +0000","1262.0","28.0","0.022187004754358162","0.0","1.0","4.0","0.0","0.0","0.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349370055444803590","https://twitter.com/LisaDeBruine/status/1349370055444803590","@TheRealHoarse This one is amazing, too 

https://t.co/ZahK3NvkOa","2021-01-13 14:57 +0000","7649.0","124.0","0.016211269446986535","12.0","0.0","79.0","4.0","15.0","0.0","14.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349364734605352961","https://twitter.com/LisaDeBruine/status/1349364734605352961","@tjmahr That's pretty much how all my packages start :)","2021-01-13 14:36 +0000","442.0","10.0","0.02262443438914027","0.0","1.0","2.0","2.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349127785864957954","https://twitter.com/LisaDeBruine/status/1349127785864957954","@ravenscimaven This company is a good model @genderfreeworld 

https://t.co/5dIxny0nTa","2021-01-12 22:55 +0000","5104.0","1502.0","0.29427899686520376","2.0","6.0","147.0","49.0","1253.0","0.0","45.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349111064416448513","https://twitter.com/LisaDeBruine/status/1349111064416448513","@Liz_Pinney @AhuitzRojas My course also has a YouTube channel with a short video for each main learning outcome for each chapter. 

https://t.co/0Ey6nqQFt3","2021-01-12 21:48 +0000","314.0","16.0","0.050955414012738856","0.0","0.0","4.0","2.0","10.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349110900209422341","https://twitter.com/LisaDeBruine/status/1349110900209422341","@Liz_Pinney @AhuitzRojas There are several open source course books for teaching R to psych undergrads and masters students at https://t.co/FTajzu4LNb","2021-01-12 21:47 +0000","787.0","24.0","0.030495552731893267","0.0","2.0","3.0","2.0","13.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349094554490826755","https://twitter.com/LisaDeBruine/status/1349094554490826755","@russpoldrack So if I run all code blocks in order, then change the colours in a block that makes a plot and rerun just that one, does that count as out-of-order? I feel like I‚Äôd do this all the time. I‚Äôm glad I stuck to teaching Rmd after RStudio introduced notebooks.","2021-01-12 20:43 +0000","412.0","3.0","0.007281553398058253","0.0","1.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349062245322551301","https://twitter.com/LisaDeBruine/status/1349062245322551301","@psforscher @davidrfeinberg @mcxfrank @PsySciAcc @hansijzerman The trick is making them mandatory enough that those of us who have supervised budgets can justify them, while voluntary enough that those who don‚Äôt have money can still participate without being second-class members.","2021-01-12 18:34 +0000","344.0","10.0","0.029069767441860465","0.0","0.0","7.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349052520988102665","https://twitter.com/LisaDeBruine/status/1349052520988102665","@lucakozma She stole my broccoli. 
ü•¶ 
Casserole recipe.","2021-01-12 17:55 +0000","75.0","3.0","0.04","0.0","0.0","3.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349029940189163522","https://twitter.com/LisaDeBruine/status/1349029940189163522","Then I have a script that reads the feedback YAML file, the marking spreadsheet, and a file of generic feedback text to make individual feedback forms. That way, if I want to make class-wide changes to feedback, I don't have to open 60 files.","2021-01-12 16:26 +0000","1443.0","3.0","0.002079002079002079","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349029938314301442","https://twitter.com/LisaDeBruine/status/1349029938314301442","FYI: I'm not normally a big fan of YAML, but it's much better than excel or csv for lareg amounts of text. (I learned this from @babeheim.) I'm writing bullet points on each learning outcome for each student, then a paragraph of individual feedback.","2021-01-12 16:26 +0000","2182.0","18.0","0.008249312557286892","1.0","1.0","0.0","4.0","0.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349029936561057798","https://twitter.com/LisaDeBruine/status/1349029936561057798","Why can't we have text wrap in @rstudio for files that aren't .R? I'm using a combination of YAML and Rmd to mark #rstats projects and want to do them all in one IDE, but have to pretend the .yml file is .R so I can wrap my feedback paragraphs.","2021-01-12 16:26 +0000","2168.0","33.0","0.01522140221402214","1.0","1.0","3.0","2.0","0.0","1.0","25.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349006995400093701","https://twitter.com/LisaDeBruine/status/1349006995400093701","@melissaekline @RogertheGS I‚Äôve been thinking about his a lot recently in the context of this thread. What demographic info do we need (for a given topic) and how should it be collected and coded for maximum participant protection and scientific generalisability? https://t.co/CMT3S1k4js","2021-01-12 14:55 +0000","219.0","3.0","0.0136986301369863","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349002370215268357","https://twitter.com/LisaDeBruine/status/1349002370215268357","@RogertheGS @melissaekline It sounds like this is a question ripe for convening a multi-national panel to sort out best practice recommendations. Do other disciplines like sociology already have such a thing? It would be so useful for data aggregation (w/in appropriate region) and stop everyone reinventing","2021-01-12 14:36 +0000","240.0","19.0","0.07916666666666666","0.0","1.0","4.0","0.0","0.0","0.0","14.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1349000667235540993","https://twitter.com/LisaDeBruine/status/1349000667235540993","@VerbingNouns ‚ÄúThsnks‚Äù","2021-01-12 14:29 +0000","85.0","3.0","0.03529411764705882","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348999462568472582","https://twitter.com/LisaDeBruine/status/1348999462568472582","Does anyone else‚Äôs brain just suddenly start singing ‚Äúshe a Chriestn lay-day‚Äù lately?","2021-01-12 14:25 +0000","2646.0","69.0","0.026077097505668934","0.0","3.0","8.0","7.0","0.0","0.0","51.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348779142553235458","https://twitter.com/LisaDeBruine/status/1348779142553235458","@djnavarro Wow, these are gorgeous. I like how you use colour.","2021-01-11 23:49 +0000","1066.0","6.0","0.005628517823639775","0.0","1.0","2.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348431058312769537","https://twitter.com/LisaDeBruine/status/1348431058312769537","@GirlFromOttawa @FLITTER I had totally forgotten about those from the baby showers I attended in my youth! I can almost taste the white bread and cream cheese.","2021-01-11 00:46 +0000","447.0","4.0","0.008948545861297539","0.0","0.0","0.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348344513954246658","https://twitter.com/LisaDeBruine/status/1348344513954246658","@dnameis_paone I could never get bookdown to make a PDF version. You can get a local html copy of the book either by downloading the files from GitHub or installing the R package and using the book() function.

devtools::install_github(""psyteachr/msc-data-skills"")","2021-01-10 19:02 +0000","167.0","7.0","0.041916167664670656","1.0","1.0","0.0","2.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348301241445724162","https://twitter.com/LisaDeBruine/status/1348301241445724162","@Lisaa1000morea I often hear of researchers being asked to *justify* samples that aren‚Äôt just western undergrads. If you‚Äôd want justification for a sample that is all South Asian, or all lesbian, or all non-binary, or all 60+, then you should collect and report those demographics for any sample.","2021-01-10 16:10 +0000","148.0","4.0","0.02702702702702703","0.0","0.0","0.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348300060040294400","https://twitter.com/LisaDeBruine/status/1348300060040294400","@Lisaa1000morea Much of my research is on social perception, specifically mate choice, so gender, age and sexual orientation are obviously pretty important. We‚Äôve also found regional heterogeneity, although the underlying cause isn‚Äôt clear.","2021-01-10 16:05 +0000","109.0","4.0","0.03669724770642202","0.0","1.0","0.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348299584670412802","https://twitter.com/LisaDeBruine/status/1348299584670412802","@Lisaa1000morea My argument is that it‚Äôs hard/slow to determine if there are limits to generalisability if you never collect demographic data and pretend like your sample is representative of all humans (which it almost certainly isn‚Äôt).","2021-01-10 16:04 +0000","59.0","1.0","0.01694915254237288","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348254057241182208","https://twitter.com/LisaDeBruine/status/1348254057241182208","@eolasinntinn I‚Äôm allergic to pets, so have a baby Yoda instead. He‚Äôs wearing the hat I made for my boyfriend for Xmas (which turned out to be *way* too small for him, but perfect for Grogu) https://t.co/NwLoUdvdux","2021-01-10 13:03 +0000","1327.0","341.0","0.2569706103993971","0.0","1.0","13.0","20.0","0.0","0.0","8.0","0.0","0","0","0","0","0","299","299","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348243369311539207","https://twitter.com/LisaDeBruine/status/1348243369311539207","@Lisaa1000morea I don‚Äôt think there are many psych areas where we are so certain there are zero age/gender/ethnicity/language/SES/education differences that there is no point collecting these data. Which variables and how to code them should be decided field-by-field.","2021-01-10 12:20 +0000","84.0","7.0","0.08333333333333333","0.0","0.0","0.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348241240035385344","https://twitter.com/LisaDeBruine/status/1348241240035385344","@Lisaa1000morea Point 1 is fair, but regarding point 2, you can recode exact ages into bins, but not the other way around, making it hard to combine datasets with different binning schemes. Coordination of demographic coding schemes within a field could help.","2021-01-10 12:12 +0000","91.0","6.0","0.06593406593406594","0.0","1.0","0.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348239702843863041","https://twitter.com/LisaDeBruine/status/1348239702843863041","@VerbingNouns I‚Äôm on the iPhone app with the timeline set to latest (not top tweets). It seems to happen (sometimes) when someone replies to a tweet, which moves it to the top of the timeline.","2021-01-10 12:06 +0000","97.0","3.0","0.030927835051546393","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348212950528569344","https://twitter.com/LisaDeBruine/status/1348212950528569344","@McAleerP WTF? How many students does a primary school teacher have? 24+? In an 8-hour work day with no breaks, that‚Äôs less than 20 min per student to call them personally and mark their daily work, with no time left over for planning.","2021-01-10 10:19 +0000","903.0","25.0","0.02768549280177187","0.0","1.0","6.0","2.0","0.0","0.0","13.0","0.0","0","0","0","0","0","3","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1348207793849962500","https://twitter.com/LisaDeBruine/status/1348207793849962500","I wish I could swipe left and right on posts to add them to seen/unliked or seen/liked lists (that I can look at again if I want) and would removed from my timeline. I‚Äôm so sick of the TL suddenly reordering itself while I read it.","2021-01-10 09:59 +0000","4340.0","107.0","0.024654377880184333","0.0","4.0","31.0","4.0","0.0","0.0","68.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347887226714279936","https://twitter.com/LisaDeBruine/status/1347887226714279936","@PsychScientists @DrGBuckingham How are subject variables always between? I've changed age several times :)","2021-01-09 12:45 +0000","285.0","6.0","0.021052631578947368","0.0","1.0","5.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347886142432169984","https://twitter.com/LisaDeBruine/status/1347886142432169984","@DrGBuckingham Once you start thinking about mixed effects models, it's really hard to label designs like that anyways. I find it more useful to talk about what each variable is being repeated over (e.g., a condition can be within raters but between stimuli).","2021-01-09 12:41 +0000","611.0","7.0","0.011456628477905073","0.0","0.0","5.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347599445442105347","https://twitter.com/LisaDeBruine/status/1347599445442105347","@LabWelling @DarwinFeminist Not sure we ever described this as evidence for different ‚Äúneural mechanisms‚Äù, but I only skimmed the paper and totally take it back if we did.","2021-01-08 17:41 +0000","70.0","7.0","0.1","0.0","2.0","0.0","2.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347534886228422657","https://twitter.com/LisaDeBruine/status/1347534886228422657","@LewisChuang @dingding_peng @DrKeonWest ‚ÄúBalanced‚Äù is totally dependent on what gender categories you‚Äôre using. What does that mean in the case of non-binary participants? Should they be proportional to population or equal in numbers to men and women?","2021-01-08 13:25 +0000","79.0","5.0","0.06329113924050633","0.0","1.0","0.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347522672989757440","https://twitter.com/LisaDeBruine/status/1347522672989757440","@DrGBuckingham Lucky you. I didn‚Äôt get a substitution for cheddar at all this week (no cheese for me), but I did get hot chillies instead of padron peppers again! ü§¶‚Äç‚ôÄÔ∏è","2021-01-08 12:36 +0000","551.0","2.0","0.003629764065335753","0.0","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347521990740103169","https://twitter.com/LisaDeBruine/status/1347521990740103169","The replies to this are really interesting. There‚Äôs clearly a tension between protecting participant anonymity and having data to inform generalisability and allow datasets to be combined to study small subgroups.

What demographic data is totally necessary in your research? https://t.co/ZtRsm8Vwo3","2021-01-08 12:34 +0000","2453.0","51.0","0.02079086832450061","1.0","0.0","7.0","2.0","0.0","0.0","41.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347521308771422213","https://twitter.com/LisaDeBruine/status/1347521308771422213","@LewisChuang @dingding_peng @DrKeonWest There might be a good objection to freely sharing it if it makes people identifiable, but you can‚Äôt assert generalisability if you don‚Äôt have any data on what populations provided the results.","2021-01-08 12:31 +0000","65.0","3.0","0.046153846153846156","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347520913290502144","https://twitter.com/LisaDeBruine/status/1347520913290502144","@LewisChuang @dingding_peng @DrKeonWest It might be my sub-disciplinary bias, but I can‚Äôt think of many psych research questions where gender is *definitely* irrelevant. If you‚Äôd be upset to find that 100% of subjects ever tested on a topic are from 1 category, then you should collect and report that demographic data.","2021-01-08 12:29 +0000","88.0","17.0","0.19318181818181818","0.0","1.0","3.0","1.0","0.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347332777784578049","https://twitter.com/LisaDeBruine/status/1347332777784578049","@AmeliaMN Such a cool (and time-consuming!) experiment. Were you mainly teaching data analysis or also data processing? Did they have to clean and join real data or work with pre-tidied datasets?","2021-01-08 00:02 +0000","294.0","7.0","0.023809523809523808","0.0","1.0","2.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347325566157017090","https://twitter.com/LisaDeBruine/status/1347325566157017090","@cantabile https://t.co/iY7xJXotVh","2021-01-07 23:33 +0000","585.0","9.0","0.015384615384615385","0.0","1.0","1.0","2.0","0.0","0.0","1.0","0.0","0","0","0","0","0","128","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347322767222448128","https://twitter.com/LisaDeBruine/status/1347322767222448128","@MorbidPsych Agreed. The 25th seems more imperative to get nuclear code out of his hands and limit his ability to issue pardons. But I doubt either will really happen.","2021-01-07 23:22 +0000","99.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347320242561814536","https://twitter.com/LisaDeBruine/status/1347320242561814536","@MorbidPsych Doesn‚Äôt a successful impeachment bar him from holding office again? It could take care of an issue that would otherwise keep simmering for the next four years.","2021-01-07 23:12 +0000","673.0","29.0","0.04309063893016345","0.0","2.0","7.0","3.0","0.0","0.0","17.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347252578615226372","https://twitter.com/LisaDeBruine/status/1347252578615226372","@westwoodsam1 @DrGBuckingham @d_spiegel Also search the hashtag #badDataViz","2021-01-07 18:43 +0000","160.0","5.0","0.03125","0.0","0.0","1.0","0.0","0.0","4.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347251493657866251","https://twitter.com/LisaDeBruine/status/1347251493657866251","@westwoodsam1 @DrGBuckingham @d_spiegel https://t.co/mMegG8yVjy","2021-01-07 18:39 +0000","212.0","10.0","0.04716981132075472","0.0","1.0","2.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347210015132823564","https://twitter.com/LisaDeBruine/status/1347210015132823564","@Richie_Research Have you seen @dalejbarr‚Äôs L3 textbook?

https://t.co/OGN1PE8P3k","2021-01-07 15:54 +0000","810.0","75.0","0.09259259259259259","0.0","2.0","10.0","5.0","45.0","0.0","13.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347206696955949063","https://twitter.com/LisaDeBruine/status/1347206696955949063","@LaurenHallion @auzdavenice @bmwiernik @DrKeonWest This would work ok if we could have standard binning schemes across studies, but how do you metatanalyse the effects of age if one study bins 35-44, 45-54, ... and one bins 30-33, 34-37, ... ?","2021-01-07 15:41 +0000","194.0","4.0","0.020618556701030927","0.0","0.0","3.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347202506905055232","https://twitter.com/LisaDeBruine/status/1347202506905055232","@auzdavenice @LaurenHallion @bmwiernik @DrKeonWest Totally agreed, but this is better dealt with when sharing, not collecting. How will we know if some populations are unrepresented if we don‚Äôt collect data? And having specific data can let you combine data over studies to see if effects are different for minority populations.","2021-01-07 15:24 +0000","175.0","7.0","0.04","0.0","1.0","2.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347201518991192066","https://twitter.com/LisaDeBruine/status/1347201518991192066","@bmwiernik @xygalatas @DrKeonWest I agree. Generalisability is important and we can‚Äôt really assess it if we don‚Äôt have relevant data on sample characteristics. It would be useful if subfields could come up with standard variables of interest and scoring to make samples comparable and combinable, though.","2021-01-07 15:20 +0000","322.0","12.0","0.037267080745341616","1.0","0.0","4.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347156278322360322","https://twitter.com/LisaDeBruine/status/1347156278322360322","@Lisaa1000morea Thanks! I'll use that in the generic feedback. I'm also writing bullet points for each student, so was looking for a quick way to say to not use labels like ""trl_sp"" in each specific instance they're used in a figure, table or text (e.g., ""make fig 1 x-axis reader-friendly"").","2021-01-07 12:21 +0000","147.0","4.0","0.027210884353741496","0.0","0.0","0.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347137398489161728","https://twitter.com/LisaDeBruine/status/1347137398489161728","@clelandpsych @AngelaCleland That's a great idea. I've been keeping the heat on way too much because my hands get too cold to function, even when I'm wrapped in a jumper, bathrobe and blanket.","2021-01-07 11:05 +0000","478.0","9.0","0.01882845188284519","0.0","1.0","2.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347136608894648322","https://twitter.com/LisaDeBruine/status/1347136608894648322","@richarddmorey Now I'm really happy that I'm doing feedback all in one big YAML file (I know) and can just search/replace ""human-readable"" with ""reader-friendly"". (I'll use a script to create individual feedback files from that, a spreadsheet of category marks, and the overall grade)","2021-01-07 11:02 +0000","364.0","9.0","0.024725274725274724","0.0","0.0","4.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347134734321782784","https://twitter.com/LisaDeBruine/status/1347134734321782784","@YashvinSeetahul That describes some of them, but often they're perfectly understandable, like ""age_in_months"", but still not appropriate for a plot in a polished report (as opposed to supplemental materials or a quick exploratory dataviz)","2021-01-07 10:55 +0000","411.0","4.0","0.009732360097323601","0.0","1.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347134127062065158","https://twitter.com/LisaDeBruine/status/1347134127062065158","@richarddmorey ""reader-friendly"" is good!","2021-01-07 10:52 +0000","603.0","9.0","0.014925373134328358","0.0","1.0","2.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1347130945481150464","https://twitter.com/LisaDeBruine/status/1347130945481150464","What's a succinct, self-explanatory term for plot labels like ""Age in Months"" as opposed to table column headers like ""age_mo""? I'm marking #rstats reports and keep using the term ""human-readable"", which doesn't really connote what I want it to.","2021-01-07 10:40 +0000","7781.0","341.0","0.043824701195219126","5.0","13.0","5.0","30.0","0.0","4.0","284.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346960895709224969","https://twitter.com/LisaDeBruine/status/1346960895709224969","@ravenscimaven It‚Äôs almost midnight here in Scotland and I just anxiety-cooked some Taiwanese 3-cup tofu ü•ò https://t.co/NQYncNX9Lm","2021-01-06 23:24 +0000","879.0","101.0","0.1149032992036405","0.0","0.0","9.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","87","87","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346872595124203524","https://twitter.com/LisaDeBruine/status/1346872595124203524","@yorl And I‚Äôm also not sure how reasonable it is to say, for example, that the senators of North Dakota are in any way representing the interests of Californian Republicans.","2021-01-06 17:33 +0000","219.0","10.0","0.045662100456621","0.0","1.0","1.0","0.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346872186620010497","https://twitter.com/LisaDeBruine/status/1346872186620010497","@yorl Aye, but the imbalance in terms of number of senators per D/R voter nationwide seems to only coincidentally line up and certainly isn‚Äôt doing so by design. I wonder what the split would be if California split into 50 North Dakota-sized states.","2021-01-06 17:32 +0000","207.0","3.0","0.014492753623188406","0.0","1.0","0.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346864180264103936","https://twitter.com/LisaDeBruine/status/1346864180264103936","@jd_wilko I don‚Äôt have my glasses on and read that you were avoiding ‚ÄúJapanese pro-wrestling spiders‚Äù and was a little frightened for you for a second there.","2021-01-06 17:00 +0000","101.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346799674716532736","https://twitter.com/LisaDeBruine/status/1346799674716532736","@MatthewMGervais @bianhaan I see it under the sharing icon https://t.co/HvzobjfEA6","2021-01-06 12:43 +0000","214.0","4.0","0.018691588785046728","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","4","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346782788054360064","https://twitter.com/LisaDeBruine/status/1346782788054360064","@BragadinLeyla @UofGNews @NatureHumBehav @UofGPsychology @PsySciAcc Here‚Äôs the link to the more accessible preprint üòâ 

https://t.co/zUdVQQylxn","2021-01-06 11:36 +0000","99.0","3.0","0.030303030303030304","0.0","1.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346776375441711105","https://twitter.com/LisaDeBruine/status/1346776375441711105","@Dr_Lauren_Finka @UofGPsychology also has fantastic open-source undergraduate #psyTeachR books (courses led by @emilynordmann, @McAleerP, and @dalejbarr)

https://t.co/FTajzu4LNb","2021-01-06 11:11 +0000","367.0","9.0","0.02452316076294278","0.0","0.0","2.0","4.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346774999659667457","https://twitter.com/LisaDeBruine/status/1346774999659667457","@SchulteMi I think there are pluses and minuses. If you have a wide range of experience, some groups can end up with a bad balance (all unconfident learners, or one person who just does everything). Some weeks I set different Qs at diff levels for each breakout room and let students choose.","2021-01-06 11:05 +0000","68.0","3.0","0.04411764705882353","0.0","0.0","1.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346759633088745472","https://twitter.com/LisaDeBruine/status/1346759633088745472","The chapters and exercises use psychology-related datasets of varying sizes, available at https://t.co/fFpweLDNOJ or  as part of the class R package:
devtools::install_github(""psyteachr/msc-data-skills"")","2021-01-06 10:04 +0000","1857.0","41.0","0.02207862143241788","0.0","1.0","6.0","5.0","23.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346586999696797703","https://twitter.com/LisaDeBruine/status/1346586999696797703","What worked really well for me last term was to assign a chapter to read and/or watch each week before zoom class, spend the first hour talking through the exercises (which about 50% of them had attempted), and the second hour on group tasks.","2021-01-05 22:38 +0000","2774.0","16.0","0.005767844268204758","0.0","1.0","7.0","1.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346584648999120906","https://twitter.com/LisaDeBruine/status/1346584648999120906","@VerbingNouns https://t.co/Noi19JALWW","2021-01-05 22:29 +0000","891.0","11.0","0.012345679012345678","0.0","0.0","3.0","1.0","2.0","0.0","1.0","0.0","0","0","0","0","0","196","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346583994335453186","https://twitter.com/LisaDeBruine/status/1346583994335453186","With the last-minute move to remote teaching at some unis, I know some instructors will be panicking. My #rstats #psyTeachR MSc course on Data Skill for Reproducible Science is open source and has several short videos for each chapter plus exercises.

https://t.co/abC58l0UZk","2021-01-05 22:26 +0000","57846.0","1710.0","0.029561248833108598","111.0","5.0","314.0","172.0","476.0","22.0","608.0","0.0","0","0","0","0","0","2","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346575570927292416","https://twitter.com/LisaDeBruine/status/1346575570927292416","@kwbroman Thanks :) Is that in helper-utils.R because that runs first? I put mine in testthat.R just before the test_check() function.","2021-01-05 21:53 +0000","122.0","1.0","0.00819672131147541","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346573173534371845","https://twitter.com/LisaDeBruine/status/1346573173534371845","@zerdeve I agree. Most science reporting should be Ed Yong-style synthesis with a much broader perspective than one paper.","2021-01-05 21:43 +0000","1838.0","46.0","0.025027203482045703","2.0","1.0","14.0","4.0","0.0","0.0","25.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346520900871581699","https://twitter.com/LisaDeBruine/status/1346520900871581699","Today I discovered that, in addition to the jars making really nice drinking glasses, the lids of small Nutella jars fit perfectly on half-used Elmlea containers. https://t.co/n6crDiZuOW","2021-01-05 18:16 +0000","2461.0","224.0","0.09101991060544494","1.0","0.0","5.0","0.0","0.0","0.0","13.0","0.0","0","0","0","0","0","205","205","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346502719775907843","https://twitter.com/LisaDeBruine/status/1346502719775907843","Or do I have to define a new function and search/replace the hundreds of uses across dozens of test files like in this example CRAN sent?

https://t.co/0bfqdBRGOa","2021-01-05 17:03 +0000","1225.0","7.0","0.005714285714285714","0.0","0.0","0.0","1.0","5.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346502717963980806","https://twitter.com/LisaDeBruine/status/1346502717963980806","#rstats devs who have to update a CRAN package: is there any problem with adding this in the testthat.R file if I only ever use expect_equal() in tests?

expect_equal &lt;- function(...) {
  testthat::expect_equal(..., check.environment=FALSE)
}","2021-01-05 17:03 +0000","2823.0","27.0","0.009564293304994687","2.0","2.0","0.0","0.0","0.0","0.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346489648592412675","https://twitter.com/LisaDeBruine/status/1346489648592412675","@Keith_Not_Kevin Javascript's automatic type conversion is a mystery. All these are true:

""5"" + 2  == ""52"";
""5"" - 2  == 3;
Number(""0"") == 0;
Boolean(""0"") == true;
Number(false) == 0;

And js converts both to numbers for

""0"" == false;

Check the red values in the table at https://t.co/fSDAVsiJtK","2021-01-05 16:12 +0000","30.0","3.0","0.1","0.0","1.0","0.0","0.0","1.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346486852568682497","https://twitter.com/LisaDeBruine/status/1346486852568682497","@MatthewMGervais Twitter bookmarks (thanks for reminding me to check and clean them)","2021-01-05 16:00 +0000","860.0","11.0","0.012790697674418604","0.0","2.0","5.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346486567674777603","https://twitter.com/LisaDeBruine/status/1346486567674777603","The lesson for me is that all dataset attributes are strings. So if you set an element's data attribute to 0:

elem.dataset.tol = 0;

Then the value of elem.dataset.tol is actually ""0"" and you can't use it in code like this:

if (elem.dataset.tol) {
  // don't run if tol == 0
}","2021-01-05 15:59 +0000","1270.0","1.0","7.874015748031496E-4","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346486566252933122","https://twitter.com/LisaDeBruine/status/1346486566252933122","Some days I really hate #javascript (and implicit type conversion)

""0"" == false; // is TRUE

if (false) { 
  // doesn't run, makes sense
}

if (""0"") { 
  // does run üòû
}","2021-01-05 15:59 +0000","1898.0","23.0","0.012118018967334035","1.0","2.0","4.0","3.0","0.0","1.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346442752259723265","https://twitter.com/LisaDeBruine/status/1346442752259723265","@jo_hardin47 @statsdog @thosuz @AmeliaMN @minebocek @askdrstats @MineDogucu @canoodleson @Miles_Ott @BaumerBen @rudeboybert https://t.co/4wbSnGsA2S","2021-01-05 13:05 +0000","446.0","4.0","0.008968609865470852","0.0","0.0","2.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346421601869422592","https://twitter.com/LisaDeBruine/status/1346421601869422592","Another #rstats open code success story: @deevybee found a small but consequential error (my fault) in appendix 3b of @dalejbarr and my LMM sim paper that doubled values for main effects when converting from cell probabilities to logit betas (now fixed)

https://t.co/2iCOBLSk4n","2021-01-05 11:41 +0000","4667.0","122.0","0.026140989929290766","4.0","0.0","30.0","11.0","21.0","0.0","56.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346377271628730368","https://twitter.com/LisaDeBruine/status/1346377271628730368","@kirstie_j The original series is campy fun and sets up things that are referenced in the other series. There are a lot of top 10 episodes lists online with mostly the same recs if you don‚Äôt want to commit to all 74 episodes. (I‚Äôm almost done with S2 and a few are tedious.)","2021-01-05 08:45 +0000","177.0","3.0","0.01694915254237288","0.0","1.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346199734806073345","https://twitter.com/LisaDeBruine/status/1346199734806073345","Although I‚Äôm a big proponent of simulations for determining appropriate sample size, much of the time you won‚Äôt have enough info. It‚Äôs great to see a thorough discussion of all the options for justification. https://t.co/3QEmMCTQeP","2021-01-04 21:00 +0000","5324.0","56.0","0.010518407212622089","2.0","1.0","24.0","7.0","1.0","0.0","21.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346196213515878402","https://twitter.com/LisaDeBruine/status/1346196213515878402","Time to retweet this now that the paper is finally officially published! DM me with your details if you should be in this list and missed the emails in September. https://t.co/YisilwbuVd","2021-01-04 20:46 +0000","5600.0","65.0","0.011607142857142858","6.0","1.0","16.0","15.0","0.0","0.0","27.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1346194228519567362","https://twitter.com/LisaDeBruine/status/1346194228519567362","@Eavanmac @LMsphsu I really hope this works for you. I tried it last year and there were so many emails to move that it crashed and many duplicated themselves and now refuse to be marked as unread. (Maybe move them in batches.)","2021-01-04 20:38 +0000","245.0","7.0","0.02857142857142857","0.0","1.0","2.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345858065187418112","https://twitter.com/LisaDeBruine/status/1345858065187418112","@skyetetra Have you seen this one by @NatiDred ? https://t.co/Q5oRlR0E3z","2021-01-03 22:22 +0000","11375.0","2028.0","0.1782857142857143","46.0","2.0","101.0","21.0","1.0","0.0","134.0","0.0","0","0","0","0","0","2583","1723","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345426586967928832","https://twitter.com/LisaDeBruine/status/1345426586967928832","Anyone involved in postgraduate admin should read this ü§£üêç https://t.co/x72LXTue4a","2021-01-02 17:47 +0000","2798.0","31.0","0.011079342387419585","1.0","1.0","8.0","4.0","0.0","0.0","17.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345070995825168388","https://twitter.com/LisaDeBruine/status/1345070995825168388","@rfarmer27 Yay! That‚Äôs exactly what I was thinking about. So they were MGM cartoons, not Disney. https://t.co/xJpIrEWsa7","2021-01-01 18:14 +0000","142.0","8.0","0.056338028169014086","0.0","0.0","2.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","40","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345068942415560709","https://twitter.com/LisaDeBruine/status/1345068942415560709","@rfarmer27 Let me know if you remember a name. I scrolled through the entire Disney short animations list the other day and couldn‚Äôt find one.","2021-01-01 18:06 +0000","85.0","1.0","0.011764705882352941","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345064262876745728","https://twitter.com/LisaDeBruine/status/1345064262876745728","Does anyone else remember 60s-aesthetic cartoons that were like mock-educational documentaries about the future and its technology? I feel like they were on the free Disney channel previews in the US in the 80s, but can find no trace of them in web searches. Did I dream this?","2021-01-01 17:48 +0000","2550.0","78.0","0.03058823529411765","0.0","2.0","2.0","7.0","1.0","0.0","66.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345060050361053185","https://twitter.com/LisaDeBruine/status/1345060050361053185","@JessieSunPsych @datingdecisions @farid_anvari I‚Äôm obsessed lately with nutritional yeast and smoked paprika on popcorn, so I have the ingredients for this. I‚Äôll give it a try soon!","2021-01-01 17:31 +0000","228.0","7.0","0.03070175438596491","0.0","1.0","3.0","2.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345059404106883076","https://twitter.com/LisaDeBruine/status/1345059404106883076","@VerbingNouns Does it help to schedule rewards between essays? You could spend a day marathoning a whole British season of something (I can recommend Fleabag or Flowers) with 1 episode between each essay.","2021-01-01 17:28 +0000","77.0","3.0","0.03896103896103896","0.0","1.0","0.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345058535428784129","https://twitter.com/LisaDeBruine/status/1345058535428784129","@JessieSunPsych @datingdecisions @farid_anvari Also, what‚Äôs your zucchini gratin recipe? That sounds delicious.","2021-01-01 17:25 +0000","122.0","1.0","0.00819672131147541","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1345058180599066626","https://twitter.com/LisaDeBruine/status/1345058180599066626","@JessieSunPsych @datingdecisions @farid_anvari Ooh, that would be a cool app! Maybe a checklist of the ingredients you have and then sort recipes by what percent of ingredients you have covered.","2021-01-01 17:23 +0000","118.0","11.0","0.09322033898305085","0.0","1.0","3.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1344953908242870274","https://twitter.com/LisaDeBruine/status/1344953908242870274","@tcarpenter216 If it‚Äôs American-sized tiny, then definitely. 

I love living in Glasgow‚Äôs west end within walking distance of work, friends, gigs, good food, and lots of parks. The only time I‚Äôve missed having private outdoor space is the few weeks of lockdown where we couldn‚Äôt lounge in parks.","2021-01-01 10:29 +0000","622.0","4.0","0.006430868167202572","0.0","0.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1344951626893848576","https://twitter.com/LisaDeBruine/status/1344951626893848576","@cantabile @DrGBuckingham @JamesSteeleII ü§© I think this is what I normally do, which comes from flags, where you‚Äôre meant to hit the end of an arc on the beat. It also leads me to hit the beat way harder than I need to because that was good flag form, but irrelevant to beat saber.","2021-01-01 10:20 +0000","336.0","1.0","0.002976190476190476","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
