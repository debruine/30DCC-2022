"Tweet id","Tweet permalink","Tweet text","time","impressions","engagements","engagement rate","retweets","replies","likes","user profile clicks","url clicks","hashtag clicks","detail expands","permalink clicks","app opens","app installs","follows","email tweet","dial phone","media views","media engagements","promoted impressions","promoted engagements","promoted engagement rate","promoted retweets","promoted replies","promoted likes","promoted user profile clicks","promoted url clicks","promoted hashtag clicks","promoted detail expands","promoted permalink clicks","promoted app opens","promoted app installs","promoted follows","promoted email tweet","promoted dial phone","promoted media views","promoted media engagements"
"1365945498830577666","https://twitter.com/LisaDeBruine/status/1365945498830577666","@jorowags Just FYI (not relevant to the rest of the thread): Not everyone is American. Black History Month is October in NL and the U.K. (February is LGBTQ+ history month.)","2021-02-28 08:42 +0000","1323.0","152.0","0.11489040060468632","0.0","3.0","6.0","18.0","1.0","0.0","124.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365343386597785606","https://twitter.com/LisaDeBruine/status/1365343386597785606","@RosieGaga @NomeDaBarbarian I identify so hard with that! I haven’t solved the hunger yet, but I recently got WiFi lights and being able to control them from my phone is so good! No more realising I’ve been sitting in the dark an hour past sunset and somehow still not fixing it for another 2 hours.","2021-02-26 16:50 +0000","100.0","4.0","0.04","0.0","0.0","4.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365317700017348608","https://twitter.com/LisaDeBruine/status/1365317700017348608","@mjskay @polesasunder Seconded. It's annoying, but you can replace them with the unicode character code. 
https://t.co/9VdYl5yi7y","2021-02-26 15:08 +0000","195.0","12.0","0.06153846153846154","0.0","1.0","1.0","2.0","3.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365316552204107780","https://twitter.com/LisaDeBruine/status/1365316552204107780","#WebMorph finally has a manual! One of the best parts of giving a workshop on a program I wrote is that it makes me systematically do everything and fix all the annoying bugs. I also discovered a bunch of functions I added years ago and forgot about.

https://t.co/wiCMrLvxQj","2021-02-26 15:03 +0000","3090.0","56.0","0.018122977346278317","5.0","0.0","15.0","8.0","20.0","1.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365285003152736258","https://twitter.com/LisaDeBruine/status/1365285003152736258","I wondered what would happen if I really messed up a custom mask. I quite like this one #webMorphArt https://t.co/NvFNT39p8W","2021-02-26 12:58 +0000","2299.0","29.0","0.012614180078294911","1.0","0.0","4.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","20","20","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365236974928461829","https://twitter.com/LisaDeBruine/status/1365236974928461829","But the symmetric scrambles are the creepiest. https://t.co/6FSA3yPCia","2021-02-26 09:47 +0000","3565.0","149.0","0.04179523141654979","0.0","4.0","20.0","2.0","0.0","0.0","12.0","0.0","0","0","0","0","0","111","111","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365236677556506626","https://twitter.com/LisaDeBruine/status/1365236677556506626","More #webMorphArt You can use the image scrambler with template masks, so only scramble inside a specific masked area. https://t.co/ETLEvd1coI","2021-02-26 09:46 +0000","3987.0","121.0","0.03034863305743667","0.0","1.0","13.0","1.0","0.0","4.0","17.0","0.0","0","0","0","0","0","85","85","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365208964867235840","https://twitter.com/LisaDeBruine/status/1365208964867235840","@RemiGau This is vastly superior in the number of combinations and their usefulness for understanding a person. I’m FLAG :)","2021-02-26 07:55 +0000","450.0","4.0","0.008888888888888889","0.0","1.0","2.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1365207551202189315","https://twitter.com/LisaDeBruine/status/1365207551202189315","@JimGrange @DermotLynott I voted pro bono because I just agreed to one of these for the DGP and it only occurs to me now that I never even considered that I should be payed for it. I would have voted for remuneration if I didn’t have that concrete example.","2021-02-26 07:50 +0000","1431.0","17.0","0.011879804332634521","0.0","1.0","4.0","3.0","0.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364954979988090880","https://twitter.com/LisaDeBruine/status/1364954979988090880","Today @IrisHolzleitner and I were prepping for Monday's Methods in Face Research Workshop and we made an #accidentalArt when averaging two images with different templates. I should probably fix @webmorph_org so this gives a useful error message, but I kind of like it :) https://t.co/gmqIYD81vw","2021-02-25 15:06 +0000","3009.0","133.0","0.044200731139913595","0.0","2.0","15.0","15.0","0.0","0.0","33.0","0.0","0","0","0","0","0","68","68","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364860008459042818","https://twitter.com/LisaDeBruine/status/1364860008459042818","@Eavanmac @AGrayArchive I hadn’t, but now I’m registered! https://t.co/0l0RmOsmUl","2021-02-25 08:49 +0000","281.0","41.0","0.14590747330960854","0.0","0.0","2.0","0.0","0.0","0.0","8.0","0.0","0","0","0","0","0","31","31","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364850780986085377","https://twitter.com/LisaDeBruine/status/1364850780986085377","@Eavanmac @AGrayArchive Oh wow, has it been a whole year already? I remember we were meant to go to a memorial event at the Mitchell Library, but it was one of the first things cancelled by covid.","2021-02-25 08:12 +0000","602.0","11.0","0.018272425249169437","0.0","1.0","0.0","1.0","1.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364734120350351362","https://twitter.com/LisaDeBruine/status/1364734120350351362","@AndyPerfors I've submitted two positive stories of trans inclusiveness. I wondered if it's more impactful to spam it with identical copies of previous posts (so they have to read everything carefully), but I couldn't make myself submit that 🤮","2021-02-25 00:29 +0000","1041.0","17.0","0.01633045148895293","0.0","1.0","3.0","5.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364557825473712134","https://twitter.com/LisaDeBruine/status/1364557825473712134","@psforscher I made a quick gist to get the data structure right (I think) so c1 and c2 don't vary within ID and covariate doesn't vary within group. It only took 109 seconds to fit, so I feel like something else is wrong with your data.

https://t.co/wWs5CJ0iH3","2021-02-24 12:48 +0000","209.0","6.0","0.028708133971291867","0.0","1.0","1.0","0.0","1.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364555777453752324","https://twitter.com/LisaDeBruine/status/1364555777453752324","@psforscher (I'm not sure what type of variables C1 and C2 are. If they're factors with &gt; 2 levels then that will make things a lot more complicated.) But I can't figure out why else your model would be taking so long.","2021-02-24 12:40 +0000","337.0","10.0","0.02967359050445104","0.0","2.0","1.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364555415858593794","https://twitter.com/LisaDeBruine/status/1364555415858593794","@psforscher And adding this only took 142 seconds:

dat$c1 = rnorm(n)
dat$c2 = rnorm(n)

tm &lt;- system.time({
  m2 = lme4::lmer(dv~1+c1+c2+(c1+c2|group)+(1|ID), dat)
})","2021-02-24 12:38 +0000","136.0","6.0","0.04411764705882353","0.0","1.0","0.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364550945024188417","https://twitter.com/LisaDeBruine/status/1364550945024188417","@psforscher This model with no predictors takes ~20 seconds for me (I don't use brms, sorry)

dat &lt;- expand.grid(
  ID = 1:20000, 
  rep = 1:20)
n = nrow(dat)
dat$group = sample(1:80, n, T)
dat$dv = rnorm(n)

m = lme4::lmer(dv~1+(1|group)+(1|ID), dat)","2021-02-24 12:21 +0000","181.0","8.0","0.04419889502762431","0.0","1.0","1.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364549312332636161","https://twitter.com/LisaDeBruine/status/1364549312332636161","@rubenarslan @psforscher He's not, is he? Th formula in the first tweet is

outcome ~ covariate + c1 + c2 + (c1 + c2 | group) + (1 | ID)","2021-02-24 12:14 +0000","390.0","8.0","0.020512820512820513","0.0","1.0","0.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364538536154853382","https://twitter.com/LisaDeBruine/status/1364538536154853382","@psforscher If you have ~400K observations, then that’s ~20 observations per ID, right? Is there substantial within-ID variance? What does the model look like with no predictors apart from intercepts? Is the covariate specific to each observation?","2021-02-24 11:31 +0000","323.0","9.0","0.02786377708978328","0.0","1.0","0.0","2.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364533744191868929","https://twitter.com/LisaDeBruine/status/1364533744191868929","@psforscher How many groups and IDs per group do you have? What does the analysis look like for a single group?","2021-02-24 11:12 +0000","288.0","5.0","0.017361111111111112","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364002507832360962","https://twitter.com/LisaDeBruine/status/1364002507832360962","@seriousstats @amandadeibert It’s all meh, weird colour scheme, a bit cluttered, and then OMfG what is going on?!? And that last one with the exasperated baby!","2021-02-23 00:01 +0000","295.0","6.0","0.020338983050847456","0.0","1.0","3.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1364000424378986497","https://twitter.com/LisaDeBruine/status/1364000424378986497","@amandadeibert I am crying laughing","2021-02-22 23:53 +0000","627.0","8.0","0.012759170653907496","0.0","1.0","3.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363996670569164803","https://twitter.com/LisaDeBruine/status/1363996670569164803","I can't believe LGBTQIA+ History Month is almost over! Getting excited for the first meeting of this journal club on Friday. DM me or @emilynordmann if you'd like to join us. https://t.co/LUgxX6ylUk","2021-02-22 23:38 +0000","3459.0","41.0","0.01185313674472391","2.0","0.0","7.0","14.0","0.0","0.0","18.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363985135599816704","https://twitter.com/LisaDeBruine/status/1363985135599816704","@B_A_Palmer True. But I deleted the original tweet because I finally found mention of the N in a figure caption. The fact they gave df for chi-square but not t-tests made me feel like they were trying to hide the N, but it was there if you search hard enough.","2021-02-22 22:52 +0000","45.0","1.0","0.022222222222222223","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363821859066773507","https://twitter.com/LisaDeBruine/status/1363821859066773507","@sTeamTraen @dingding_peng @DrGBuckingham (P.S., this function is mostly a joke)","2021-02-22 12:04 +0000","415.0","3.0","0.007228915662650603","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363820545536634882","https://twitter.com/LisaDeBruine/status/1363820545536634882","@sTeamTraen @dingding_peng @DrGBuckingham I had a bash at a function that does what is expected from primary school maths. It's harder than you'd think (but can probably be simplified if I thought about it harder).

https://t.co/gUbglgR0rw","2021-02-22 11:58 +0000","365.0","9.0","0.024657534246575342","0.0","1.0","2.0","0.0","5.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363813495645569024","https://twitter.com/LisaDeBruine/status/1363813495645569024","Really feeling this right now. I miss so many people, but also don’t seem to have the energy to interact with anyone anymore. https://t.co/z0f20m5hjX","2021-02-22 11:30 +0000","5358.0","91.0","0.0169839492347891","1.0","1.0","46.0","2.0","3.0","0.0","38.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363761381405843457","https://twitter.com/LisaDeBruine/status/1363761381405843457","@sTeamTraen @dingding_peng @DrGBuckingham I thought R did bankers rounding (up for odd numbers and down for even), or is that just for rounding to the nearest integer?","2021-02-22 08:03 +0000","651.0","8.0","0.01228878648233487","0.0","2.0","2.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363613440112263169","https://twitter.com/LisaDeBruine/status/1363613440112263169","@CathrynTownsend I assumed you meant English language, but reading some of the others makes me think you mean authors from England now. So the Winterson book still counts.","2021-02-21 22:15 +0000","190.0","3.0","0.015789473684210527","0.0","1.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363611861996994563","https://twitter.com/LisaDeBruine/status/1363611861996994563","@CathrynTownsend The Passion @Wintersonworld (historical magical realism)

Neuromancer @GreatDismal

This is how you lose the time war @tithenai (gorgeous epistolary fic)

The Paradox Suite @wordstrings (totally changed how I look at fanfic)

Who Fears Death @Nnedi (expansive africanfuturism)","2021-02-21 22:09 +0000","1130.0","22.0","0.019469026548672566","0.0","1.0","5.0","12.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1363603708462964742","https://twitter.com/LisaDeBruine/status/1363603708462964742","https://t.co/HAOEANY4a8 https://t.co/LY6XbMs79M","2021-02-21 21:37 +0000","2079.0","22.0","0.010582010582010581","0.0","0.0","6.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","267","10","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362896891281866752","https://twitter.com/LisaDeBruine/status/1362896891281866752","@emma_cogdev @DrGBuckingham @IamHappyToast I still get a few responses a day to this tweet. The poll is in the thread somewhere. https://t.co/fFUkevifQo","2021-02-19 22:48 +0000","277.0","8.0","0.02888086642599278","0.0","1.0","2.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362768825415061504","https://twitter.com/LisaDeBruine/status/1362768825415061504","Let me know if you try it and have any problems. I'll probably submit this version to CRAN soon.","2021-02-19 14:19 +0000","1341.0","1.0","7.457121551081282E-4","0.0","0.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362768608884047874","https://twitter.com/LisaDeBruine/status/1362768608884047874","I've updated the dev version of {faux} to finally fix an issue @willemsleegers filed over a year ago. It no longer mangles factor level names with underscores in long format, and changing the default separator in wide format works as expected. #rstats

https://t.co/fCsPDSi0Ye https://t.co/tz5Z21EhAt","2021-02-19 14:18 +0000","2254.0","45.0","0.019964507542147295","2.0","1.0","6.0","4.0","3.0","0.0","3.0","0.0","0","0","0","0","0","26","26","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362766294299389955","https://twitter.com/LisaDeBruine/status/1362766294299389955","@tjmahr I just forgot I have to run ""git rm --cached .Rprofile"" in the terminal to get it to actually stop trying to stage itself. I prefer git in the terminal, but the RStudio pane version is so convenient for straightforward commits and pushes that my terminal skills are slipping.","2021-02-19 14:09 +0000","768.0","7.0","0.009114583333333334","1.0","1.0","0.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362717881553870853","https://twitter.com/LisaDeBruine/status/1362717881553870853","Yesterday I avoided marking by doing meta-marking, today I'm avoiding coding by doing meta-coding.","2021-02-19 10:57 +0000","1789.0","20.0","0.011179429849077696","1.0","1.0","11.0","1.0","1.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362715283111219212","https://twitter.com/LisaDeBruine/status/1362715283111219212","I was debugging and got frustrated by having to set default values for arguments so I could step through the code, so I made a function that does it for you.

https://t.co/QZDURB9yZK https://t.co/QjWEgr18fM","2021-02-19 10:46 +0000","3476.0","175.0","0.050345224395857306","3.0","1.0","13.0","7.0","12.0","0.0","38.0","0.0","0","0","0","0","0","101","101","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362694782934474753","https://twitter.com/LisaDeBruine/status/1362694782934474753","@tjmahr They pass! The failures were about my new .Rprofile (which .gitignore refuses to ignore so I had to manually delete it and now always have to unselect on commit). I always want usethis, so added require(usethis) to my .Rprofile, but this breaks R-CMD-check.","2021-02-19 09:25 +0000","190.0","2.0","0.010526315789473684","0.0","1.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362688822035767299","https://twitter.com/LisaDeBruine/status/1362688822035767299","@tjmahr I tried this today and it worked perfectly! (Well, everything failed, but I successfully failed...) Is there any need to use both Travis-CI and R-CMD-check?","2021-02-19 09:01 +0000","154.0","4.0","0.025974025974025976","0.0","1.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362684510291324929","https://twitter.com/LisaDeBruine/status/1362684510291324929","I love how making a confidently absurd statement about a graph really gets people to look at it critically in a way that a bland summary wouldn't. https://t.co/Aw8XdpcvKc","2021-02-19 08:44 +0000","4933.0","194.0","0.03932698155280762","1.0","2.0","35.0","2.0","5.0","0.0","149.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362671589708476417","https://twitter.com/LisaDeBruine/status/1362671589708476417","@mjskay I think it would be very hard to implement something automatic because the dots are used for a lot of other purposes than just passing arguments to one other function. If you’re doing that and want autocomplete, probably adding the arguments by name is the only solution.","2021-02-19 07:53 +0000","289.0","5.0","0.01730103806228374","0.0","1.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362522051668492294","https://twitter.com/LisaDeBruine/status/1362522051668492294","@DrGBuckingham What? No.","2021-02-18 21:59 +0000","547.0","7.0","0.012797074954296161","0.0","0.0","2.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362497868989366277","https://twitter.com/LisaDeBruine/status/1362497868989366277","@aggieerin I need to add a time series example like this. And nested groups. All we did was cross-classified models, so it's hard to extrapolate.","2021-02-18 20:23 +0000","125.0","4.0","0.032","0.0","1.0","1.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362497686675607560","https://twitter.com/LisaDeBruine/status/1362497686675607560","@aggieerin The 1 in ""random = ~1|partno"" represents the participant's deflection from the intercept (mean_panas, if I'm understanding correctly), but isn't in the Y formula. Does this make sense?","2021-02-18 20:22 +0000","152.0","8.0","0.05263157894736842","0.0","1.0","2.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362497246458224645","https://twitter.com/LisaDeBruine/status/1362497246458224645","@aggieerin You need to add a random intercept term to your model for each participant:

part_i &lt;- rnorm(number_group, 0, part_i_sd)

Y &lt;- mean_panas + rep(part_i , 2)+
      slope_time*time_point + 
      slope_group*group + 
      slope_interaction*group*time_point + 
      error_terms","2021-02-18 20:20 +0000","205.0","12.0","0.05853658536585366","0.0","2.0","3.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362496025068523522","https://twitter.com/LisaDeBruine/status/1362496025068523522","@DrGBuckingham @jud41 @emilynordmann @McAleerP @dalejbarr @dalejbarr did a lot of the staff education before he and I wrote this class, so it incorporated much of what he presented to staff. @McAleerP and @emilynordmann are probably better placed to talk about staff ed, as their courses have multiple staff.","2021-02-18 20:15 +0000","316.0","5.0","0.015822784810126583","0.0","1.0","0.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362495201403633664","https://twitter.com/LisaDeBruine/status/1362495201403633664","@aggieerin I'm not understanding how you're modeling the group-level random intercepts and slopes here. You seem to just have one error_term and fixed values for mean_panas, slope_time, slope_group, and slope_interaction.","2021-02-18 20:12 +0000","839.0","25.0","0.029797377830750895","0.0","2.0","3.0","3.0","0.0","0.0","17.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362493419998879744","https://twitter.com/LisaDeBruine/status/1362493419998879744","@jud41 @DrGBuckingham @emilynordmann @McAleerP @dalejbarr This course is meant to catch up MSc students with a typical non-R psych undergrad background. It's 10 lessons with associated videos and exercises.

https://t.co/abC58l0UZk","2021-02-18 20:05 +0000","1239.0","52.0","0.041969330104923326","2.0","2.0","6.0","0.0","28.0","0.0","14.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362491915481059333","https://twitter.com/LisaDeBruine/status/1362491915481059333","I finished today's marking, so updated the app and made a quick run-through video. I can't put it online (it's too dangerous to run user-defined code), so you have to access it through R using the function markr_app()

https://t.co/Mm2vgFabkn https://t.co/jRGhKWCWa6","2021-02-18 19:59 +0000","1476.0","17.0","0.011517615176151762","0.0","0.0","2.0","0.0","8.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362457752149360645","https://twitter.com/LisaDeBruine/status/1362457752149360645","@emilynordmann @n_j_davis @jotaylor2306 @DrGBuckingham @McAleerP @dalejbarr @QiuYani @CesarAntonioGS R also makes it easier to really explore data. For example, @dalejbarr’s whole level 3 course is based on simulating data to better understand stats conceptually. (This is still the main way I understand new stats.)

https://t.co/Z7FVMjyNBV","2021-02-18 17:43 +0000","247.0","15.0","0.06072874493927125","0.0","1.0","1.0","0.0","6.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362457109829480448","https://twitter.com/LisaDeBruine/status/1362457109829480448","@emilynordmann @n_j_davis @jotaylor2306 @DrGBuckingham @McAleerP @dalejbarr @QiuYani @CesarAntonioGS I agree that just translating exercises from SPSS to R wouldn’t be helpful, but the whole philosophy of teaching methods changed (the R in #psyTeachR is for Reproducible Research, not Rstats)","2021-02-18 17:41 +0000","296.0","9.0","0.030405405405405407","0.0","1.0","4.0","0.0","1.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362374730184032262","https://twitter.com/LisaDeBruine/status/1362374730184032262","The app will be updated soon, but I have actual marking I need to finish today before I'm allowed to work on meta-marking any more (even though meta-marking is *so* much more interesting).","2021-02-18 12:13 +0000","2818.0","17.0","0.00603264726756565","1.0","0.0","2.0","1.0","0.0","0.0","12.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362370452543459335","https://twitter.com/LisaDeBruine/status/1362370452543459335","I'm working on a shiny app to make this usable without R, but at the moment it just converts spreadsheets to YAML, which is an easier way to provide paragraphs of feedback.

https://t.co/Eu1Ixj2qZH","2021-02-18 11:56 +0000","1700.0","23.0","0.013529411764705882","0.0","1.0","1.0","0.0","10.0","0.0","8.0","0.0","0","0","0","0","0","3","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362370451113193473","https://twitter.com/LisaDeBruine/status/1362370451113193473","If you think this would be useful for you, please give it a try and let me know if there is anything else you'd want it to be able to do. We're been using it for exam feedback at @UofGPsychology for a few years now and it's been helpful for getting the files named for moodle.","2021-02-18 11:56 +0000","753.0","4.0","0.005312084993359893","0.0","1.0","0.0","3.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362369826400960512","https://twitter.com/LisaDeBruine/status/1362369826400960512","You can also create visualisations of the whole marking file to include in the feedback or just for your own information. https://t.co/ZyrvDGRxZd","2021-02-18 11:54 +0000","799.0","39.0","0.04881101376720901","0.0","1.0","2.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","32","32","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362369364125745152","https://twitter.com/LisaDeBruine/status/1362369364125745152","Once you have the template and spreadsheet set up, creating the feedback files is this simple:

markr::make_feedback(
  marks = ""marking.csv"", # or data frame
  template = ""template.Rmd"",
  filename = ""fb/[class]/feedback_[student_id]""
)","2021-02-18 11:52 +0000","762.0","12.0","0.015748031496062992","0.0","1.0","0.0","1.0","0.0","0.0","10.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362369360854147072","https://twitter.com/LisaDeBruine/status/1362369360854147072","Do you wish you could create student feedback documents dynamically from spreadsheets? Markr lets you render an Rmd template using the info from each row in a table and saves it to a filename you can specify.

https://t.co/vSAa84xBCH https://t.co/mQopWDM2dF","2021-02-18 11:52 +0000","7454.0","446.0","0.05983364636436812","10.0","1.0","38.0","7.0","30.0","0.0","110.0","0.0","0","0","0","0","0","250","250","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362312103298793476","https://twitter.com/LisaDeBruine/status/1362312103298793476","@ravenscimaven That’s awful and not standard in my experience. I’ve been on several TV shows as a scientist and never had to answer questions like this. 

https://t.co/A6BBTsgSvx","2021-02-18 08:04 +0000","888.0","21.0","0.02364864864864865","0.0","0.0","1.0","2.0","15.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1362307988808212481","https://twitter.com/LisaDeBruine/status/1362307988808212481","@mjskay @JessicaHullman https://t.co/Lxtn1sn88A","2021-02-18 07:48 +0000","244.0","10.0","0.040983606557377046","0.0","0.0","4.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","65","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361945393274245121","https://twitter.com/LisaDeBruine/status/1361945393274245121","@Tweetgood_Mac March 6th https://t.co/39tNtNt0Qk","2021-02-17 07:47 +0000","1897.0","289.0","0.15234580917237744","0.0","2.0","10.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","273","273","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361792969121136643","https://twitter.com/LisaDeBruine/status/1361792969121136643","@Richie_Research @Rob_O_Malley @HollyDunsworth @TheLeakeyFndtn To start with, “sexually selected by violent warfare” is incoherent in a way you normally aren’t. Do you mean sexually selected by women whose mate preferences are shaped by violent warfare? If so, what’s the evidence and why are alternatives  wrong?","2021-02-16 21:41 +0000","365.0","34.0","0.09315068493150686","0.0","0.0","6.0","3.0","0.0","0.0","25.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361760059521458178","https://twitter.com/LisaDeBruine/status/1361760059521458178","@Richie_Research @Rob_O_Malley @HollyDunsworth @TheLeakeyFndtn Did you watch the talk?","2021-02-16 19:31 +0000","793.0","31.0","0.03909205548549811","0.0","1.0","5.0","3.0","0.0","0.0","22.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361755874436526088","https://twitter.com/LisaDeBruine/status/1361755874436526088","It’s that time of the month where I put all the veggie scraps from the freezer into the slow cooker and make broth. The house already smells amazing. This is one of the very few life hacks I’ve tried that stuck.","2021-02-16 19:14 +0000","3476.0","141.0","0.0405638665132336","0.0","2.0","24.0","10.0","0.0","0.0","105.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361734223263125508","https://twitter.com/LisaDeBruine/status/1361734223263125508","@GlasgowTea @rimamrahal Would you mind adding alt text so everyone can access the info in images?","2021-02-16 17:48 +0000","774.0","27.0","0.03488372093023256","0.0","1.0","5.0","5.0","0.0","0.0","16.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361640038946242561","https://twitter.com/LisaDeBruine/status/1361640038946242561","What do you want to learn to do with webmorph or morphometric face analysis?

This workshop is now full with 11 on the waitlist, but don't let that stop you from signing up if you're interested. If the waitlist gets much bigger, we'll run a second workshop in March. https://t.co/adKwlQlUu1","2021-02-16 11:34 +0000","2092.0","12.0","0.0057361376673040155","1.0","0.0","2.0","2.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361614321214717953","https://twitter.com/LisaDeBruine/status/1361614321214717953","@megandfigueroa This looks really cool. Do you have to log the thing when you do it or can you retrospectively log? (and thanks for reminding me to eat breakfast :)","2021-02-16 09:52 +0000","485.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361613117873152005","https://twitter.com/LisaDeBruine/status/1361613117873152005","@djnavarro Take care of yourself. It's a fucking disgrace that you have to go through this.","2021-02-16 09:47 +0000","1445.0","15.0","0.010380622837370242","0.0","0.0","3.0","4.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361609652140716033","https://twitter.com/LisaDeBruine/status/1361609652140716033","@matherion @charliejhadley Ah, that was just on run. If I save the file I do see the install message at the top. 👍","2021-02-16 09:33 +0000","173.0","2.0","0.011560693641618497","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361609309562503169","https://twitter.com/LisaDeBruine/status/1361609309562503169","@matherion @charliejhadley Nope, just tested it and I get this for NAMESPACE::function from a CRAN package I don't have:
 
Error in loadNamespace(name) : there is no package called 'face'","2021-02-16 09:32 +0000","115.0","5.0","0.043478260869565216","0.0","1.0","3.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361599301093388288","https://twitter.com/LisaDeBruine/status/1361599301093388288","@_johnmackintosh @charliejhadley Seconding this question. What’s better about remotes? I ask complete beginners to download the class package from GitHub; does a new install of R have remotes?","2021-02-16 08:52 +0000","74.0","6.0","0.08108108108108109","0.0","1.0","1.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361598777635860480","https://twitter.com/LisaDeBruine/status/1361598777635860480","@matherion @charliejhadley Does this come from package writing? It annoying when trying to run someone else’s script and finding out every few minutes you need to install another package, so I always use library at the top and also include the namespace for unusual functions.","2021-02-16 08:50 +0000","128.0","3.0","0.0234375","0.0","1.0","0.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361382242229104641","https://twitter.com/LisaDeBruine/status/1361382242229104641","@JohnSakaluk @datingdecisions @dstephenlindsay It would just make the whole process less stressful if the auto-generated letters didn’t say “proofs must be returned within 48 hours”, but rather something like “proofs should ideally be returned within 2 working days, please contact us if you need longer”.","2021-02-15 18:29 +0000","273.0","15.0","0.054945054945054944","0.0","1.0","8.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361366697219940353","https://twitter.com/LisaDeBruine/status/1361366697219940353","@RemiGau @GuyProchilo It's on reward and midfollicular vs luteal estradiol and prog. I don't know enough to judge if the brain areas they focus on are theoretically motivated or a fishing expedition. And it has that frustrating PNAS methods at the end format.

https://t.co/k3voielV0D","2021-02-15 17:28 +0000","260.0","7.0","0.026923076923076925","0.0","2.0","0.0","0.0","5.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361324650526105602","https://twitter.com/LisaDeBruine/status/1361324650526105602","@lysanderjames This would be great. @AdeyemiAdetula1, @D_BasnightBrown and @nataliadutrapsy would be perfect people to collab with on this.","2021-02-15 14:41 +0000","172.0","12.0","0.06976744186046512","0.0","1.0","3.0","2.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361314851788894216","https://twitter.com/LisaDeBruine/status/1361314851788894216","@VerbingNouns That was my first instinct having done behavioural hormone studies. There's such a huge difference between individuals and over the cycle, plus receptor sensitivity to account for. This just seemed impossible to find once, much less for 5 or 6 different correlations.","2021-02-15 14:02 +0000","178.0","11.0","0.06179775280898876","0.0","3.0","2.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361314441078398976","https://twitter.com/LisaDeBruine/status/1361314441078398976","@GuyProchilo Thanks! I'm marking essays on a target article with these suspiciously high correlations (I didn't choose the article) and will mention this paper in my generic feedback to the students.","2021-02-15 14:00 +0000","314.0","11.0","0.03503184713375796","0.0","1.0","2.0","3.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361298031916822529","https://twitter.com/LisaDeBruine/status/1361298031916822529","Should I be wary of a paper that reports several between-subject correlations between hormones (in a single phase, from blood) and fMRI parameters that look like this (with n = 10)? I would be if they were behavioural data, but I'm not a neuroscientist. https://t.co/vFmrEa7Thz","2021-02-15 12:55 +0000","8507.0","1088.0","0.1278946749735512","0.0","10.0","14.0","14.0","1.0","0.0","454.0","0.0","0","0","0","0","0","595","595","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361033006656421889","https://twitter.com/LisaDeBruine/status/1361033006656421889","@djnavarro Those are very pleasantly shaped blobs :)","2021-02-14 19:22 +0000","488.0","2.0","0.004098360655737705","0.0","0.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1361021985757794304","https://twitter.com/LisaDeBruine/status/1361021985757794304","@d_olivaw @charliejhadley I’ll definitely try it out. I need different consistent setups for my own coding, teaching in person, teaching on zoom, and recording videos, so it would be perfect to be able to  script that.","2021-02-14 18:38 +0000","38.0","2.0","0.05263157894736842","0.0","0.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360977380630814724","https://twitter.com/LisaDeBruine/status/1360977380630814724","@page_gould @Richie_Research @UofGPsychology I was just looking at your GLM slides @page_gould and they’re so lovely and clear! I’m definitely going to add that resource to my GLM chapter.","2021-02-14 15:41 +0000","305.0","5.0","0.01639344262295082","0.0","1.0","2.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360974560624074756","https://twitter.com/LisaDeBruine/status/1360974560624074756","@page_gould @Richie_Research Wow! That’s a lot of work. I feel lucky that we teach tidyverse from day 1 at @UofGPsychology, so everyone is used to pipes. Base R is great for package development, but I do love how well tidyverse integrates things for beginners. #psyTeachR","2021-02-14 15:29 +0000","449.0","10.0","0.022271714922048998","0.0","2.0","2.0","2.0","0.0","2.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360953171401715712","https://twitter.com/LisaDeBruine/status/1360953171401715712","@d_olivaw Good idea!","2021-02-14 14:04 +0000","230.0","4.0","0.017391304347826087","0.0","0.0","0.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360951980336812033","https://twitter.com/LisaDeBruine/status/1360951980336812033","I've made some upgrades and bug fixes to my #rstats package faux (for simulating data with factorial designs) and would love to get some user feedback. Would anyone be interested in a zoom tutorial Thursday Feb 18 at 15:00 GMT? https://t.co/fCsPDSi0Ye","2021-02-14 14:00 +0000","5309.0","128.0","0.0241100018835939","6.0","0.0","6.0","20.0","18.0","0.0","44.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360949673834463232","https://twitter.com/LisaDeBruine/status/1360949673834463232","@bmwiernik I can't find any appearance options under project options. https://t.co/yTltnAraM8","2021-02-14 13:51 +0000","244.0","10.0","0.040983606557377046","0.0","1.0","1.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","3","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360934908273786880","https://twitter.com/LisaDeBruine/status/1360934908273786880","If you want to put the code above inside .Rprofile, wrap it in this so it doesn't run until after RStudio has started up:

setHook(""rstudio.sessionInit"", function(newSession) {
  # your rstudioapi code
}, action = ""append"")","2021-02-14 12:52 +0000","1470.0","6.0","0.004081632653061225","0.0","0.0","3.0","2.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360931641594626052","https://twitter.com/LisaDeBruine/status/1360931641594626052","I wish it had an option to change font programmatically. I adore FiraCode, but ligatures are confusing to beginners, so I never use it when teaching. I’d love to have a quick way to swap between all my settings and teaching-friendly settings, but font size is a good start.","2021-02-14 12:39 +0000","2159.0","22.0","0.010189902732746642","0.0","3.0","6.0","1.0","0.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360913396288401410","https://twitter.com/LisaDeBruine/status/1360913396288401410","Found a cool one. Try this:

prefs &lt;- list(
  font_size_points = 16L,
  help_font_size_points = 12L
)
mapply(rstudioapi::writeRStudioPreference, 
             names(prefs), prefs)

More options: https://t.co/JL6Byzrxr8","2021-02-14 11:26 +0000","1848.0","46.0","0.024891774891774892","1.0","1.0","5.0","1.0","31.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360896865395478528","https://twitter.com/LisaDeBruine/status/1360896865395478528","I just remembered I'm not teaching code as regularly anymore (just coding club every other week) and I can customise my #RStudio! I've switched back to a dark theme and am playing with changing the panes. What are everybody's best tips and tricks? #rstats","2021-02-14 10:21 +0000","13798.0","719.0","0.05210900130453689","9.0","6.0","33.0","30.0","3.0","14.0","618.0","0.0","0","0","0","0","0","6","6","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360707256971575299","https://twitter.com/LisaDeBruine/status/1360707256971575299","Is there anything better than an email from Travis-CI that starts with “Fixed:”?","2021-02-13 21:47 +0000","1846.0","5.0","0.0027085590465872156","0.0","0.0","3.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360661551921963010","https://twitter.com/LisaDeBruine/status/1360661551921963010","@tomstafford I fixed rnorm_pre to work with multiple vectors. It's only on the dev version, of course. Have a play and see what you think.

https://t.co/6FbsSWgbUv","2021-02-13 18:46 +0000","127.0","4.0","0.031496062992125984","0.0","1.0","0.0","0.0","3.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360638405810528256","https://twitter.com/LisaDeBruine/status/1360638405810528256","@aggieerin This will be fixed in the next update (and is available in the dev version now). Now you can also simulate missingness based on joint probabilities from your data.

https://t.co/skTbFpt2ZT","2021-02-13 17:14 +0000","126.0","1.0","0.007936507936507936","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360630584800915457","https://twitter.com/LisaDeBruine/status/1360630584800915457","Does anyone know how to remove ""output: github_document"" from the top of the main page in #pkgdown sites? (besides going in and deleting it from the html every time you build the site)","2021-02-13 16:43 +0000","2219.0","42.0","0.01892744479495268","0.0","2.0","2.0","1.0","0.0","3.0","34.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360629674741805058","https://twitter.com/LisaDeBruine/status/1360629674741805058","@tjmahr @bmwiernik Thanks! I'll put this on my list to learn. The original version of faux was a huge mess after the recent tidyverse changes and I switched almost everything to base. I just need to get to grips with tidyeval.","2021-02-13 16:39 +0000","121.0","1.0","0.008264462809917356","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360606294864977930","https://twitter.com/LisaDeBruine/status/1360606294864977930","(obviously there will need to be a lot more checking in case something isn't a valid column name or index, but I can only fit so much in a tweet)","2021-02-13 15:06 +0000","1226.0","7.0","0.005709624796084829","0.0","1.0","0.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360605913820897286","https://twitter.com/LisaDeBruine/status/1360605913820897286","OK, this seems to do what I want:

getcols &lt;- function(data, ...) {
  sapply(rlang::exprs(...), function(v) {
    switch(typeof(v),
      symbol  = rlang::as_string(v),
      character = v,
      names(data)[v])
  })
}

getcols(mtcars, 1L, cyl, ""disp"")","2021-02-13 15:05 +0000","1305.0","3.0","0.0022988505747126436","0.0","1.0","0.0","2.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360600386097283072","https://twitter.com/LisaDeBruine/status/1360600386097283072","I can use this to figure out which ones are numeric, symbol, or character, but then how do I select just the symbols?

rlang::exprs(...) %&gt;% lapply(typeof)","2021-02-13 14:43 +0000","873.0","12.0","0.013745704467353952","0.0","1.0","0.0","3.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360593310360952836","https://twitter.com/LisaDeBruine/status/1360593310360952836","@tomstafford The code is mainly:

y &lt;- stats::rnorm(n)
z &lt;- r * scale(x)[,1] + sqrt(1 - r^2) * 
    scale(stats::resid(stats::lm(y ~ x)))[,1]
yresult &lt;- mu + sd * z

Where x is the existing vector and r is the correlation.

So you can maybe modify that for more than one x?","2021-02-13 14:14 +0000","228.0","2.0","0.008771929824561403","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360592800614670343","https://twitter.com/LisaDeBruine/status/1360592800614670343","@tomstafford I'm not sure, I'll add this to my to-do list (or you can file an issue on github). I'm working on faux today to make sim_df work with missing data (and optionally return missingness with the same pattern).","2021-02-13 14:12 +0000","177.0","2.0","0.011299435028248588","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360592236623392770","https://twitter.com/LisaDeBruine/status/1360592236623392770","Help #rstats

I want to use rlang::ensyms(...) on the arguments to a function, but only if they're characters or unquoted column names, not numeric. How do I test this without running into ""object 'x' not found""?

(I'm not getting anywhere with https://t.co/Hyy6bJ1JUj)","2021-02-13 14:10 +0000","3308.0","44.0","0.013301088270858524","3.0","1.0","2.0","6.0","1.0","1.0","30.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360335246277947401","https://twitter.com/LisaDeBruine/status/1360335246277947401","@aggieerin Ah, good to know that breaks it! That’s the problem with testing on too tidy data. I’ll try to remember to sort that soon (or you can add an issue to the GitHub).","2021-02-12 21:09 +0000","234.0","5.0","0.021367521367521368","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360259041491058690","https://twitter.com/LisaDeBruine/status/1360259041491058690","@dataandme Yes! I’ve been a little paranoid that I did something that made people soft block me, but I can’t think of what.","2021-02-12 16:06 +0000","469.0","6.0","0.01279317697228145","0.0","0.0","1.0","2.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360238336535891970","https://twitter.com/LisaDeBruine/status/1360238336535891970","@AnthonyTeacher @lakens I’d say that falls under resource constraints. Time is a limited resource.","2021-02-12 14:44 +0000","658.0","2.0","0.00303951367781155","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360224673951285249","https://twitter.com/LisaDeBruine/status/1360224673951285249","@elborgo9 @JamesSteeleII In my experience, not all (or even most) of the reviewers, but if anyone ever wants to replicate or build on your study, or include it in an evidence synthesis, they’ll really appreciate the effort.","2021-02-12 13:50 +0000","102.0","5.0","0.049019607843137254","0.0","1.0","2.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360224279523176450","https://twitter.com/LisaDeBruine/status/1360224279523176450","@elborgo9 Everyone should try an exact replication, computational reproducibility check, or meta-analysis someday to really understand how to make methods and results useful to others.","2021-02-12 13:48 +0000","249.0","2.0","0.008032128514056224","1.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360221874790268933","https://twitter.com/LisaDeBruine/status/1360221874790268933","@elborgo9 Definitely wrongly. I agree that restricting the length of methods is unjustifiable, especially when most publication is electronic now.","2021-02-12 13:39 +0000","216.0","12.0","0.05555555555555555","0.0","2.0","3.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360221004400836608","https://twitter.com/LisaDeBruine/status/1360221004400836608","This is only a good idea if authors, reviewers and editors acknowledge that there are *many* valid sample size justifications besides the N that gives you 80% power to detect the median effect size from meta-analyses, with an alpha of .05. @lakens’ preprint is a good primer. https://t.co/UwYpA4lrhB","2021-02-12 13:35 +0000","7580.0","96.0","0.012664907651715039","4.0","1.0","25.0","6.0","3.0","0.0","55.0","0.0","0","0","0","0","0","2","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360210731380146176","https://twitter.com/LisaDeBruine/status/1360210731380146176","This is beautifully clear and a model for how to help students understand how to write up methods. https://t.co/WY62SjNnHd","2021-02-12 12:54 +0000","19597.0","332.0","0.016941368576822984","23.0","3.0","112.0","10.0","0.0","0.0","184.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360208983387230211","https://twitter.com/LisaDeBruine/status/1360208983387230211","@MattBoisgontier @tomstafford This is an interesting green paper with recommendations for authors and publishers
https://t.co/xA2frFLhdb","2021-02-12 12:47 +0000","169.0","17.0","0.10059171597633136","0.0","0.0","2.0","1.0","13.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360118206950739968","https://twitter.com/LisaDeBruine/status/1360118206950739968","@tomstafford This is one of my goals on the Open Science Working group for APA, to make sure journals have policies about citing all research software, authors are educated on how to do it, and software creators are encouraged to make citation info prominent in their software.","2021-02-12 06:47 +0000","5900.0","90.0","0.015254237288135594","2.0","2.0","13.0","11.0","1.0","0.0","61.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360008364395294720","https://twitter.com/LisaDeBruine/status/1360008364395294720","@chrisdc77 @o_guest @JenniRodd @LorijnSZ fNIRS?","2021-02-11 23:30 +0000","307.0","3.0","0.009771986970684038","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360004459137499136","https://twitter.com/LisaDeBruine/status/1360004459137499136","@tladeras Nice idea! I recently marked 60 Rmd reports on data that students chose or simulated themselves and it’s not straightforward for all of them to choose a question their dataset can answer. I’ll keep the data consult idea in mind for next year.","2021-02-11 23:15 +0000","82.0","2.0","0.024390243902439025","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1360002659613351936","https://twitter.com/LisaDeBruine/status/1360002659613351936","@psmaldino I went to grad school because the alpha and the mail was in a different way it would have been nice for a couple hours and it would have been nice if I had a really nice idea. 

(This *almost* makes sense)","2021-02-11 23:07 +0000","516.0","2.0","0.003875968992248062","0.0","0.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359940538716282883","https://twitter.com/LisaDeBruine/status/1359940538716282883","Does anyone know a simple, clear primer for explaining how you can and can't interpret a 0.8 MDE (minimal detectable effect)? Especially one that is larger than the significant effect in your data. I'm trying to avoid the temptation to procrastinate marking by writing one myself.","2021-02-11 19:01 +0000","1663.0","10.0","0.006013229104028864","0.0","0.0","1.0","2.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359932988176424964","https://twitter.com/LisaDeBruine/status/1359932988176424964","@richarddmorey This is lovely!","2021-02-11 18:31 +0000","674.0","8.0","0.011869436201780416","0.0","0.0","1.0","0.0","1.0","0.0","5.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359886029692538884","https://twitter.com/LisaDeBruine/status/1359886029692538884","https://t.co/lEjGB0xLo8","2021-02-11 15:24 +0000","1578.0","1.0","6.337135614702154E-4","0.0","0.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359880969164107778","https://twitter.com/LisaDeBruine/status/1359880969164107778","@bmwiernik It's currently usable if your authors don't have common names and you don't mind typing them in one by one. It tells you if there are multiples, but I need to check the API to figure out how to display disambiguating info so you can choose the right one.","2021-02-11 15:04 +0000","149.0","2.0","0.013422818791946308","0.0","0.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359821812583059461","https://twitter.com/LisaDeBruine/status/1359821812583059461","(I'm marking essays today, so my brain just wants new coding projects.)","2021-02-11 11:09 +0000","1757.0","20.0","0.011383039271485486","0.0","2.0","6.0","1.0","0.0","0.0","11.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359821160934948865","https://twitter.com/LisaDeBruine/status/1359821160934948865","@simoncolumbus @jorgeapenas Definitely. Especially if you are one of only a few people who research that specific topic or use a specific method.","2021-02-11 11:06 +0000","231.0","6.0","0.025974025974025976","0.0","1.0","2.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359818066453032960","https://twitter.com/LisaDeBruine/status/1359818066453032960","I just looked up the ORCIDs of 15 authors in about 3 minutes using the authors tab of https://t.co/izPxqzf50D 

Should I add the ability to add multiple authors as a list and better handling of multiple matches, then make this a standalone app? Would this be of use to anyone?","2021-02-11 10:54 +0000","3812.0","109.0","0.028593913955928647","2.0","1.0","21.0","5.0","47.0","0.0","33.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359782200397467651","https://twitter.com/LisaDeBruine/status/1359782200397467651","@jaredlander @CMastication @hadleywickham @JennyBryan @stephhazlitt @monkmanmh col_types = cols() works get rid of the message and default to guess for all columns.","2021-02-11 08:31 +0000","69.0","5.0","0.07246376811594203","0.0","1.0","2.0","2.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359777316155633664","https://twitter.com/LisaDeBruine/status/1359777316155633664","@djnavarro So true. If studying your own demographic is a COI, why doesn’t this ever apply to straight white men?","2021-02-11 08:12 +0000","3039.0","115.0","0.03784139519578809","2.0","2.0","29.0","10.0","0.0","0.0","64.0","0.0","0","0","0","0","0","8","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359508376942698499","https://twitter.com/LisaDeBruine/status/1359508376942698499","I was just tidying some very old emails and found this (the alt text was fun to write :) https://t.co/ONFxBbbA4L","2021-02-10 14:23 +0000","2826.0","286.0","0.10120311394196745","0.0","0.0","12.0","7.0","0.0","0.0","14.0","0.0","0","0","0","0","0","253","253","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359413628206804992","https://twitter.com/LisaDeBruine/status/1359413628206804992","@ed_hagen @thomas_neitmann Nice! I’ll update my book with this. (What is MASS useful for besides mvrnorm?) https://t.co/GLRw9g7iYa","2021-02-10 08:07 +0000","2364.0","184.0","0.077834179357022","1.0","4.0","10.0","17.0","0.0","0.0","47.0","0.0","0","0","0","0","0","105","105","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359410156300296192","https://twitter.com/LisaDeBruine/status/1359410156300296192","@MDeBoltC 89 of the 100 spots are full, but there will be a waitlist (I’m sure not everyone will turn up) and if the waitlist is large, we’ll hold it again. Limits are because I’m not sure how many simultaneous users https://t.co/hK3ZvfrxQf can handle.","2021-02-10 07:53 +0000","290.0","1.0","0.0034482758620689655","0.0","0.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359283577813430274","https://twitter.com/LisaDeBruine/status/1359283577813430274","@davidrfeinberg I assume it’s about which wheels control drive and steering. I’m just astounded the logs were strong and straight enough. And the back tires were nearly flat!","2021-02-09 23:30 +0000","488.0","12.0","0.02459016393442623","0.0","1.0","4.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359277906132893698","https://twitter.com/LisaDeBruine/status/1359277906132893698","This is the most nerve-wracking thing I’ve ever seen. https://t.co/JR9gpTW8jD","2021-02-09 23:08 +0000","13412.0","287.0","0.02139874739039666","6.0","10.0","40.0","26.0","1.0","0.0","204.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359270723580284930","https://twitter.com/LisaDeBruine/status/1359270723580284930","@bjbalas I recently marked a ton of student code and found myself commenting a surprising number of times “this works but only by accident”.","2021-02-09 22:39 +0000","30.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359270085559517185","https://twitter.com/LisaDeBruine/status/1359270085559517185","@bjbalas I’m also not sure how to teach how you check that the answer you found (or arrived at yourself), is the right pattern versus something that produces the output you want right now, but not with other probable inputs. I learned it by being burned repeatedly by found code.","2021-02-09 22:36 +0000","42.0","6.0","0.14285714285714285","0.0","1.0","1.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359269012169891844","https://twitter.com/LisaDeBruine/status/1359269012169891844","@bjbalas Sometimes you just have to tell them they’re constrained to use a specific technique, like purrr map functions, even if it’s totally valid to use apply or for loops, so they can practice a skill you want them to build on.","2021-02-09 22:32 +0000","34.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359267007095447553","https://twitter.com/LisaDeBruine/status/1359267007095447553","@bjbalas You can ask them to test their understanding of the code they found by solving a conceptually similar problem that has enough of a difference to need some changes, like starting with the input in a different format. Or changing the variable names to fit a specific use case.","2021-02-09 22:24 +0000","77.0","15.0","0.19480519480519481","0.0","2.0","1.0","0.0","0.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359194953361022976","https://twitter.com/LisaDeBruine/status/1359194953361022976","We have a fair amount of activity on webmorph, mostly driven by approved users. Guest users usually just upload and process a few images. There are batch functions for transforming and averaging images, so you can process hundreds at a time. https://t.co/fgc8EZwE2X","2021-02-09 17:38 +0000","1381.0","12.0","0.008689355539464157","0.0","0.0","2.0","2.0","0.0","0.0","0.0","0.0","0","0","0","0","0","8","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359191750229827591","https://twitter.com/LisaDeBruine/status/1359191750229827591","For accounts with persistent storage, academic emails get approved automatically (email me if yours isn't recognised), but we don't have the resources to support a persistent account for everyone who wants one yet. https://t.co/uRuNqBommP","2021-02-09 17:25 +0000","1760.0","18.0","0.010227272727272727","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","15","15","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359191746098380803","https://twitter.com/LisaDeBruine/status/1359191746098380803","Some new @webmorph_org stats. Anyone can access the full capabilities of webmorph with a guest account, but storage is limited and not persistent after logout. You can always download your files between sessions, though. https://t.co/UMAEB0iWMi","2021-02-09 17:25 +0000","1098.0","10.0","0.009107468123861567","0.0","1.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","7","7","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359170525965262863","https://twitter.com/LisaDeBruine/status/1359170525965262863","I'm looking at the analytics for @webmorph_org today to see how many simultaneous users we can handle for the workshop (65 have already registered). WTF happened at 3am last Monday?!? All the light blue boxes are &lt; 25 users. https://t.co/oenSh25X2D","2021-02-09 16:01 +0000","2171.0","95.0","0.04375863657300783","0.0","1.0","1.0","9.0","0.0","0.0","24.0","0.0","0","0","0","0","0","60","60","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359162395646640132","https://twitter.com/LisaDeBruine/status/1359162395646640132","@WillBeischel Do you have any links to preprints or slides for those of us not attending SPSP? I have a few students who’d be really interested.","2021-02-09 15:29 +0000","534.0","18.0","0.033707865168539325","0.0","1.0","7.0","3.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1359159005294321669","https://twitter.com/LisaDeBruine/status/1359159005294321669","@DermotLynott I feel a really strong urge to tag @emilynordmann on this 😂","2021-02-09 15:15 +0000","3018.0","19.0","0.006295559973492379","0.0","1.0","2.0","13.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358917692166713345","https://twitter.com/LisaDeBruine/status/1358917692166713345","I love how much of my timeline today is Glaswegians taking photos of the snow. (I don’t have a pretty enough view to post them, but I’ve taken a few out the window myself today.) https://t.co/1Opr71NvUO","2021-02-08 23:16 +0000","2619.0","39.0","0.014891179839633447","0.0","0.0","12.0","5.0","0.0","0.0","22.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358826768564703233","https://twitter.com/LisaDeBruine/status/1358826768564703233","@ChelseaParlett @IrisHolzleitner will be in the context of the R package she's developing
https://t.co/Hh0io74TK5 https://t.co/IzXhz93trC","2021-02-08 17:15 +0000","249.0","8.0","0.0321285140562249","0.0","0.0","1.0","1.0","2.0","0.0","1.0","0.0","0","0","0","0","0","3","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358825138452639745","https://twitter.com/LisaDeBruine/status/1358825138452639745","Make images that smoothly transform from one image to another (yes, I know I messed up the dimension labels) https://t.co/CrgUAOHetR","2021-02-08 17:08 +0000","1888.0","100.0","0.05296610169491525","0.0","1.0","4.0","1.0","1.0","0.0","4.0","0.0","0","0","0","0","0","89","89","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358820742796869635","https://twitter.com/LisaDeBruine/status/1358820742796869635","@ChelseaParlett I'm old ;) The scrambling is based on code I first wrote in 2006. https://t.co/MHX3H8DpT1","2021-02-08 16:51 +0000","279.0","9.0","0.03225806451612903","0.0","1.0","2.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","45","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358819823728361474","https://twitter.com/LisaDeBruine/status/1358819823728361474","@ashtroid22 I constantly reference a book I wrote to remember how to do stuff. The actual main point of my blog is to impress future me with how much I used to know how to do.","2021-02-08 16:47 +0000","544.0","13.0","0.02389705882352941","1.0","0.0","7.0","2.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358818701382975488","https://twitter.com/LisaDeBruine/status/1358818701382975488","You can symmetrically scramble selected parts of the face https://t.co/A9qF5SZrrM","2021-02-08 16:43 +0000","2439.0","72.0","0.02952029520295203","0.0","2.0","5.0","2.0","0.0","0.0","12.0","0.0","0","0","0","0","0","51","51","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358816659763560448","https://twitter.com/LisaDeBruine/status/1358816659763560448","@tjmahr @rabaath It's making me twitch a little.","2021-02-08 16:35 +0000","1339.0","22.0","0.016430171769977596","0.0","0.0","8.0","9.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358804424928481280","https://twitter.com/LisaDeBruine/status/1358804424928481280","@joshtybur @VU_FGW @UMesplab @vaneisl https://t.co/5cXia5ni8p","2021-02-08 15:46 +0000","431.0","2.0","0.004640371229698376","0.0","0.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","76","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358804153334644736","https://twitter.com/LisaDeBruine/status/1358804153334644736","Do you want to make and analyse stimuli for face research in a reproducible way? We're giving a workshop March 1st on webmorph and @IrisHolzleitner's new R package, facefuns. It's free but registration is required. https://t.co/fb7QTZ0Wzx","2021-02-08 15:45 +0000","39688.0","528.0","0.013303769401330377","51.0","6.0","103.0","71.0","0.0","0.0","292.0","0.0","0","0","0","0","0","5","5","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358735816361656320","https://twitter.com/LisaDeBruine/status/1358735816361656320","@VerbingNouns I know, I know, but this is the main source of me delaying declining a review. And then I get a reminder and feel even more pressure to come up with good suggestions that aren't overburdening someone else and delay even further until the editor has to withdraw the request. 🤯","2021-02-08 11:13 +0000","744.0","8.0","0.010752688172043012","0.0","2.0","3.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358734802074161152","https://twitter.com/LisaDeBruine/status/1358734802074161152","@bg_farrar Nice. How are you getting the labels rotated? I just get this: https://t.co/1bL4kgpWFO","2021-02-08 11:09 +0000","175.0","13.0","0.07428571428571429","0.0","1.0","0.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","8","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358729641012453378","https://twitter.com/LisaDeBruine/status/1358729641012453378","@bg_farrar @CameronBrick To avoid that warning:

ggplot(df, aes(as.numeric(x))) +
  geom_density(trim = F) +
  scale_x_continuous(
    breaks = 1:5, 
    labels = LETTERS[1:5], 
    lim = c(0, 6)
  )

(I'm glad you'll be using bars, which are appropriate here, despite normally advocating #barbarplots ;)","2021-02-08 10:49 +0000","146.0","7.0","0.04794520547945205","0.0","1.0","1.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358722926573481986","https://twitter.com/LisaDeBruine/status/1358722926573481986","@bg_farrar @rogierK @CameronBrick The bars are WAY better for me. Maybe reduce the width of the bars?

geom_bar(width=.4)","2021-02-08 10:22 +0000","295.0","15.0","0.05084745762711865","0.0","1.0","6.0","0.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358722513048592386","https://twitter.com/LisaDeBruine/status/1358722513048592386","@rogierK @bg_farrar @CameronBrick The y axis in a bar plot IS the count, so directly translates to stacking all the ""dots"" on top of each other. He probably wants the y-axis to represent proportion, though, so set aes(x = xval, y = ..prop..)

https://t.co/kQLfUkNSvf","2021-02-08 10:21 +0000","165.0","12.0","0.07272727272727272","0.0","0.0","1.0","1.0","4.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358721535389876227","https://twitter.com/LisaDeBruine/status/1358721535389876227","@rogierK @bg_farrar @CameronBrick geom_bar() is really the best solution here","2021-02-08 10:17 +0000","217.0","9.0","0.041474654377880185","0.0","1.0","2.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358721428137406464","https://twitter.com/LisaDeBruine/status/1358721428137406464","@bg_farrar @CameronBrick I still think it's a bad plot type for discrete data, but if you're determined:

df = data.frame(x = factor(sample(LETTERS[1:5], 500, T)))

ggplot(df, aes(as.numeric(x))) +
  geom_density(trim = F) +
  xlim(0.67, 5.33) +
  scale_x_continuous(breaks = 1:5, labels = LETTERS[1:5])","2021-02-08 10:16 +0000","100.0","7.0","0.07","0.0","1.0","1.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358720309726175233","https://twitter.com/LisaDeBruine/status/1358720309726175233","@bg_farrar How are you setting up facet_grid to get the labels horizontal on the left?","2021-02-08 10:12 +0000","95.0","2.0","0.021052631578947368","0.0","1.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358717940946853891","https://twitter.com/LisaDeBruine/status/1358717940946853891","@bg_farrar library(ggplot2)

df &lt;- data.frame(
  x = sample(1:5, 1000, T)
)

ggplot(df, aes(x)) +
  geom_density(trim = FALSE) +
  xlim(0.67, 5.33)

But also I'd caution against representing categorical data with a density plot. It's misleading.","2021-02-08 10:02 +0000","64.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358716776801054720","https://twitter.com/LisaDeBruine/status/1358716776801054720","@bg_farrar trim = FALSE in the geom_density function and maybe also adjust the x-axis limits","2021-02-08 09:58 +0000","291.0","10.0","0.03436426116838488","0.0","2.0","1.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358515457880424448","https://twitter.com/LisaDeBruine/status/1358515457880424448","@richarddmorey I had an almanac and a notebook next to the computer for this game. https://t.co/b3DZkRMB5R","2021-02-07 20:38 +0000","1588.0","82.0","0.05163727959697733","0.0","1.0","9.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","68","68","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358511024907952133","https://twitter.com/LisaDeBruine/status/1358511024907952133","@MattCrump_ OMG I love this. What's the app?","2021-02-07 20:20 +0000","266.0","1.0","0.0037593984962406013","0.0","0.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358508219761573897","https://twitter.com/LisaDeBruine/status/1358508219761573897","@samclifford @cantabile Do you have a reliable way to suppress smart quotes in places where they should be suppressed but used where they should be used? I turn them off entirely for bookdown because I can't get them to go away in every circumstance.","2021-02-07 20:09 +0000","70.0","4.0","0.05714285714285714","0.0","1.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358475449622548481","https://twitter.com/LisaDeBruine/status/1358475449622548481","@heatherklus How about some lesbian necromancers and skeletons in space?

Both books in this trilogy start a little slow (the third is due in 2022), but the storytelling is so intricate and the payoff is worth it. 

I might start them again now ☠️ https://t.co/jMPPT3a7oB","2021-02-07 17:59 +0000","531.0","36.0","0.06779661016949153","0.0","1.0","8.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","26","26","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358365045751701504","https://twitter.com/LisaDeBruine/status/1358365045751701504","@DrGBuckingham @Don_lyall I just do a general search and replace for “our studio” and “our norm”.","2021-02-07 10:40 +0000","165.0","2.0","0.012121212121212121","0.0","1.0","0.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358360665912725506","https://twitter.com/LisaDeBruine/status/1358360665912725506","@DrGBuckingham The tools in YouTube for editing captions are great, and you can download them in several formats. For a Mac, I really like HandBrake to add the captions. Embedded subtitles are more accessible than hard burn.","2021-02-07 10:23 +0000","905.0","9.0","0.009944751381215469","0.0","2.0","2.0","0.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358358515425964038","https://twitter.com/LisaDeBruine/status/1358358515425964038","@Don_lyall @DrGBuckingham The auto is hilariously bad at statistical and coding jargon, in my experience. It’s a really useful first pass, but definitely needs thorough proofreading.","2021-02-07 10:14 +0000","148.0","3.0","0.02027027027027027","0.0","1.0","0.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358178154783850496","https://twitter.com/LisaDeBruine/status/1358178154783850496","@kashdogcicero @SuryaGanguli Very cool! But why is it case sensitive?","2021-02-06 22:18 +0000","188.0","11.0","0.05851063829787234","0.0","0.0","0.0","1.0","0.0","0.0","10.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358177992963469314","https://twitter.com/LisaDeBruine/status/1358177992963469314","@DrGBuckingham It’s weirdly case sensitive. I’m 83 for Lisadebruine and 116 for LisaDeBruine.","2021-02-06 22:17 +0000","554.0","8.0","0.01444043321299639","0.0","1.0","2.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358114684822581251","https://twitter.com/LisaDeBruine/status/1358114684822581251","The secret vignette for the new distribution functions is at https://t.co/aFzSScKJVa in case anyone is interested.","2021-02-06 18:05 +0000","1135.0","15.0","0.013215859030837005","0.0","0.0","4.0","1.0","10.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358113459548925954","https://twitter.com/LisaDeBruine/status/1358113459548925954","I’m so thankful for #testhat. Today I fixed some annoying display issues and expanded the distribution conversion functions in faux (sending to CRAN soon) but would have inadvertently borked some important functions if I didn’t have tests.","2021-02-06 18:00 +0000","2619.0","44.0","0.016800305460099276","1.0","1.0","10.0","4.0","0.0","5.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1358085267144527872","https://twitter.com/LisaDeBruine/status/1358085267144527872","@JoshSPayne Thanks! I sent it to her last night :)","2021-02-06 16:08 +0000","15.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357995300712030209","https://twitter.com/LisaDeBruine/status/1357995300712030209","@DrGBuckingham How does the kick drum work?","2021-02-06 10:11 +0000","447.0","5.0","0.011185682326621925","0.0","1.0","0.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357994978161614848","https://twitter.com/LisaDeBruine/status/1357994978161614848","@simoncolumbus @richarddmorey @djnavarro That was just my sense check. I looked at the difference in ranking for the (on average) three top and bottom ranked items to see if people were using the scale backwards, which was surprisingly common. It’s a terrible scale for a ton of other reasons, though, too.","2021-02-06 10:10 +0000","175.0","15.0","0.08571428571428572","0.0","0.0","1.0","2.0","0.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357986566153601024","https://twitter.com/LisaDeBruine/status/1357986566153601024","@richarddmorey @djnavarro I had to exclude a subset of participants from the Lieberman moral judgments scale because they consistently ranked things like speeding and public drunkenness as more morally wrong than murder. https://t.co/npwlWdbPr2","2021-02-06 09:36 +0000","2257.0","370.0","0.16393442622950818","1.0","2.0","7.0","2.0","1.0","0.0","116.0","0.0","0","0","0","0","0","241","241","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357832794546798598","https://twitter.com/LisaDeBruine/status/1357832794546798598","Not the point of this post, but I love that there is a tiny but visible extra hump at the opposite side for most of these, which I’m assuming is people who got confused about the direction of the scale. https://t.co/8BLarhpurL","2021-02-05 23:25 +0000","6670.0","116.0","0.017391304347826087","3.0","0.0","42.0","7.0","2.0","0.0","58.0","0.0","0","0","0","0","0","4","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357724001540460545","https://twitter.com/LisaDeBruine/status/1357724001540460545","For the first journal club on Friday, Feb 26 (14:00 GMT), we will discuss Systemic inequalities for LGBTQ professionals in STEM by @CechErin &amp; @Tom_Waidzunas  https://t.co/PgrdCKSLQX https://t.co/RrTyldd4cr","2021-02-05 16:13 +0000","7366.0","38.0","0.005158837903882704","3.0","0.0","2.0","6.0","9.0","0.0","18.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357722218105630726","https://twitter.com/LisaDeBruine/status/1357722218105630726","@EPronizius @hansijzerman @LIPPC2S @UGrenobleAlpes @dom_muller @cedricbatailler @Alessan09558632 @psforscher @AdeyemiAdetula1 @OlivierDujols @An_an_iasz @AuroreGaboriaud @maebraud @nataliadutrapsy No, but I’m currently talking with someone about offering this as a semi-regular online workshop (over 3 half-days, so not as rushed as today’s workshop). It would be useful to know if there’s much desire for that.","2021-02-05 16:06 +0000","595.0","52.0","0.08739495798319327","0.0","5.0","15.0","7.0","0.0","0.0","24.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357720271369732098","https://twitter.com/LisaDeBruine/status/1357720271369732098","Thanks for inviting me! I really enjoyed teaching this workshop today. I know it was a challenging 4 hours to go from factorial designs in faux to cross-classified data with random intercepts and slopes for mixed effects models. https://t.co/tboOR6K1wx","2021-02-05 15:58 +0000","2821.0","27.0","0.00957107408720312","2.0","0.0","12.0","5.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357717269321814016","https://twitter.com/LisaDeBruine/status/1357717269321814016","This is a serious challenge for any diverse team. It’s worth putting effort into really nailing down how you plan to interpret all possible patterns of results before you have data. https://t.co/gIBAvhAALi","2021-02-05 15:46 +0000","2832.0","22.0","0.007768361581920904","0.0","2.0","5.0","0.0","0.0","0.0","15.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357509532264640513","https://twitter.com/LisaDeBruine/status/1357509532264640513","@TheRealRynnstar https://t.co/uDQM5IPf71","2021-02-05 02:01 +0000","801.0","6.0","0.00749063670411985","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","275","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357081007254552579","https://twitter.com/LisaDeBruine/status/1357081007254552579","@JimGrange @DrGBuckingham It’s still under development, but the Data tab of this app has a section to simulate factorial designs. You can download the data and ignore the rest of the app functions. 

https://t.co/izPxqzf50D","2021-02-03 21:38 +0000","220.0","17.0","0.07727272727272727","0.0","1.0","4.0","0.0","12.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357030321875779585","https://twitter.com/LisaDeBruine/status/1357030321875779585","@rskudesia @bmwiernik @drboothroyd @aggieerin This is what I was thinking of. Not sure how much it touches on multilevel stuff. https://t.co/udtSrXIqAm","2021-02-03 18:16 +0000","105.0","7.0","0.06666666666666667","0.0","1.0","3.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1357029742285893632","https://twitter.com/LisaDeBruine/status/1357029742285893632","@rskudesia @bmwiernik @drboothroyd I think @aggieerin has a bunch of lavaan resources. 

https://t.co/lTNFcLsAUN","2021-02-03 18:14 +0000","68.0","6.0","0.08823529411764706","0.0","1.0","2.0","0.0","2.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356946698505961477","https://twitter.com/LisaDeBruine/status/1356946698505961477","We're going to live-code a buzzfeed-style quiz #shiny app at the @UofGPsychology Coding Club today at 14:00 (UK). We'll be starting with this template https://t.co/eHXMvIafXP

Message me within the next hour (by 13:45) if you want the link.","2021-02-03 12:44 +0000","3453.0","68.0","0.019693020561830293","4.0","0.0","3.0","8.0","22.0","0.0","31.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356930563354034176","https://twitter.com/LisaDeBruine/status/1356930563354034176","(FYI: the output looks like this) https://t.co/HueEmFf8yQ","2021-02-03 11:40 +0000","1528.0","80.0","0.05235602094240838","0.0","1.0","1.0","0.0","0.0","0.0","16.0","0.0","0","0","0","0","0","62","62","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356927843289223169","https://twitter.com/LisaDeBruine/status/1356927843289223169","library(tidyverse)

X &lt;- iris[, 1:4] # numeric columns

pairs &lt;- crossing(a = names(X), b = names(X)) %&gt;%
  filter(a &lt; b) %&gt;% # remove dupes
  mutate(k = map2(a, b, function(a, b) {
    cor.test(X[[a]], X[[b]]) %&gt;% unlist()
  })) %&gt;%
  unnest_wider(k) %&gt;%
  type_convert()","2021-02-03 11:29 +0000","1731.0","10.0","0.005777007510109763","0.0","1.0","1.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","2","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356927841821216769","https://twitter.com/LisaDeBruine/status/1356927841821216769","I'm trying to make an example of how to run any analysis on every pair of columns in a data table efficiently. Is there a better pattern than below? I don't get why I have to unlist the output and type convert it; why can't unnest handle a list of lists? #tidyverse #rstats","2021-02-03 11:29 +0000","3802.0","142.0","0.03734876380852183","3.0","1.0","2.0","4.0","0.0","0.0","123.0","0.0","0","0","0","0","0","9","9","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356681720456765441","https://twitter.com/LisaDeBruine/status/1356681720456765441","@oscar_olvera100 @bmwiernik I love the overthinking here :) The context is I’m giving an intro to simulations Friday and will start with how to simulate data using means, SDs and correlations for groups (which maps onto how people think about t-tests and anovas). Then the glm version to ease into lmem.","2021-02-02 19:11 +0000","254.0","9.0","0.03543307086614173","0.0","1.0","2.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356666298604879895","https://twitter.com/LisaDeBruine/status/1356666298604879895","@janhove Awesome! I love this bit :)

“Any non-tautological relationship is much more likely to be ever so slightly nonlinear than it is to be perfectly linear, ...: There are just so many more ways in which a relationship can be nonlinear than it can be linear.”","2021-02-02 18:10 +0000","1098.0","24.0","0.02185792349726776","1.0","1.0","1.0","7.0","6.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356645214245580800","https://twitter.com/LisaDeBruine/status/1356645214245580800","@richarddmorey @Corey_Yanofsky Yeah, I need to strike a balance that stops students from doing KS tests on their DVs and worrying that they aren't normal, but not overwhelming them with new info to worry about at the analysis stage of their dissertations.","2021-02-02 16:46 +0000","367.0","2.0","0.005449591280653951","0.0","0.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356615077026291725","https://twitter.com/LisaDeBruine/status/1356615077026291725","@patilindrajeets @dsquintana Nice! That looks really thorough. A little overwhelming for some of them, but definitely a resource I'll recommend for those who are ready.","2021-02-02 14:46 +0000","973.0","17.0","0.017471736896197326","0.0","1.0","5.0","2.0","1.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356610572469608458","https://twitter.com/LisaDeBruine/status/1356610572469608458","Feedback is very welcome. I'm especially concerned about hitting the right balance of accurate but not overly complex. The target audience here is undergrads who are using S-W tests on their DV and predictors to explain why not to and what to do instead.","2021-02-02 14:28 +0000","3027.0","28.0","0.009250082590023126","0.0","1.0","4.0","9.0","1.0","0.0","13.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356610570271784961","https://twitter.com/LisaDeBruine/status/1356610570271784961","Its that time of year again when dissertation students start analysing their data and worrying about normality. I've written a blog post to explain why only the normality of the residuals matters and how to visualise it in #rstats. 

https://t.co/AAvwKwWOa9","2021-02-02 14:28 +0000","71580.0","4454.0","0.06222408493992736","100.0","7.0","402.0","328.0","1231.0","4.0","2368.0","0.0","0","0","0","0","0","14","14","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356608981020647427","https://twitter.com/LisaDeBruine/status/1356608981020647427","@bmwiernik Thanks. The DGP-aware method is definitely the better one (or really the only possible way) for multilevel data, but sometimes the DGP-blind method is easier given the data parameters you have access to.","2021-02-02 14:22 +0000","289.0","6.0","0.020761245674740483","0.0","1.0","3.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356544334074679300","https://twitter.com/LisaDeBruine/status/1356544334074679300","Are there terms for simulating data based on descriptives (e.g., M, SD and r) versus model parameters (e.g. fixed effects and SDs for random effects).

I'm trying to name the two approaches used in this tutorial https://t.co/8pN84cYpyT and describe what faux does.","2021-02-02 10:05 +0000","5331.0","150.0","0.028137310073157007","2.0","2.0","16.0","7.0","37.0","0.0","86.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356295968837279750","https://twitter.com/LisaDeBruine/status/1356295968837279750","Such a great idea by @pimpmymemory to set time management and study skills tasks as the first few weeks’ activities. https://t.co/yn0X1a7FMA","2021-02-01 17:38 +0000","3004.0","22.0","0.007323568575233023","1.0","0.0","7.0","12.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1356174819633590275","https://twitter.com/LisaDeBruine/status/1356174819633590275","@BeccaEHarrison That sounds amazing. If you get permission from students, I’m sure lots of people here would love to see them (I know I would).","2021-02-01 09:37 +0000","560.0","10.0","0.017857142857142856","0.0","1.0","1.0","6.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
