"Tweet id","Tweet permalink","Tweet text","time","impressions","engagements","engagement rate","retweets","replies","likes","user profile clicks","url clicks","hashtag clicks","detail expands","permalink clicks","app opens","app installs","follows","email tweet","dial phone","media views","media engagements","promoted impressions","promoted engagements","promoted engagement rate","promoted retweets","promoted replies","promoted likes","promoted user profile clicks","promoted url clicks","promoted hashtag clicks","promoted detail expands","promoted permalink clicks","promoted app opens","promoted app installs","promoted follows","promoted email tweet","promoted dial phone","promoted media views","promoted media engagements"
"1410344350421237762","https://twitter.com/LisaDeBruine/status/1410344350421237762","@joachimgoedhart @emilynordmann @McAleerP @PatersonHelena @wtoivo1 Oh no, don’t give us any more ideas for this. It already has an associated R package with functions to facilitate raincloud plots. 

https://t.co/1ZHWNB2KtE","2021-06-30 21:07 +0000","155.0","14.0","0.09032258064516129","0.0","0.0","2.0","0.0","9.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410255054544805888","https://twitter.com/LisaDeBruine/status/1410255054544805888","@cantabile https://t.co/9BYZPRAvJo","2021-06-30 15:13 +0000","126.0","2.0","0.015873015873015872","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410201301355479042","https://twitter.com/LisaDeBruine/status/1410201301355479042","@cassyld Yup. I was flying 4-6 times a year pre-pandemic and will now not consider more than 1 flight per year and am committing to take the train/ferry anywhere in the UK and  Europe.","2021-06-30 11:39 +0000","1373.0","34.0","0.024763292061179897","0.0","0.0","20.0","12.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410170586819710978","https://twitter.com/LisaDeBruine/status/1410170586819710978","I've been meaning to learn about SimDesignR for awhile now. I'm really looking forward to this @sim_school session today! (14:00 BST)
https://t.co/0fzCFtL0PD","2021-06-30 09:37 +0000","2192.0","56.0","0.025547445255474453","2.0","0.0","13.0","6.0","25.0","0.0","10.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410153102863392771","https://twitter.com/LisaDeBruine/status/1410153102863392771","I see it's already been filed as an issue and is a result of using csslint, which hasn't kept up with CSS standard changes. 

https://t.co/Xu8jgcLPdg","2021-06-30 08:27 +0000","1477.0","13.0","0.008801624915368992","0.0","1.0","4.0","2.0","3.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410151523703721989","https://twitter.com/LisaDeBruine/status/1410151523703721989","Please @rstudio will you stop marking variable definitions as malformed in CSS files? It's so useful to be able to define variables for colours. And I don't like having to tell students to ignore IDE warnings; it sets bad habits. https://t.co/nWBPJPgmmJ","2021-06-30 08:21 +0000","3758.0","146.0","0.038850452368281004","0.0","2.0","10.0","9.0","0.0","0.0","75.0","0.0","0","0","0","0","0","50","50","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410149423599001602","https://twitter.com/LisaDeBruine/status/1410149423599001602","@rlmcelreath I use “data” as shorthand for both “the data points” (are) and “the dataset” (is). And I think that’s totally fine and fully understandable by readers in almost every situation.","2021-06-30 08:13 +0000","1308.0","26.0","0.019877675840978593","0.0","0.0","22.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410148390139269120","https://twitter.com/LisaDeBruine/status/1410148390139269120","@RevoltKenya @FredrikHedenus @DegenRolf It is *exceedingly* irresponsible to publish a study concluding that a marginalised group is more narcissistic, psychopathic, and Machiavellian based on sampling that cannot possibly be representative and questionable analyses.","2021-06-30 08:09 +0000","238.0","28.0","0.11764705882352941","1.0","2.0","4.0","5.0","0.0","0.0","16.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410125992442597377","https://twitter.com/LisaDeBruine/status/1410125992442597377","@FredrikHedenus @DegenRolf In addition, several cell Ns are tiny (hidden by not reporting crossed category Ns). Given the nature of the data, analyses should nest subjects by country, but were instead a series of one-way ANOVAs. The prevalence of p ~ .05 suggests capitalising on analytic flexibility. https://t.co/kQfp6RRPWK","2021-06-30 06:40 +0000","1044.0","36.0","0.034482758620689655","0.0","3.0","5.0","11.0","0.0","0.0","17.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1410012057735417861","https://twitter.com/LisaDeBruine/status/1410012057735417861","@_nazeefatima Most of us are pretty overwhelmed with email and a gentle nudge can help overcome the feeling that you need to put more effort into a response the longer you’d let it wait, which leads to even more delays and more anxiety…","2021-06-29 23:07 +0000","38.0","3.0","0.07894736842105263","0.0","0.0","0.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409931293652140036","https://twitter.com/LisaDeBruine/status/1409931293652140036","@coles_nicholas_ https://t.co/3TON9UfdFV","2021-06-29 17:46 +0000","1236.0","54.0","0.043689320388349516","0.0","1.0","8.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","630","39","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409930924733632518","https://twitter.com/LisaDeBruine/status/1409930924733632518","@BertieArbon @bmwiernik I’m finding it a bit more applicable to the more object oriented languages I code in than R, but I’m also finding things to apply to R.","2021-06-29 17:45 +0000","739.0","8.0","0.010825439783491205","0.0","2.0","2.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409926955869388800","https://twitter.com/LisaDeBruine/status/1409926955869388800","@BertieArbon @bmwiernik “The ideal number of arguments for a function is zero (niladic). Next comes 1 (monadic), followed closely by 2 (dyadic). 3 arguments (triadic) should be avoided where possible. More than 3 (polyadic) requires very special justification—and then shouldn’t be used anyway.” https://t.co/fr0mRlywXP","2021-06-29 17:29 +0000","588.0","26.0","0.04421768707482993","1.0","1.0","4.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","223","13","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409904388030750723","https://twitter.com/LisaDeBruine/status/1409904388030750723","@seanpmackinnon I see what you mean. Is this some sort of sign that something else is wrong with your model then?","2021-06-29 15:59 +0000","67.0","3.0","0.04477611940298507","0.0","1.0","1.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409903821447380992","https://twitter.com/LisaDeBruine/status/1409903821447380992","I don’t remember who suggested I read Robert Martin’s Clean Code (@bmwiernik?), but I am loving it. 

“The first rule of functions is that they should be small. The second rule of functions is that they should be smaller than that.”","2021-06-29 15:57 +0000","16062.0","395.0","0.02459220520483128","10.0","3.0","74.0","50.0","1.0","0.0","249.0","0.0","0","0","0","0","0","8","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409887770886168577","https://twitter.com/LisaDeBruine/status/1409887770886168577","@seanpmackinnon …but doesn’t removing, say, the random slope for condition by subject, treat each trial as an independent observation, leading to pseudo replication?","2021-06-29 14:53 +0000","76.0","6.0","0.07894736842105263","0.0","1.0","1.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409887395865055241","https://twitter.com/LisaDeBruine/status/1409887395865055241","@seanpmackinnon … and random slopes of 0 indicates the difference between mean responses for conditions A and B doesn’t vary by subject (maybe plausible if there is no effect?) or by item (again, more plausible for really constrained stimuli)…","2021-06-29 14:52 +0000","67.0","1.0","0.014925373134328358","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409885938638000131","https://twitter.com/LisaDeBruine/status/1409885938638000131","@seanpmackinnon …so if the random intercept for S is 0, that means there was no variation in subjects’ mean response (usually implausible), and a random intercept for I of 0 means all items elicit the same mean response (more plausible if items are carefully selected to be homogeneous)…","2021-06-29 14:46 +0000","74.0","1.0","0.013513513513513514","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409885188180557827","https://twitter.com/LisaDeBruine/status/1409885188180557827","@seanpmackinnon What does it *mean* for a random effect to actually be 0? Imagine a cross-classified design where subjects respond to items in 2 conditions. If condition is within S and within I, you have 2 random intercepts and 2 random slopes…","2021-06-29 14:43 +0000","108.0","1.0","0.009259259259259259","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409831799866511360","https://twitter.com/LisaDeBruine/status/1409831799866511360","I feel like removing random slopes indicated by the exp design is like testing if data for a paired-samples t-test are significantly correlated and doing an independent-samples t-test if they aren’t. If r=0 it might suggest problems with your data, but doesn’t change the design.","2021-06-29 11:11 +0000","2614.0","73.0","0.0279265493496557","1.0","3.0","18.0","4.0","0.0","0.0","43.0","0.0","0","0","0","0","0","4","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409828449158578183","https://twitter.com/LisaDeBruine/status/1409828449158578183","This is a really clear explanation with simulations showing how different relationships among an intervention, DV, and control variable measured post-treatment can bias your estimates in drastically different ways. https://t.co/9maRUsyTsW","2021-06-29 10:57 +0000","3121.0","37.0","0.011855174623518103","1.0","1.0","13.0","2.0","0.0","0.0","20.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409825127995432960","https://twitter.com/LisaDeBruine/status/1409825127995432960","“Trust the full model – the random effects structure should be determined by your design rather than by your data.” https://t.co/1HxS8rEQeW https://t.co/dpGoT9LnRH","2021-06-29 10:44 +0000","9086.0","312.0","0.034338542813119086","5.0","3.0","29.0","9.0","0.0","0.0","114.0","0.0","0","0","0","0","0","152","152","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409811053194657793","https://twitter.com/LisaDeBruine/status/1409811053194657793","@PsyTechOli Which is reported in full in the ms depends on prereg and how much the new analyses differ. I’d always report prereg analyses in the paper along with better analyses and their justification. If robustness checks give the same conclusion, I just summarise briefly in the ms.","2021-06-29 09:48 +0000","135.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409810031403483139","https://twitter.com/LisaDeBruine/status/1409810031403483139","@PsyTechOli If you can make a convincing argument that the outliers are probably not explainable under the model being tested, and how to identify such values (usually a simple SD cutoff isn’t the best way), then I’d recommend also reporting analyses with these values removed.","2021-06-29 09:44 +0000","145.0","1.0","0.006896551724137931","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409809344783433731","https://twitter.com/LisaDeBruine/status/1409809344783433731","@PsyTechOli What are the possible explanations for the outliers? Are they physiologically implausible (like heights over 8’), likely to represent a different process (RTs of 10K ms when the median is &lt;800ms), or around the expected number of extreme values given the sample size?","2021-06-29 09:41 +0000","89.0","7.0","0.07865168539325842","0.0","1.0","1.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409765998828437506","https://twitter.com/LisaDeBruine/status/1409765998828437506","@SolomonKurz A good power analysis needs to justify the parameters used or give power curves over a range. But we should be mindful that a single power calculation can take hours for complex models (especially ordinal LMEM), and a sensitivity power analysis can require dozens or more.","2021-06-29 06:49 +0000","447.0","7.0","0.015659955257270694","0.0","2.0","1.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409764430578081793","https://twitter.com/LisaDeBruine/status/1409764430578081793","@SolomonKurz A surprising number of papers still report something like “power analyses show N participants were required for P% power” without clearly specifying the term, effect size, variance parameters, and within-subject correlations used in the calculation.","2021-06-29 06:43 +0000","292.0","10.0","0.03424657534246575","0.0","1.0","2.0","2.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409763672747040770","https://twitter.com/LisaDeBruine/status/1409763672747040770","@SolomonKurz Very few researchers have enough info about the random effects variance to run an informative power analysis before collecting data (unless they have a pilot study). Are you asking for a sensitivity power analysis?","2021-06-29 06:40 +0000","910.0","34.0","0.03736263736263736","0.0","0.0","20.0","9.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409540932555493387","https://twitter.com/LisaDeBruine/status/1409540932555493387","Is it fair to refuse to fill out image permission forms for commercial books when I've made the face images and #webmorph software freely available CC-BY? I'd thought one of the benefits of open access resources is that I don't have to be pestered with this.","2021-06-28 15:55 +0000","2988.0","78.0","0.02610441767068273","0.0","1.0","9.0","6.0","0.0","2.0","60.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409514514635231236","https://twitter.com/LisaDeBruine/status/1409514514635231236","Resources for brms:

https://t.co/0o353Miu1b (book)
https://t.co/pgLiTypoC3 (code)","2021-06-28 14:10 +0000","1381.0","26.0","0.01882693700217234","0.0","0.0","2.0","0.0","18.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409497961185300491","https://twitter.com/LisaDeBruine/status/1409497961185300491","I’m really enjoying today’s @sim_school talk by @xmjandrews on posterior/prior predictive checks in Bayesian modelling.","2021-06-28 13:04 +0000","4505.0","108.0","0.02397336293007769","2.0","2.0","20.0","32.0","3.0","0.0","49.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409146815337963526","https://twitter.com/LisaDeBruine/status/1409146815337963526","@ethantenison We have a tidyverse first philosophy at #psyTeachR because of an emphasis on data wrangling as a skill normally overlooked by methods classes in psych. But of course we include elements of base R so they can understand others’ code. 

https://t.co/FTajzu4LNb","2021-06-27 13:49 +0000","1267.0","56.0","0.04419889502762431","2.0","0.0","17.0","5.0","22.0","0.0","10.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1409142293626507275","https://twitter.com/LisaDeBruine/status/1409142293626507275","@cantabile https://t.co/cLeOyhsIi7","2021-06-27 13:31 +0000","485.0","9.0","0.018556701030927835","0.0","0.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","166","6","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408812067637891079","https://twitter.com/LisaDeBruine/status/1408812067637891079","@emilynordmann @1eigh_c1ark In the interests of keeping @emilynordmann alive to work on the revisions of this paper, maybe an extra drink for every 100 downloads after 1000? We’re already at 1022 🍻🥃🍹🍸","2021-06-26 15:39 +0000","190.0","5.0","0.02631578947368421","0.0","0.0","3.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408727076182630406","https://twitter.com/LisaDeBruine/status/1408727076182630406","It’s 63 pages long, but that includes 43 half-page figures and lots of step-by-step code blocks, so don’t be intimidated by that. https://t.co/j6ntDfBwai","2021-06-26 10:01 +0000","2339.0","127.0","0.0542967079948696","0.0","0.0","13.0","4.0","0.0","0.0","23.0","0.0","0","0","0","0","0","87","87","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408725653785042945","https://twitter.com/LisaDeBruine/status/1408725653785042945","So @emilynordmann said we could have celebratory drinks after this preprint was downloaded 1000 times. There’s less than 50 to go, so if you’ve ever wanted a gentle intro to #rstats through #dataviz, I encourage you to download it 😉🥂

https://t.co/L3Bl1kzpBQ","2021-06-26 09:55 +0000","37129.0","1171.0","0.03153868943413504","49.0","7.0","185.0","69.0","564.0","3.0","289.0","0.0","0","0","0","0","0","5","5","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408707246154993671","https://twitter.com/LisaDeBruine/status/1408707246154993671","@MicheleNuijten @paulvanderlaken Congratulations!","2021-06-26 08:42 +0000","486.0","2.0","0.00411522633744856","0.0","0.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408093477993422852","https://twitter.com/LisaDeBruine/status/1408093477993422852","@babeheim @LottyBrand If you're not going to use Rmd, then that's way preferable to setting wd in the script!!","2021-06-24 16:03 +0000","218.0","4.0","0.01834862385321101","0.0","0.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408088916150865926","https://twitter.com/LisaDeBruine/status/1408088916150865926","#SIPS2021 session on Large-Scale Psychological Science. Get involved in the @PsySciAcc 

https://t.co/SEKHnSI5G9","2021-06-24 15:45 +0000","4792.0","69.0","0.014398998330550918","8.0","0.0","15.0","10.0","21.0","1.0","14.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408084778944012292","https://twitter.com/LisaDeBruine/status/1408084778944012292","@babeheim @LottyBrand Oh, I used to admire you, Bret ;)","2021-06-24 15:29 +0000","269.0","11.0","0.040892193308550186","0.0","1.0","4.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408077747205951493","https://twitter.com/LisaDeBruine/status/1408077747205951493","@lakens @seriousstats @maltoesermalte I'm working on new functions that are better suited for mixed effects designs (just in the dev version for now). 

https://t.co/VXApEKvAdg","2021-06-24 15:01 +0000","535.0","10.0","0.018691588785046728","0.0","0.0","5.0","1.0","3.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408050126564831232","https://twitter.com/LisaDeBruine/status/1408050126564831232","What parts of data management have you received formal training in?

* Data management plan
* Data collection
* Data storage
* Data cleaning
* Data analysis
* Data sharing
* Locating existing data https://t.co/1TkDu1a5jC","2021-06-24 13:11 +0000","1947.0","27.0","0.01386748844375963","2.0","0.0","5.0","0.0","0.0","0.0","12.0","0.0","0","0","0","0","0","8","8","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408049464309342210","https://twitter.com/LisaDeBruine/status/1408049464309342210","#SIPS2021 Data Management Hackathon by @SchiavoneSays @AnnaWysocki3 and colleagues

https://t.co/rSzqriAIAb","2021-06-24 13:08 +0000","2589.0","22.0","0.008497489378138278","0.0","1.0","7.0","0.0","0.0","0.0","14.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408044661529268233","https://twitter.com/LisaDeBruine/status/1408044661529268233","https://t.co/VAKZUp6sGK","2021-06-24 12:49 +0000","1873.0","9.0","0.004805125467164976","0.0","0.0","2.0","0.0","1.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408044021759590400","https://twitter.com/LisaDeBruine/status/1408044021759590400","Nice #sips2021 lightning talk by @juliafstrand on developing a lab culture that normalises looking for mistakes. What processes do you use in your lab to catch errors?

https://t.co/kOCM9PxYQA","2021-06-24 12:47 +0000","8446.0","127.0","0.015036703765095904","4.0","1.0","25.0","9.0","32.0","1.0","55.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408043075222609927","https://twitter.com/LisaDeBruine/status/1408043075222609927","I learned about a new power #rstats package today at #SIPS2021 lightning talks, @chrisaberson’s pwr2ppl, and look forward to learning more about it!

https://t.co/75xVz0i2wc","2021-06-24 12:43 +0000","5143.0","103.0","0.02002722146607039","9.0","2.0","26.0","9.0","40.0","1.0","16.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408014285440159745","https://twitter.com/LisaDeBruine/status/1408014285440159745","The R package LexOps is great for matching stimuli on one or more parameters. @JackEdTaylor is an amazing #rstats coder who is also looking for a postdoc (I’d 100% hire him if I had a relevant grant.)

https://t.co/6vlhJDimHe","2021-06-24 10:48 +0000","3782.0","76.0","0.02009518773135907","8.0","1.0","10.0","13.0","26.0","0.0","18.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408005925554823174","https://twitter.com/LisaDeBruine/status/1408005925554823174","Matching stimuli in different conditions just by checking that their parameters aren't statistically significantly different is ""conceptually misguided and pragmatically useless"" (Sassenhagen &amp; Alday, 2016)

https://t.co/Vj0pkQPxT5","2021-06-24 10:15 +0000","2603.0","64.0","0.024587014982712256","3.0","1.0","5.0","2.0","30.0","0.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1408004799690383360","https://twitter.com/LisaDeBruine/status/1408004799690383360","I'm at a fab #SIPS2021 session by @JackEdTaylor on reproducible stimulus matching. 

https://t.co/vLIyFZXemW","2021-06-24 10:11 +0000","8557.0","133.0","0.015542830431225898","5.0","1.0","17.0","30.0","27.0","2.0","51.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407974162510057473","https://twitter.com/LisaDeBruine/status/1407974162510057473","@CarolynBot @victorshiramizu This one is ripe for stimulating new stats/methods memes.","2021-06-24 08:09 +0000","207.0","3.0","0.014492753623188406","0.0","0.0","0.0","2.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407961217629626374","https://twitter.com/LisaDeBruine/status/1407961217629626374","This is just beautiful 🦇 science https://t.co/IL7TeAetUt","2021-06-24 07:18 +0000","9183.0","62.0","0.006751606228901231","7.0","1.0","18.0","5.0","0.0","0.0","31.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407824107031367682","https://twitter.com/LisaDeBruine/status/1407824107031367682","@vboykis I’m never sure if academic research counts as DS, but I weekly work with R, PHP, JavaScript, SQL, and CSS/HTML (which I probably wouldn’t count as languages). I work with Java, Python, and Julia less regularly.","2021-06-23 22:13 +0000","1144.0","14.0","0.012237762237762238","0.0","0.0","2.0","10.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407822798710579203","https://twitter.com/LisaDeBruine/status/1407822798710579203","@aggieerin Until very recently, I thought this emoji was a wee guy sticking two middle fingers up 😤 (which would also not be inappropriate here)","2021-06-23 22:08 +0000","322.0","11.0","0.034161490683229816","0.0","0.0","4.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407815763419975684","https://twitter.com/LisaDeBruine/status/1407815763419975684","Sorry, I reversed the labels when I recoded the original numeric data (that'll teach me to drunk code after the #SIPS2021 social hour ;)

This should be the correct one. https://t.co/AWFBtmCtud","2021-06-23 21:40 +0000","4548.0","513.0","0.11279683377308707","1.0","5.0","17.0","14.0","2.0","7.0","81.0","0.0","0","0","0","0","0","386","386","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407813457936797701","https://twitter.com/LisaDeBruine/status/1407813457936797701","The problems with the study design and analysis is too much to go into tonight, but I really don't think this analysis is supportable off Ns like that. Especially without accounting for the nested by country nature of the data (these are from 1-way ANOVAs). HT @victorshiramizu https://t.co/Avci6gpvMN","2021-06-23 21:30 +0000","8922.0","474.0","0.0531271015467384","4.0","4.0","16.0","29.0","13.0","0.0","152.0","0.0","0","0","0","0","0","256","256","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407812534808219648","https://twitter.com/LisaDeBruine/status/1407812534808219648","I said I wasn't going to do this tonight, but I've downloaded the data for this paper and had a look at all the cell sizes 🤦‍♀️

https://t.co/MzsVtLuVx3 https://t.co/GbTHwXWAzX","2021-06-23 21:27 +0000","14465.0","2730.0","0.18873142067058418","4.0","7.0","44.0","55.0","411.0","0.0","877.0","0.0","0","0","0","0","0","1332","1332","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407713348213477382","https://twitter.com/LisaDeBruine/status/1407713348213477382","@charliejhadley Every time I get my hands on some team code, I put in spaces around %&gt;%, &lt;- and +, add spaces after commas in arguments, and take out spaces between function names and (). I hope to eventually wear down my collaborators, but some are pretty stubborn.","2021-06-23 14:53 +0000","958.0","40.0","0.04175365344467641","0.0","2.0","21.0","2.0","0.0","0.0","15.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407689155027640320","https://twitter.com/LisaDeBruine/status/1407689155027640320","@rnyrthe And so many new people! https://t.co/MmwW8BVP1S","2021-06-23 13:17 +0000","727.0","20.0","0.027510316368638238","0.0","1.0","5.0","4.0","0.0","0.0","1.0","0.0","0","0","0","0","0","9","9","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407642223630602244","https://twitter.com/LisaDeBruine/status/1407642223630602244","@deborahapthorp Would you be more interested in a package that provides the function to make an input interface like this inside your own shiny app, or a package that sets up a whole shiny app like this that you can then customise?","2021-06-23 10:10 +0000","39.0","1.0","0.02564102564102564","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407640108623351810","https://twitter.com/LisaDeBruine/status/1407640108623351810","@GlasgowCC For anyone else who just wants the link without having to transcribe it from a video: https://t.co/8UoEr1lBsT","2021-06-23 10:02 +0000","498.0","23.0","0.04618473895582329","0.0","2.0","2.0","0.0","13.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407612664772235264","https://twitter.com/LisaDeBruine/status/1407612664772235264","Help. I may have overscheduled myself. #HBES2021 #SIPS2021 @sim_school https://t.co/hdl7ok0t2M","2021-06-23 08:13 +0000","6957.0","558.0","0.08020698576972833","3.0","0.0","49.0","30.0","0.0","10.0","14.0","0.0","0","0","0","0","0","452","452","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407369716704976904","https://twitter.com/LisaDeBruine/status/1407369716704976904","@tegladwintmp2 I just added it, thanks :) Now that I have a function for making these radio tables, the hardest part is getting all the questions into a list. Why isn't there a standard tabular format for questionnaires with the question, category, and scoring?

https://t.co/guUqmsBjam","2021-06-22 16:07 +0000","20.0","1.0","0.05","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407362658119131140","https://twitter.com/LisaDeBruine/status/1407362658119131140","@seanpmackinnon Ah, you found a bug! I set it to toggle views on screen size *change* and didn't initialise it to the starting screen size. It's on my list to fix :)","2021-06-22 15:39 +0000","42.0","2.0","0.047619047619047616","0.0","0.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407333016486170626","https://twitter.com/LisaDeBruine/status/1407333016486170626","@seanpmackinnon The interface now switches between tabular and drop-down versions when your screen size crosses the 600px wide threshold (and you can always toggle it back).","2021-06-22 13:41 +0000","48.0","1.0","0.020833333333333332","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407332628194381826","https://twitter.com/LisaDeBruine/status/1407332628194381826","@t_palma This is really just a teaching demo for helping people understand how simulation parameters map onto lme4 output, so we probably won't make the app anymore complex. But I'm working on functions in faux to make multilevel design simulation easier. https://t.co/VXApEKvAdg","2021-06-22 13:40 +0000","51.0","10.0","0.19607843137254902","0.0","1.0","2.0","0.0","1.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407332157387948032","https://twitter.com/LisaDeBruine/status/1407332157387948032","@bmwiernik I've added the 30-item one.
https://t.co/guUqmsBjam","2021-06-22 13:38 +0000","210.0","4.0","0.01904761904761905","0.0","0.0","1.0","1.0","2.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407293812448415748","https://twitter.com/LisaDeBruine/status/1407293812448415748","@seanpmackinnon Thanks! I'll probably add some js to try to detect screen size and make a more sensible default view than always table format first. I'm just rebooting the js part of my brain; it's been a while :)","2021-06-22 11:06 +0000","72.0","2.0","0.027777777777777776","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407292415938121735","https://twitter.com/LisaDeBruine/status/1407292415938121735","@ImADataGuy Thanks ☺️ A blog post is a good idea. I learned a lot about selectize.js today! And there are a few tricky things (like stopping click propagation) that you wouldn't know to do unless you have a fair amount of experience with js.","2021-06-22 11:00 +0000","18.0","2.0","0.1111111111111111","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407290155778650114","https://twitter.com/LisaDeBruine/status/1407290155778650114","@JohnHelveston I love @rubenarslan's formr, but I'm looking for something that people can pop into their own custom shiny apps to display questionnaires in this format, not a generic online questionnaire solution. (I use Experimentum for that https://t.co/c9VOgrJzMk ;)","2021-06-22 10:51 +0000","116.0","18.0","0.15517241379310345","0.0","0.0","1.0","2.0","11.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407289439408304133","https://twitter.com/LisaDeBruine/status/1407289439408304133","It requires some CSS and JavaScript to work, but adding it to a shiny app is really easy. You just specify the questions and options as named lists, and optionally set the width of the question column. Would anyone be interested in this as an R package?","2021-06-22 10:48 +0000","1573.0","12.0","0.007628734901462174","0.0","2.0","1.0","1.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407289437034270731","https://twitter.com/LisaDeBruine/status/1407289437034270731","I'm looking for feedback on this #shiny interface. I want to show questions in a table format (better for sighted viewers on larger screens) or a drop-down menu format (better for screen readers and phone screens) and allow users to toggle back and forth.

https://t.co/guUqmsBjam","2021-06-22 10:48 +0000","2218.0","53.0","0.023895401262398558","1.0","3.0","4.0","3.0","32.0","0.0","9.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407245337178353664","https://twitter.com/LisaDeBruine/status/1407245337178353664","@drboothroyd @LivUni Even worse than median! One person with a massive grant could make every single other person in their unit “below the mean”.

A policy like this actively encourages sabotaging your colleagues.","2021-06-22 07:53 +0000","1035.0","35.0","0.033816425120772944","1.0","2.0","8.0","1.0","0.0","0.0","23.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407244405984071680","https://twitter.com/LisaDeBruine/status/1407244405984071680","@westwoodsam1 @thuyvytnguyen @MicheleNuijten I’ve mostly heard sensitivity analyses meaning an estimate of the smallest effect your data (sample size and other parameters) has X% power to detect.","2021-06-22 07:49 +0000","303.0","5.0","0.0165016501650165","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407243844186476544","https://twitter.com/LisaDeBruine/status/1407243844186476544","Dataviz was my gateway into #rstats. We hope this #psyTeachR tutorial inspires people who want to make informative, reproducible plots, but don’t use R (yet), to give it a try. Feedback on this preprint is very welcome. 
❤️🧡💛💚💙💜🤎🖤
https://t.co/22phatXqIp https://t.co/josPJoDF0R","2021-06-22 07:47 +0000","3687.0","50.0","0.013561160835367507","4.0","1.0","20.0","2.0","10.0","1.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407119402252840960","https://twitter.com/LisaDeBruine/status/1407119402252840960","@hankgreen My best memory of television is watching some old sci-fi show with my dad when I was really little (neither of us can recall the name). It had a giant gold robot, a medium-sized silver robot, and a small bronze robot.

(P.S. I still think Squeeze is the scariest XFiles episode.)","2021-06-21 23:33 +0000","2631.0","43.0","0.016343595591030026","0.0","2.0","11.0","1.0","0.0","0.0","29.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407118044460109830","https://twitter.com/LisaDeBruine/status/1407118044460109830","Since it uses selectInputs under the hood (the radio buttons just trigger changes to hidden selects), this can be made accessible or better for phones by toggling the radio-button columns and the select inputs.","2021-06-21 23:27 +0000","1392.0","6.0","0.004310344827586207","0.0","0.0","3.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407115960515977218","https://twitter.com/LisaDeBruine/status/1407115960515977218","@PaulSharpeY @MichaelALevin @Notawful I settled on that one before I read this (rough demo below), but I'm looking forward to learning more about your Experiment Factory!

https://t.co/guUqmsBjam","2021-06-21 23:19 +0000","30.0","3.0","0.1","0.0","0.0","1.0","0.0","2.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407115224323346433","https://twitter.com/LisaDeBruine/status/1407115224323346433","I just made one with a pretty straightforward setup:

questions &lt;- list(
  E1 = ""Extraverted"",
  A1 = ""Critical"",
  C1 = ""Dependable""
)

options &lt;- c(
  ""Disagree"" = 1,
  ""Neither"" = 2,
  ""Agree"" = 3
)

radio_table(id = ""tipi"", questions, options)","2021-06-21 23:16 +0000","1753.0","19.0","0.010838562464346835","0.0","2.0","8.0","1.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1407115221404205058","https://twitter.com/LisaDeBruine/status/1407115221404205058","Is there already an #rstats package that makes shiny questionnaires like this?

https://t.co/guUqmsBjam https://t.co/LuUs4z0HbB","2021-06-21 23:16 +0000","8469.0","561.0","0.06624158696422246","9.0","4.0","29.0","15.0","43.0","1.0","196.0","0.0","0","0","0","0","0","264","264","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406999209832861703","https://twitter.com/LisaDeBruine/status/1406999209832861703","I'm looking for a questionnaire for a demo that is short (&lt;3 minutes to complete) and has the potential to generate interesting graphical feedback at both the individual and aggregate level. People love stuff like Myers-Briggs, but I don't want to perpetuate that pseudo-science.","2021-06-21 15:35 +0000","6710.0","226.0","0.03368107302533532","2.0","8.0","16.0","18.0","3.0","0.0","179.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406960552971276289","https://twitter.com/LisaDeBruine/status/1406960552971276289","@coles_nicholas_ 31 possible main effects and interactions… https://t.co/sMVfnloTFN","2021-06-21 13:01 +0000","1072.0","21.0","0.01958955223880597","0.0","0.0","5.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","398","15","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566153963687943","https://twitter.com/LisaDeBruine/status/1406566153963687943","🎛Simulating for LMEM https://t.co/q9yI1jmp0u companion to a paper on mixed effects models with @dalejbarr

📕Scienceverse https://t.co/izPxqzf50D is an ambitious (but in-progress) app for creating machine-readable descriptions of studies and human-readable summaries (w/ @lakens)","2021-06-20 10:54 +0000","3026.0","69.0","0.02280237937871778","0.0","2.0","9.0","13.0","33.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566151447105537","https://twitter.com/LisaDeBruine/status/1406566151447105537","Some apps I've made:

☁️Word Cloud https://t.co/RUTsCv0ElV makes a customisable word cloud from text. Created during a live-coding event at @beautiful_hack 

📊Plot Demo https://t.co/J5qJHKyLfO visualizes data from a 2×2 factorial design in 6 different plot styles","2021-06-20 10:54 +0000","1965.0","115.0","0.058524173027989825","0.0","2.0","6.0","7.0","92.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566149182177280","https://twitter.com/LisaDeBruine/status/1406566149182177280","🗓 Day 4

Sharing Your Apps
❤️ https://t.co/nzdNMMqmmZ
🧡 Self-hosting a shiny server
💛 GitHub
💚 In an R package

Advanced Patterns
💙 Creating and downloading a customized report
💜 Shiny modules for repeated structures","2021-06-20 10:54 +0000","1228.0","8.0","0.006514657980456026","0.0","1.0","2.0","2.0","2.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566146950807554","https://twitter.com/LisaDeBruine/status/1406566146950807554","🗓 Day 3

Customizing Your Apps
❤️ CSS, HTML, and Javascript
🧡 Structuring a complex app

Intermediate Patterns
💛 Debugging and error handling
💚 Displaying elements contingent on the state of other elements","2021-06-20 10:54 +0000","1140.0","5.0","0.0043859649122807015","0.0","1.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566144971100162","https://twitter.com/LisaDeBruine/status/1406566144971100162","🗓 Day 2

Basic Patterns
❤️ Different input types
🧡 Different output types
💛 Reading and saving data
💚 Reactive functions","2021-06-20 10:54 +0000","1032.0","7.0","0.006782945736434108","0.0","1.0","1.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566142517317639","https://twitter.com/LisaDeBruine/status/1406566142517317639","🗓 Day 1

Your First Shiny App
 ❤️ Overview of the UI/server structure
 🧡 Inputs, outputs, and action buttons
 💛 Reactive functions

ShinyDashboard
  💚 Basic template for shinydashboard projects
  💙 Sidebar, menu navigation, and tabs
  💜 Row- and column-based layouts","2021-06-20 10:54 +0000","1141.0","13.0","0.011393514460999123","0.0","1.0","2.0","5.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566139619119106","https://twitter.com/LisaDeBruine/status/1406566139619119106","Unlike most of my R training work, this one isn't free (it's $895 US; run by Code Horizons) and is meant for people who have a training budget. I hope that running paid workshops for those who can afford it will support my efforts to provide free resources for those who can't.","2021-06-20 10:54 +0000","1398.0","30.0","0.02145922746781116","0.0","1.0","10.0","8.0","0.0","0.0","11.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406566137559764993","https://twitter.com/LisaDeBruine/status/1406566137559764993","I'm teaching a 4-day remote seminar on Building Web Apps with R Shiny, July 27-30. You can participate live or asynchronously. We'll  make an app that collects and saves data, dynamically visualizes the data, and produces downloadable reports.

https://t.co/tb5tJzPiBe","2021-06-20 10:54 +0000","68226.0","1883.0","0.02759944889045232","62.0","5.0","244.0","240.0","651.0","0.0","679.0","0.0","0","0","1","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406395652079337473","https://twitter.com/LisaDeBruine/status/1406395652079337473","You can use this to make single datasets to use with awesome simulation packages like simr (which allows simulation from scratch, but it's hard to specify a complex design) or to run your own custom power simulations.","2021-06-19 23:37 +0000","1267.0","8.0","0.006314127861089187","0.0","0.0","1.0","1.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406394007354228737","https://twitter.com/LisaDeBruine/status/1406394007354228737","Add random effects by factor:

data &lt;- add_random(subj = 4, item = 2) %&gt;%
  add_between(""subj"", version = 1:2) %&gt;%
  add_ranef(""subj"", u0s = 1.3) %&gt;%
  add_ranef(""item"", u0i = 1.5, u1i = 1.5, .cors = 0.3) %&gt;%
  add_ranef(c(""subj"", ""item""), u0si = 1.7) %&gt;%
  add_ranef(sigma = 2.2) https://t.co/pgdLW4EBuV","2021-06-19 23:30 +0000","913.0","13.0","0.014238773274917854","0.0","0.0","2.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","6","6","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406393549118218246","https://twitter.com/LisaDeBruine/status/1406393549118218246","Recode categorical factors:

data &lt;- add_random(subj = 2, item = 3) %&gt;%
  add_between(""subj"", cond = c(""A"", ""B"")) %&gt;%
  add_between(""item"", type = c(""X"", ""Y"", ""Z"")) %&gt;%
  add_recode(""cond"", ""cond.e"", A = -0.5, B = 0.5) %&gt;%
  add_recode(""cond"", ""cond.t"", A = 0, B = 1) https://t.co/pxtyTgh42M","2021-06-19 23:28 +0000","1735.0","18.0","0.01037463976945245","0.0","2.0","2.0","2.0","0.0","0.0","2.0","0.0","0","0","0","0","0","10","10","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406392135247699968","https://twitter.com/LisaDeBruine/status/1406392135247699968","Filter to counterbalance. In this example,odd-numbered subjects get odd-numbered items.

data &lt;- add_random(subj = 4, item = 4) %&gt;%
  add_between(""subj"", subj_cb = c(""A"", ""B"")) %&gt;%
  add_between(""item"", item_cb = c(""A"", ""B"")) %&gt;%
  filter(subj_cb == item_cb) https://t.co/op9HiSg0oM","2021-06-19 23:23 +0000","822.0","8.0","0.009732360097323601","0.0","1.0","2.0","3.0","0.0","0.0","0.0","0.0","0","0","0","0","0","2","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406390767359344641","https://twitter.com/LisaDeBruine/status/1406390767359344641","Add between factors with add_between(). If you have more than one factor, they will be crossed.

data &lt;- add_random(subj = 4, item = 2) %&gt;%
  add_between(""subj"",
    cond = c(""control"", ""test""),
    gen = c(""X"", ""Z"")) %&gt;%
  add_between(""item"", version = c(""A"", ""B"")) https://t.co/6hse0yEmDM","2021-06-19 23:17 +0000","929.0","16.0","0.017222820236813777","0.0","1.0","4.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","9","9","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406390764549124098","https://twitter.com/LisaDeBruine/status/1406390764549124098","A cross-classified design with 100 subjects and 30 items, the add two within-subject factors.

data &lt;- add_random(subj = 100, item = 30) %&gt;%
  add_within(""subj"", 
    time = c(""pre"", ""post""),
    condition = c(""control"", ""test"")
  )","2021-06-19 23:17 +0000","711.0","3.0","0.004219409282700422","0.0","1.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406390762401583104","https://twitter.com/LisaDeBruine/status/1406390762401583104","You can build up a multilevel model by adding random factors in a stepwise fashion using add_random(). The example below simulates 3 schools with 2, 3 and 4 classes nested in each school.

data &lt;- add_random(school = 3) %&gt;%
  add_random(class = c(2, 3, 4), nested_in = ""school"")","2021-06-19 23:17 +0000","502.0","5.0","0.0099601593625498","0.0","1.0","2.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406389050190278659","https://twitter.com/LisaDeBruine/status/1406389050190278659","As this package grows, it takes more and more time to make sure changes don't break other things (I ❤️ unit tests) and to make sure the syntax and argument names are sensible and consistent.","2021-06-19 23:10 +0000","651.0","6.0","0.009216589861751152","0.0","1.0","3.0","2.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406389048189534210","https://twitter.com/LisaDeBruine/status/1406389048189534210","I spent about 1/3 of today's development time fixing unit tests. I changed sim_design so anonymous factors are named B1, B2, W1, W2, ... instead of A, B, C, D, ..., which made it hard to tell which were within and which between, but which hundreds of my unit tests used.","2021-06-19 23:10 +0000","704.0","5.0","0.007102272727272727","0.0","1.0","2.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406387734495870978","https://twitter.com/LisaDeBruine/status/1406387734495870978","b0 = 0
b1 = .2

data = add_random(sub = 10, item = 10) %&gt;%
  add_between(""sub"", grp = 0:1) %&gt;%
  add_ranef(""sub"", u0s = 1.3) %&gt;%
  add_ranef(""item"", u0i = 1.5, u1i = 1.5, .cors = 0.3) %&gt;%
  add_ranef(err = 2.1) %&gt;%
  dplyr::mutate(dv = b0 + u0s + u0i + (b1 + u1i) * grp + err) https://t.co/Ato0OMnEki","2021-06-19 23:05 +0000","836.0","28.0","0.03349282296650718","0.0","1.0","7.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","16","16","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406387731673014273","https://twitter.com/LisaDeBruine/status/1406387731673014273","I spent most of today making new functions in faux for simulating multilevel data. This vignette explains how to use them; I hope they're intuitive. I'll add them to the CRAN version if others find them useful.

https://t.co/VXApEKvAdg","2021-06-19 23:05 +0000","33233.0","724.0","0.021785574579484247","33.0","3.0","166.0","82.0","170.0","0.0","267.0","0.0","0","0","0","0","0","3","3","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406361008361422853","https://twitter.com/LisaDeBruine/status/1406361008361422853","@Sam_D_Parsons I can see that. It’s an amazing show. I heard someone describe it as not so much a comedy show, but an art-house horror film about making a comedy show.","2021-06-19 21:19 +0000","722.0","13.0","0.018005540166204988","0.0","1.0","4.0","4.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1406180731370586113","https://twitter.com/LisaDeBruine/status/1406180731370586113","@McAleerP @Leesplez The papaja #rstats package by @FrederikAust is fantastic for writing papers in R Markdown. 

@dalejbarr and I wrote this paper in papaja https://t.co/hNpmL8NAcm and the source files are all here https://t.co/xj6AVHL693","2021-06-19 09:23 +0000","1434.0","57.0","0.0397489539748954","2.0","1.0","13.0","6.0","26.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405560371298148357","https://twitter.com/LisaDeBruine/status/1405560371298148357","@LottyBrand The webpage has a link to the session recording for each session. I’ll DM you the password.","2021-06-17 16:18 +0000","86.0","1.0","0.011627906976744186","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405187129731338241","https://twitter.com/LisaDeBruine/status/1405187129731338241","@CrystalNSYoung It would be a more useful critique to point to what newer work they think you've missed and how that work adds to the paper. ""Old"" isn't bad in and of itself.","2021-06-16 15:34 +0000","839.0","19.0","0.02264600715137068","0.0","1.0","12.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405121738166484997","https://twitter.com/LisaDeBruine/status/1405121738166484997","@sTeamTraen I’ve been hearing a lot of good things from @cantabile about targets for breaking your data pipeline into smaller pieces, which might help with this problem. 

https://t.co/JF4M0ECRX0","2021-06-16 11:15 +0000","273.0","13.0","0.047619047619047616","0.0","0.0","5.0","0.0","5.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405120847413661697","https://twitter.com/LisaDeBruine/status/1405120847413661697","@sTeamTraen For example, do you remove test subjects before or after you calculate summary variables? This should make no difference in the end, but introduces huge apparent “inconsistency” between analysts at some points, making it harder to detect meaningful inconsistency.","2021-06-16 11:11 +0000","576.0","11.0","0.019097222222222224","0.0","2.0","2.0","0.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405120274958258178","https://twitter.com/LisaDeBruine/status/1405120274958258178","@sTeamTraen One barrier is that there are so many different ways to process raw data that judging consistency is almost impossible unless you outlined together first what steps you’d take in what order.","2021-06-16 11:09 +0000","238.0","10.0","0.04201680672268908","0.0","2.0","3.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1405081175752908803","https://twitter.com/LisaDeBruine/status/1405081175752908803","The zoom link for the @UofGPsychology #MethodsMetaScience seminar today is on the website now. All are invited to come learn about Generalizability Theory and Alan Huebner's #rstats Gboot package for conducting basic and advanced G-theory analyses.
[16 June 14:00 BST] https://t.co/t5IR7MvNKP","2021-06-16 08:33 +0000","3604.0","23.0","0.006381798002219756","4.0","0.0","2.0","13.0","0.0","2.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404337741106659329","https://twitter.com/LisaDeBruine/status/1404337741106659329","@rogers_k8 With n = 100, a minimum lower than 10 or a maximum higher than 50 would be pretty unusual.

df %&gt;%
  mutate(id = 1:1000) %&gt;%
  gather(number, duplicates, min:max) %&gt;%
  ggplot(aes(duplicates, color = number)) +
  geom_histogram(binwidth = 1, fill = ""white"") https://t.co/aacVilNFwq","2021-06-14 07:19 +0000","179.0","10.0","0.055865921787709494","0.0","1.0","3.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","4","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404335616402337792","https://twitter.com/LisaDeBruine/status/1404335616402337792","@rogers_k8 library(tidyverse)

f = function(n = 100) {
  sim = replicate(n, sample(1:15, 4, TRUE)) %&gt;%
    t() %&gt;% data.frame()
  sim$id = 1:n
  
  lvl = gather(sim, ""stim"", ""lvl"", X1:X4) %&gt;%
    count(lvl)

  list(
    min = min(lvl$n),
    max = max(lvl$n)
  )
}

df = map_df(1:1000, ~f())","2021-06-14 07:11 +0000","118.0","5.0","0.0423728813559322","0.0","1.0","4.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404335561716940801","https://twitter.com/LisaDeBruine/status/1404335561716940801","@rogers_k8 Here's a quick simulation (with study n = 100 and 1000 reps) to check the plausible range of minimum and maximum n per level.","2021-06-14 07:11 +0000","684.0","26.0","0.038011695906432746","0.0","1.0","4.0","8.0","0.0","0.0","13.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404032782175723526","https://twitter.com/LisaDeBruine/status/1404032782175723526","@dingding_peng That looks like a really interesting talk! And lovely slides :)","2021-06-13 11:07 +0000","1460.0","21.0","0.014383561643835616","0.0","1.0","6.0","5.0","0.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404021865073545222","https://twitter.com/LisaDeBruine/status/1404021865073545222","&gt; and demonstrate the use of the Gboot package in R for computing bootstrap confidence intervals for G-theory variance components and reliability coefficients:

https://t.co/irvWSm8gua","2021-06-13 10:24 +0000","1331.0","10.0","0.007513148009015778","0.0","0.0","1.0","2.0","5.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404021863873925128","https://twitter.com/LisaDeBruine/status/1404021863873925128","&gt; However, there has been a scarcity of user-friendly computer software resources for conducting basic and advanced G-theory analyses. This talk will give a brief overview of G-theory and current computational tools, discuss some applications to sports performance science, &gt;","2021-06-13 10:24 +0000","1456.0","4.0","0.0027472527472527475","0.0","1.0","0.0","3.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404021862649241602","https://twitter.com/LisaDeBruine/status/1404021862649241602","Generalizability theory (G-theory) is a powerful, modern framework in which to conduct reliability analyses. The method allows the user to disentangle various sources of measurement error and find optimal measurement procedures. &gt;","2021-06-13 10:24 +0000","605.0","5.0","0.008264462809917356","0.0","1.0","0.0","3.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1404021861051211780","https://twitter.com/LisaDeBruine/status/1404021861051211780","The next @UofGPsychology #MethodsMetaScience seminar will be Wednesday 16 June at 14:00 BST by Alan Huebner on Computational Tools and Applications for Generalizability Theory. All are welcome.

https://t.co/A2KZYqiv9b","2021-06-13 10:24 +0000","9586.0","113.0","0.011788024201961194","6.0","1.0","20.0","23.0","24.0","2.0","37.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403692565162082306","https://twitter.com/LisaDeBruine/status/1403692565162082306","@page_eco @AdamMGrant @d_f_stone How aggressive you’re being isn’t always the same as how aggressive you’re perceived, which derails this whole thing for a lot of people who can’t say anything critical without being *perceived* as aggressive.","2021-06-12 12:36 +0000","3473.0","78.0","0.022458969190901238","5.0","1.0","19.0","19.0","0.0","0.0","28.0","0.0","0","0","0","0","0","6","6","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403376561827549186","https://twitter.com/LisaDeBruine/status/1403376561827549186","@amolk @anilkseth Almost no one reports being able to “hear” it if you remove the camera shake, which complicates that hypothesis a bit.","2021-06-11 15:40 +0000","214.0","4.0","0.018691588785046728","0.0","1.0","1.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403062808946823175","https://twitter.com/LisaDeBruine/status/1403062808946823175","@nataliadutrapsy 💯If you’ve been doing research for more than a few years and you don’t disagree with at least some aspects of your *own* work, you probably need to introspect a little harder.","2021-06-10 18:53 +0000","4823.0","124.0","0.025710138917686087","8.0","2.0","40.0","16.0","0.0","0.0","58.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403059346272100357","https://twitter.com/LisaDeBruine/status/1403059346272100357","@PWGTennant @ukrepro I really enjoyed the session, plus live tweeting helps me pay attention and process the material.","2021-06-10 18:39 +0000","415.0","5.0","0.012048192771084338","0.0","0.0","2.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403007115892072451","https://twitter.com/LisaDeBruine/status/1403007115892072451","I'm looking forward to next month's @ukrepro event on Octopus: The new primary research record. I think it's the future of science to move from papers as the primary research product to more modular and diverse research objects. https://t.co/7Y2jhZ0aAr
https://t.co/oBUM9A7Co4","2021-06-10 15:12 +0000","1652.0","21.0","0.012711864406779662","0.0","0.0","1.0","1.0","16.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403004775185014794","https://twitter.com/LisaDeBruine/status/1403004775185014794","Q: How can we learn more about DAGs?

A: Leeds summer school in Causal Inference
https://t.co/inJsDyQV4H","2021-06-10 15:02 +0000","1927.0","50.0","0.02594706798131811","0.0","1.0","3.0","2.0","32.0","0.0","12.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403003948458405893","https://twitter.com/LisaDeBruine/status/1403003948458405893","Q: Does updating the DAG from the data go against the idea of drawing the DAG from theory/expertise? (Daniela Rodrigues)

A: @PWGTennant recommends including the original DAG in your paper and explaining your reasoning for updating it from the data.","2021-06-10 14:59 +0000","1340.0","7.0","0.0052238805970149255","0.0","1.0","1.0","2.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403003193991196680","https://twitter.com/LisaDeBruine/status/1403003193991196680","I'm really excited about DAGs again (the first time was after watching @rlmcelreath speak on them at EHBEA), but I'd love to watch someone walk through the process of developing a new DAG. It seems like a tricky process.","2021-06-10 14:56 +0000","1262.0","20.0","0.01584786053882726","0.0","1.0","1.0","3.0","0.0","0.0","14.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403001812018286594","https://twitter.com/LisaDeBruine/status/1403001812018286594","Excellent question from @1987Andrewk in the chat (not discussed yet): Should we have a DAG registration system like PROSPERO? What would be the pros and cons?","2021-06-10 14:51 +0000","1295.0","3.0","0.0023166023166023165","0.0","1.0","0.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1403001047119892482","https://twitter.com/LisaDeBruine/status/1403001047119892482","More audience recommendations: 

https://t.co/80gr10mgTz (via Joe Hicks)","2021-06-10 14:48 +0000","1376.0","14.0","0.010174418604651164","1.0","1.0","1.0","3.0","6.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402999896588767238","https://twitter.com/LisaDeBruine/status/1402999896588767238","The accuracy of your estimates depends on the accuracy of your DAG.

But hiding your assumptions doesn't mean you haven't made them. At least share them transparently so the scientific community can discuss them.","2021-06-10 14:43 +0000","2095.0","50.0","0.02386634844868735","1.0","1.0","7.0","1.0","1.0","0.0","39.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402999894025990150","https://twitter.com/LisaDeBruine/status/1402999894025990150","DAGs do not:

* prove whether an effect is causal
* indicate whether an effect is harmful, protective, or meaningful
* indicate if effect modification (interaction) is present
* indicate if a cause is sufficient or necessary (nonlinearity)","2021-06-10 14:43 +0000","1183.0","10.0","0.0084530853761623","0.0","1.0","6.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402999017789804552","https://twitter.com/LisaDeBruine/status/1402999017789804552","9. Use your DAGs to inform your model: clearly state any adjustments in your paper

10. Share and publish your DAGs: don't worry if they look messy, this is #openScience and transparency at its best!","2021-06-10 14:40 +0000","1213.0","13.0","0.010717230008244023","1.0","1.0","3.0","2.0","0.0","0.0","6.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402998606508949505","https://twitter.com/LisaDeBruine/status/1402998606508949505","7. Draw forward arcs: start assuming all variables are potential causes of all future variables, removing an arc is a stronger assumption than including one

8. Check &amp; update your DAGs against your data: use the daggity #rstats package to check for inconsistencies","2021-06-10 14:38 +0000","1893.0","16.0","0.008452192287374538","2.0","1.0","4.0","0.0","0.0","0.0","9.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402998604239802369","https://twitter.com/LisaDeBruine/status/1402998604239802369","4. Get help: go #TeamScience!

5. Include all relevant variables: unavailable or unobservable variables can be included as latent variables

6. Draw your DAGs in temporal order: don't make pretty shapes","2021-06-10 14:38 +0000","921.0","14.0","0.01520086862106406","0.0","1.0","2.0","0.0","0.0","0.0","11.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402997055602106388","https://twitter.com/LisaDeBruine/status/1402997055602106388","Top 10 tips:

1. Developing and stating a clear research question: Absolutely fundamental but so often ignored!

2. Consider &amp; state your context:  DAGs are context-specific to who, where and when

3. Draw your DAGs as early as possible: don't run many and report your favourite https://t.co/1EKY7SBo2L","2021-06-10 14:32 +0000","1250.0","32.0","0.0256","0.0","2.0","6.0","0.0","0.0","0.0","6.0","0.0","0","0","0","0","0","18","18","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402996135979982856","https://twitter.com/LisaDeBruine/status/1402996135979982856","Collider bias can even reverse the sign of an association. For example, smoking is positively associated with death from COVID-19, but after conditioning on diabetes, it is negatively associated! https://t.co/M6aI9jyUUD","2021-06-10 14:28 +0000","1837.0","40.0","0.021774632553075667","1.0","1.0","6.0","4.0","0.0","0.0","6.0","0.0","0","0","0","0","0","22","22","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402994507193274377","https://twitter.com/LisaDeBruine/status/1402994507193274377","You need a new causal model for each factor you want to understand; don't interpret the coefficients of confounders, mediators, and competing exposures. This is the Table 2 fallacy.

https://t.co/BITXVvtI8o","2021-06-10 14:22 +0000","2604.0","94.0","0.03609831029185868","2.0","1.0","12.0","6.0","25.0","0.0","47.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402993428133138444","https://twitter.com/LisaDeBruine/status/1402993428133138444","DO condition on confounders: blocks confounding paths
DON'T condition on mediators: blocks true causal paths
OPTIONALLY condition on competing exposures: improves precision of your estimates","2021-06-10 14:17 +0000","1215.0","12.0","0.009876543209876543","0.0","1.0","5.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402992780763303952","https://twitter.com/LisaDeBruine/status/1402992780763303952","Each variable in your DAG is
* Exposure (IV)
* Outcome (DV)
* Confounder (creates indirect association between C and F)
* Mediator (channels part of causal effect of C on F)
* Competing Exposure (adds heterogeneity to F) https://t.co/wFyrsyioXR","2021-06-10 14:15 +0000","1171.0","30.0","0.025619128949615714","0.0","1.0","4.0","0.0","0.0","0.0","4.0","0.0","0","0","0","0","0","21","21","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402988406771122178","https://twitter.com/LisaDeBruine/status/1402988406771122178","Collider scope: when selection bias can substantially influence observed associations 
by @MarcusMunafo  Kate Tilling, Amy E Taylor, David M Evans, @davidMevans @mendel_random 

https://t.co/pMq2xDtIKe","2021-06-10 13:57 +0000","1528.0","27.0","0.01767015706806283","0.0","2.0","7.0","4.0","7.0","0.0","6.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402987602165198849","https://twitter.com/LisaDeBruine/status/1402987602165198849","dagR: A Suite of R Functions for Directed Acyclic Graphs
https://t.co/Qfmt5SlaFB
by Lutz Breitling (via @tvpollet)","2021-06-10 13:54 +0000","1356.0","21.0","0.015486725663716814","1.0","2.0","3.0","2.0","5.0","0.0","7.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402987599770226693","https://twitter.com/LisaDeBruine/status/1402987599770226693","People are sharing interesting links in the chat:

Tools for causal discovery
https://t.co/yZRrAoHxCM

TETRAD project
https://t.co/dvJlmeqCuG","2021-06-10 13:54 +0000","836.0","12.0","0.014354066985645933","0.0","1.0","3.0","2.0","6.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402986668550852609","https://twitter.com/LisaDeBruine/status/1402986668550852609","Question time!

Q: Can you analyse a vicious cycle with DAGS? 
A: Yes, a DAG can't be circular at one time point, but a vertex can affect itself at a later time point","2021-06-10 13:51 +0000","906.0","6.0","0.006622516556291391","0.0","1.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402985581206937615","https://twitter.com/LisaDeBruine/status/1402985581206937615","Collider bias is so important to understand, but not always intuitive. Some great papers on it:

https://t.co/ShLqWLhW14 by @MarcusMunafo 

https://t.co/EwpeWWuiZF by @dingding_peng https://t.co/3GSqx9kVpj","2021-06-10 13:46 +0000","2320.0","155.0","0.0668103448275862","3.0","1.0","13.0","7.0","32.0","0.0","21.0","0.0","0","0","0","0","0","78","78","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402984734909624325","https://twitter.com/LisaDeBruine/status/1402984734909624325","Conditioning can help you to get rid of confounding in a model. For example, ice cream consumption and shark attacks are correlated, unless you condition on the ""confounder"" of weather. https://t.co/ALdWPStwDX","2021-06-10 13:43 +0000","1053.0","30.0","0.02849002849002849","0.0","1.0","4.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","23","23","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402983244434350094","https://twitter.com/LisaDeBruine/status/1402983244434350094","Estimation is philosophically different to NHST. But does this just kick the can down the road to others who have to justify a smallest effect size of interest for supporting hypotheses or deciding whether or not to implement an intervention? https://t.co/LvZHL0PA7o","2021-06-10 13:37 +0000","1388.0","51.0","0.03674351585014409","0.0","3.0","2.0","1.0","0.0","0.0","18.0","0.0","0","0","0","0","0","27","27","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402981827447459842","https://twitter.com/LisaDeBruine/status/1402981827447459842","Everything comes back to the data generating process https://t.co/0PVdK5e6JP","2021-06-10 13:31 +0000","1667.0","74.0","0.04439112177564487","3.0","1.0","10.0","2.0","0.0","0.0","15.0","0.0","0","0","0","0","0","43","43","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402979778764984321","https://twitter.com/LisaDeBruine/status/1402979778764984321","The C-Word: Scientific Euphemisms Do Not Improve Causal Inference From Observational Data 
https://t.co/6EFm7nZ6T6","2021-06-10 13:23 +0000","1918.0","24.0","0.01251303441084463","1.0","1.0","6.0","1.0","11.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402979305207050241","https://twitter.com/LisaDeBruine/status/1402979305207050241","I like this concept of Schrödinger's Inference. https://t.co/KNVHVW1yFy","2021-06-10 13:21 +0000","3145.0","234.0","0.07440381558028616","3.0","1.0","20.0","20.0","3.0","0.0","38.0","0.0","0","0","0","0","0","149","149","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402978667349823496","https://twitter.com/LisaDeBruine/status/1402978667349823496","What's your favourite scientific euphemism for avoiding saying two things are causally related? Mine's ""X is associated with Y"". I like ""X predicts Y"" in the context of a regression model, but some people get really het up about that phrase.","2021-06-10 13:19 +0000","936.0","11.0","0.011752136752136752","0.0","1.0","4.0","2.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402975256344776707","https://twitter.com/LisaDeBruine/status/1402975256344776707","Also led by @GeorgiaTomova 

There are 263 people here!  I'm guessing many, like me, have been meaning to get to grips with DAGs for awhile and this seems like  perfect opportunity.","2021-06-10 13:05 +0000","1172.0","20.0","0.017064846416382253","0.0","2.0","1.0","14.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402973602539048965","https://twitter.com/LisaDeBruine/status/1402973602539048965","Just starting the @ukrepro workshop #IntroToDAGs by @PWGTennant https://t.co/mB6NhoLcAF","2021-06-10 12:59 +0000","21078.0","342.0","0.016225448334756618","12.0","1.0","30.0","61.0","10.0","7.0","183.0","0.0","0","0","0","0","0","2572","38","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402948265998487552","https://twitter.com/LisaDeBruine/status/1402948265998487552","@heatherklus I'm just updating the inclusion guidelines for our @psyTeachR books today and wondering if you ever had a chance to write that blog post, @heatherklus","2021-06-10 11:18 +0000","75.0","1.0","0.013333333333333334","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402336754192035841","https://twitter.com/LisaDeBruine/status/1402336754192035841","#psyTeachR #CodingClub meets tomorrow at 14:00 (UK time); all welcome. Check the link for the zoom and last week's code. We'll restructure the simulation functions to keep a record of previously simulated data to make faceted plots for comparison.

https://t.co/BlxxAoSSfN https://t.co/nUITpjpLPb","2021-06-08 18:48 +0000","2058.0","89.0","0.043245869776482024","2.0","0.0","6.0","8.0","13.0","0.0","13.0","0.0","0","0","0","0","0","47","47","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402335249795850242","https://twitter.com/LisaDeBruine/status/1402335249795850242","@graceelavery The TERFs are totally ruining an excellent Scots phrase.","2021-06-08 18:42 +0000","145.0","12.0","0.08275862068965517","0.0","1.0","3.0","4.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402333666764861452","https://twitter.com/LisaDeBruine/status/1402333666764861452","@DrAndrewV2 I love how this so obviously lends itself to that meme :)
https://t.co/FKsWMqxkve","2021-06-08 18:36 +0000","494.0","6.0","0.012145748987854251","0.0","1.0","1.0","1.0","3.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402328374387875841","https://twitter.com/LisaDeBruine/status/1402328374387875841","@chrisderv @xieyihui @PsyTeachR We don't use the theorem and proof environment, but since webex is meant to work with bookdown, I should definitely make it as seamless as possible. @dalejbarr and I will update webex as soon as we get a chance and I'll change all the custom classes to be less likely to conflict.","2021-06-08 18:15 +0000","388.0","5.0","0.01288659793814433","0.0","1.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402326529170939904","https://twitter.com/LisaDeBruine/status/1402326529170939904","@chrisderv @xieyihui Makes sense. I'm just happy to have finally figured out why all the @psyTeachR books would no longer knit if you upgraded bookdown. It's been pestering our team for months now.","2021-06-08 18:07 +0000","68.0","5.0","0.07352941176470588","0.0","1.0","1.0","2.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402325798112182274","https://twitter.com/LisaDeBruine/status/1402325798112182274","@JimProvost Unfortunately, I used a custom div class in the webex package that bookdown now uses. Since all the @PsyTeachR books use webex, I think I'll have to budge on this one and change our package to avoid the conflict.","2021-06-08 18:04 +0000","40.0","1.0","0.025","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402323789795450882","https://twitter.com/LisaDeBruine/status/1402323789795450882","@chrisderv @xieyihui Thanks. I'll do that. I'm a developer of webex, so I might solve it by changing the div class there. I should know by now not to use overly-generic class names (as should y'all ;)","2021-06-08 17:57 +0000","93.0","6.0","0.06451612903225806","0.0","1.0","1.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402320011964919812","https://twitter.com/LisaDeBruine/status/1402320011964919812","@MicrobiomDigest I saved you a copy, but you can download from here, too https://t.co/xeUpgjR51R","2021-06-08 17:41 +0000","1678.0","58.0","0.03456495828367104","3.0","1.0","16.0","3.0","28.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402319253290762240","https://twitter.com/LisaDeBruine/status/1402319253290762240","@dainty_chainsaw I suspect everyone could already guess that from your username ;) https://t.co/1oeoY5OFGg","2021-06-08 17:38 +0000","119.0","7.0","0.058823529411764705","0.0","0.0","2.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","48","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402318179288981508","https://twitter.com/LisaDeBruine/status/1402318179288981508","@Benjaming_G @mjskay The only real benefit I see to teaching &lt;- is to make sure students know what's going on in code they find on the internet. And I guess it makes the conceptual links to -&gt; and superassignment &lt;&lt;- (which is probably not a good thing to make easier).","2021-06-08 17:34 +0000","606.0","4.0","0.006600660066006601","0.0","1.0","3.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402315703508668422","https://twitter.com/LisaDeBruine/status/1402315703508668422","Tag yourself. I'm ""too many head tilts"". https://t.co/OrJLuu7SU1","2021-06-08 17:24 +0000","6416.0","104.0","0.016209476309226933","2.0","8.0","12.0","8.0","0.0","0.0","74.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402311694253277192","https://twitter.com/LisaDeBruine/status/1402311694253277192","@Surrey_Repro @ProfAndyField @PsyPAG @ukrepro @RR_Oxford @PsyTechOli @chaddlewick I just gave the first workshop and wasn't involved in organising this amazing series.","2021-06-08 17:08 +0000","172.0","2.0","0.011627906976744186","0.0","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402311488682041344","https://twitter.com/LisaDeBruine/status/1402311488682041344","The following code works fine:

&lt;div class='solution2'&gt;
&lt;button&gt;Solution&lt;/button&gt;
&lt;/div&gt;

And this does too:

&lt;div class='solution'&gt;
&lt;span&gt;Solution&lt;/span&gt;
&lt;/div&gt;

So it seems specific to when there's a button in a div with class 'solution'.","2021-06-08 17:08 +0000","1316.0","18.0","0.013677811550151976","0.0","2.0","0.0","3.0","0.0","0.0","12.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402311484101775369","https://twitter.com/LisaDeBruine/status/1402311484101775369","I have a #bookdown chapter with only the following (originally created by webex::hide(), but also fails if I write the HTML directly). I can't render and get en error with the lua filter.
#rstats @xieyihui 

&lt;div class='solution'&gt;
&lt;button&gt;Solution&lt;/button&gt;
&lt;/div&gt; https://t.co/YemF6ElmlJ","2021-06-08 17:08 +0000","3585.0","72.0","0.0200836820083682","3.0","1.0","2.0","2.0","0.0","0.0","29.0","0.0","0","0","0","0","0","35","35","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402141188573089792","https://twitter.com/LisaDeBruine/status/1402141188573089792","@Chican3ry I don’t know whether to laugh or despair at their frankly illiterate ideal of “no pronouns”.","2021-06-08 05:51 +0000","169.0","8.0","0.047337278106508875","0.0","0.0","2.0","1.0","0.0","0.0","5.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402138585948688384","https://twitter.com/LisaDeBruine/status/1402138585948688384","@HehmanLab Congratulations! 🥳","2021-06-08 05:41 +0000","114.0","4.0","0.03508771929824561","0.0","0.0","1.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1402000268087136267","https://twitter.com/LisaDeBruine/status/1402000268087136267","@EikoFried @Chops310 “Shaw (2011) argued that the requirement to fulfil all [three ICMJE] criteria has the potential to create the paradoxical situation that science is performed but that none of the contributors qualify for authorship because of their distribution of labor.”

Now I want to do this.","2021-06-07 20:31 +0000","3848.0","94.0","0.02442827442827443","1.0","2.0","28.0","9.0","2.0","0.0","45.0","0.0","0","0","0","0","0","7","7","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401998645046792197","https://twitter.com/LisaDeBruine/status/1401998645046792197","@cantabile I still have two Apple accounts, one US and one UK. Don’t do this; it makes updates a nightmare.","2021-06-07 20:24 +0000","598.0","12.0","0.020066889632107024","0.0","1.0","2.0","7.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401814341226315778","https://twitter.com/LisaDeBruine/status/1401814341226315778","Nice Registered Report showing little to no correlation between basal testosterone and personality for men or women, regardless of hormonal contraceptives status. By @TheRisingSundin @JnfrLTackett https://t.co/gErW3pKvW4","2021-06-07 08:12 +0000","4741.0","58.0","0.01223370596920481","3.0","1.0","21.0","11.0","1.0","0.0","21.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401584485943103490","https://twitter.com/LisaDeBruine/status/1401584485943103490","Everyone interested in data simulation should follow @sim_school, who will be posting workshop recordings on YouTube! https://t.co/I3iANKahgX","2021-06-06 16:59 +0000","7114.0","153.0","0.021506887826820354","8.0","1.0","43.0","77.0","0.0","0.0","24.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401517828075888644","https://twitter.com/LisaDeBruine/status/1401517828075888644","And this simulations workshop (I’ve been meaning to learn about SimDesign) https://t.co/HseEwvMSYl https://t.co/zXtGqlfBZe","2021-06-06 12:34 +0000","1613.0","17.0","0.010539367637941723","1.0","1.0","7.0","3.0","1.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401516681034403841","https://twitter.com/LisaDeBruine/status/1401516681034403841","Looking forward to this @improvingpsych session on matching stimuli reproducibly by @JackEdTaylor https://t.co/rGVuZ28QpE","2021-06-06 12:29 +0000","4678.0","26.0","0.0055579307396323215","2.0","1.0","6.0","13.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401515600241991683","https://twitter.com/LisaDeBruine/status/1401515600241991683","@dan_p_simpson That feels like being assigned a book report by random colleagues. Which I guess is no different than a journal review request, but this time involves a presentation :)","2021-06-06 12:25 +0000","154.0","1.0","0.006493506493506494","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401509467741736965","https://twitter.com/LisaDeBruine/status/1401509467741736965","@dan_p_simpson Is that not just journal club?","2021-06-06 12:01 +0000","571.0","5.0","0.008756567425569177","0.0","1.0","0.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401492646149885953","https://twitter.com/LisaDeBruine/status/1401492646149885953","@lakens @deevybee @sohmeiling I also have two tutorial chapters from random workshops on intro to data simulation and simulation for mixed models:

https://t.co/JnwdnRTYFD

https://t.co/0YMSkMskNx","2021-06-06 10:54 +0000","7731.0","176.0","0.022765489587375502","7.0","2.0","24.0","27.0","66.0","0.0","50.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401490439417569281","https://twitter.com/LisaDeBruine/status/1401490439417569281","@deevybee I’m just chatting with the instructors of the PsyPAG data simulation workshop series about putting our materials together in an online book that can be expanded by the community.","2021-06-06 10:45 +0000","3242.0","27.0","0.008328192473781616","2.0","1.0","8.0","8.0","0.0","0.0","8.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401199305243901958","https://twitter.com/LisaDeBruine/status/1401199305243901958","@bmwiernik @willemsleegers @Flavio_Azevedo_ @baixx062 @FrederikAust Oh, this is so much easier to explain than sprintf! I have to go revise a book chapter now :)","2021-06-05 15:28 +0000","218.0","1.0","0.0045871559633027525","0.0","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401198857711726597","https://twitter.com/LisaDeBruine/status/1401198857711726597","@bmwiernik @willemsleegers @Flavio_Azevedo_ @baixx062 @FrederikAust Nice! I’ve been using https://t.co/q5cRsCW5zy to call sprintf after appending analysis results lists to the fmt string and using %1$x to reference the list items by position, but that’s a bit of a pain to teach and you get a warning if you don’t use all the list items.","2021-06-05 15:26 +0000","136.0","3.0","0.022058823529411766","0.0","1.0","2.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401197313780027396","https://twitter.com/LisaDeBruine/status/1401197313780027396","@kimberlyquinn @wdonald_1985 @bmwiernik @JkayFlake @CookieSci We might have different definitions of “required to work”. I still have to log my holiday hours, and go to admin meetings (fewer than during term) and fill out time allocation forms. Where and when I work is more flexible, but I couldn’t take 3 months off, even if I wanted to.","2021-06-05 15:20 +0000","261.0","9.0","0.034482758620689655","0.0","1.0","3.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401194562459254788","https://twitter.com/LisaDeBruine/status/1401194562459254788","@willemsleegers @Flavio_Azevedo_ @baixx062 @FrederikAust Every time I try to write one, I realise I’m basically just wrapping sprintf and should just show people how to use sprintf.","2021-06-05 15:09 +0000","253.0","6.0","0.023715415019762844","0.0","1.0","4.0","0.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401190213326671872","https://twitter.com/LisaDeBruine/status/1401190213326671872","@wdonald_1985 @bmwiernik @JkayFlake @CookieSci Hold on, do American academics not have to work in the summer?!?","2021-06-05 14:52 +0000","559.0","46.0","0.08228980322003578","0.0","4.0","3.0","3.0","0.0","0.0","35.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401130758123790336","https://twitter.com/LisaDeBruine/status/1401130758123790336","@MauroMozzarelli @ukhomeoffice That’s a totally valid concern. Every step of my residency application (years ago as a US citizen) was plagued with immigration not being able to access records they should definitely have, like my Life in the UK test results or the fact I’d been paying taxes here for years.","2021-06-05 10:56 +0000","409.0","15.0","0.03667481662591687","1.0","1.0","8.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401129617780584449","https://twitter.com/LisaDeBruine/status/1401129617780584449","@CareyDP1 @mnlimas @deevybee @tomgauld @newscientist Tiktok definitely has improved my sourdough!","2021-06-05 10:51 +0000","212.0","3.0","0.014150943396226415","0.0","0.0","3.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401122021749276679","https://twitter.com/LisaDeBruine/status/1401122021749276679","@Sosowski I wrote a MadLibs program when I was 10 and had to figure out through trial and error that I couldn’t name the variables NOUN1$, NOUN2$, etc.","2021-06-05 10:21 +0000","265.0","9.0","0.033962264150943396","0.0","1.0","3.0","3.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401120924309590016","https://twitter.com/LisaDeBruine/status/1401120924309590016","@Sosowski 10 HOME : TEXT
20 INPUT “Enter a name: “;N$
30 INPUT “Enter a year: “;Y
40 PRINT N$;” started coding in “;Y
50 END","2021-06-05 10:17 +0000","978.0","24.0","0.024539877300613498","1.0","1.0","11.0","4.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401087929548632067","https://twitter.com/LisaDeBruine/status/1401087929548632067","@LMatyjek @_Luisa_Hahn Terms change and have enough cultural diversity that you can’t make a static list that works for everything, but open-ended has other challenges and isn’t a panacea. If you’re going to group participants in categories for analysis, tell them what those categories are and why.","2021-06-05 08:06 +0000","112.0","9.0","0.08035714285714286","0.0","0.0","6.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1401086866879913984","https://twitter.com/LisaDeBruine/status/1401086866879913984","@LMatyjek You might be interested to read @_Luisa_Hahn’s dissertation overview looking at different option combinations for gender questions, plus an open-ended question. 

https://t.co/gCLy6FlorA https://t.co/HXxha4oSbH","2021-06-05 08:01 +0000","682.0","164.0","0.2404692082111437","1.0","1.0","13.0","6.0","13.0","0.0","20.0","0.0","0","0","0","0","0","110","110","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400854433970393090","https://twitter.com/LisaDeBruine/status/1400854433970393090","@Nay_Landell @RuthAgbakoba I know someone whose mother’s identical twin married her father’s (non-twin) brother, so her cousins are basically 3/4 siblings.","2021-06-04 16:38 +0000","839.0","10.0","0.011918951132300357","0.0","2.0","2.0","5.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400847153837248529","https://twitter.com/LisaDeBruine/status/1400847153837248529","Number 4’s ""Doesn’t stay up all night eating marshmallows and starches"" profile has people asking a lot of questions already answered by his profile. https://t.co/DtFIQtGNFE","2021-06-04 16:09 +0000","2294.0","9.0","0.003923278116826504","0.0","0.0","1.0","4.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400831571708583941","https://twitter.com/LisaDeBruine/status/1400831571708583941","@JCSkewesDK I’m so sorry you and your colleagues are being targeted like this.","2021-06-04 15:07 +0000","157.0","7.0","0.044585987261146494","0.0","1.0","3.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400831186344292355","https://twitter.com/LisaDeBruine/status/1400831186344292355","@JCSkewesDK Low power, poor scale validity, and unrepresentative samples don’t make work “psuedoscience”, just needing improvement. That label makes it sound like they think sexism doesn’t exist, so nothing you do to study it could possibly be scientific. There’s no way for you to win.","2021-06-04 15:05 +0000","1675.0","66.0","0.03940298507462687","1.0","3.0","13.0","5.0","0.0","0.0","44.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400829310366367745","https://twitter.com/LisaDeBruine/status/1400829310366367745","@Display_Geek I support your choice to identify as transsexual, but after reading your blog post I feel like you’d agree that this particular quartet does a pretty crap job of covering the possible options, and probably still leads to a conflation of nonbinary and transsexual identities.","2021-06-04 14:58 +0000","1069.0","60.0","0.05612722170252572","0.0","2.0","3.0","24.0","0.0","0.0","30.0","0.0","0","0","0","0","0","1","1","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400822907257999360","https://twitter.com/LisaDeBruine/status/1400822907257999360","@GustafRydevik It's a Brazilian site, so I see how that could happen. Translation is tricky!","2021-06-04 14:33 +0000","945.0","19.0","0.020105820105820106","0.0","1.0","6.0","8.0","0.0","0.0","4.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400816140805410822","https://twitter.com/LisaDeBruine/status/1400816140805410822","I'm registering for a grant system to submit an application and this is definitely not OK. https://t.co/nnbPgU7dUP","2021-06-04 14:06 +0000","15378.0","4148.0","0.2697359864741839","3.0","8.0","94.0","218.0","9.0","0.0","1413.0","0.0","0","0","0","0","0","2403","2403","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400743121445605378","https://twitter.com/LisaDeBruine/status/1400743121445605378","@Richie_Research @RussellGarwood @PSU_sexuality Congrats! https://t.co/2eVxOkq0Ez","2021-06-04 09:15 +0000","473.0","10.0","0.021141649048625793","0.0","0.0","1.0","1.0","0.0","0.0","4.0","0.0","0","0","0","0","0","92","4","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400741169110388738","https://twitter.com/LisaDeBruine/status/1400741169110388738","@cantabile @DrGBuckingham You’re safe. Americans call these “fanny packs”, but fanny does *not* mean bum here. (It was my grandmother’s first name!)","2021-06-04 09:08 +0000","462.0","20.0","0.04329004329004329","0.0","3.0","2.0","2.0","0.0","0.0","13.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400736018320531458","https://twitter.com/LisaDeBruine/status/1400736018320531458","@cantabile What do you call these? https://t.co/EyEAa0IMdp","2021-06-04 08:47 +0000","1031.0","57.0","0.055286129970902036","0.0","2.0","2.0","4.0","0.0","0.0","33.0","0.0","0","0","0","0","0","16","16","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400423989244215298","https://twitter.com/LisaDeBruine/status/1400423989244215298","⬆️All are welcome, not just psych PhDs.","2021-06-03 12:07 +0000","1907.0","15.0","0.007865757734661772","1.0","0.0","4.0","3.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400421414923079683","https://twitter.com/LisaDeBruine/status/1400421414923079683","Sign up for this free workshop (tomorrow!) if you want to learn how to quickly simulate data with factorial designs and run power simulations. We’ll be working on this exercise https://t.co/xru31f0Grj https://t.co/o6pXwFp0Un","2021-06-03 11:57 +0000","11492.0","213.0","0.018534632788026452","16.0","2.0","23.0","37.0","64.0","0.0","71.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400150903466905602","https://twitter.com/LisaDeBruine/status/1400150903466905602","@cantabile @LDBraunholtz @yoyehudi @DrVeronikaCH @lakens @AidanBudd @MalvikaSharan @metanutter @MetaEvidence @NikiRust @DrGBuckingham @JamesSteeleII @kirstie_j Now we just have to book a date for you to come up to Glasgow so @emilynordmann and I can take you out to the Glaswegian pubs!","2021-06-02 18:02 +0000","682.0","8.0","0.011730205278592375","0.0","1.0","4.0","3.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400109588062650368","https://twitter.com/LisaDeBruine/status/1400109588062650368","@GKountourides I think that’s just my Twitter banner, but I also love it as an icon!","2021-06-02 15:18 +0000","91.0","2.0","0.02197802197802198","0.0","0.0","1.0","1.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400085644710494212","https://twitter.com/LisaDeBruine/status/1400085644710494212","The @UKDataService has a really cool qualitative data search service that I so wish existed for quant data.

https://t.co/U3YP40o4GR","2021-06-02 13:43 +0000","2626.0","64.0","0.024371667936024372","2.0","0.0","18.0","18.0","19.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1400069138173792268","https://twitter.com/LisaDeBruine/status/1400069138173792268","This is in 20 minutes. Please do come along if you want to learn a bit more about the UK data Service and doing secondary data analyses on #qualitative data. https://t.co/cEBDhFw3mm","2021-06-02 12:37 +0000","3041.0","36.0","0.01183821111476488","1.0","2.0","6.0","15.0","1.0","0.0","11.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399984807958941700","https://twitter.com/LisaDeBruine/status/1399984807958941700","@deevybee @sTeamTraen As someone who accidentally weeded a nettle with their bare hands this weekend, another analogy is letting nettles grow in a community garden because you either believe everyone already knows how to avoid them or nobody actually uses that garden.","2021-06-02 07:02 +0000","551.0","11.0","0.019963702359346643","0.0","1.0","1.0","7.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399828332284350467","https://twitter.com/LisaDeBruine/status/1399828332284350467","We’re looking forward to the @UofGPsychology #MethodsMetaScience talk Wed, June 2nd at 14:00 BST by @mahaake of the @UKDataService on (Re)Using Qualitative Data: Getting the Most Out of Data

All are welcome. Check https://t.co/A2KZYqiv9b for the zoom link on the day.","2021-06-01 20:40 +0000","11597.0","168.0","0.014486505130637234","14.0","0.0","21.0","36.0","46.0","2.0","49.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399826547125768196","https://twitter.com/LisaDeBruine/status/1399826547125768196","I see the article has now “updated some of the language to better reflect our values of inclusivity”, but the original text is still there and crossed out. 

https://t.co/a4BKL4kSBD","2021-06-01 20:33 +0000","2121.0","57.0","0.026874115983026876","1.0","0.0","2.0","5.0","29.0","0.0","20.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399825028452077576","https://twitter.com/LisaDeBruine/status/1399825028452077576","OMG the pioneer/settler/livestock part is 🤢 in so many ways (how could someone not see how racist that analogy is?) but also such an anti-team science stance to say that only “pioneers” can be outstanding and it doesn’t really matter if the “livestock” are even there at all. https://t.co/UA6x0F422j","2021-06-01 20:27 +0000","5663.0","144.0","0.025428218258873387","3.0","5.0","22.0","31.0","4.0","0.0","79.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399749022374674435","https://twitter.com/LisaDeBruine/status/1399749022374674435","@emilynordmann You know I can do that :)","2021-06-01 15:25 +0000","175.0","2.0","0.011428571428571429","0.0","0.0","0.0","1.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399734492537962498","https://twitter.com/LisaDeBruine/status/1399734492537962498","We’ll need to make a rainbow hex logo if we do an LGBTQIA+ R training, @emilynordmann
🖤🤎❤️🧡💛💚💙💜 https://t.co/Prs4GpiIsS","2021-06-01 14:28 +0000","3254.0","51.0","0.01567301782421635","0.0","2.0","12.0","30.0","0.0","0.0","7.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399727005059387400","https://twitter.com/LisaDeBruine/status/1399727005059387400","@camjpatrick @DavidKButlerUoA @d_olivaw @cantabile I love this analogy! Sometimes it’s hard to know when to teach a method that’s easier to understand/implement if you’re doing the thing infrequently, versus a method that is harder but way more efficient if you need to do the thing 100 times.","2021-06-01 13:58 +0000","78.0","8.0","0.10256410256410256","0.0","1.0","3.0","1.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399719841318191110","https://twitter.com/LisaDeBruine/status/1399719841318191110","@AdamCSchembri https://t.co/IXma7mPUrp","2021-06-01 13:29 +0000","386.0","16.0","0.04145077720207254","0.0","1.0","2.0","5.0","6.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399718693937029126","https://twitter.com/LisaDeBruine/status/1399718693937029126","@patilindrajeets Congrats! Do you have a formal engineering background, or are your coding skills self-taught?","2021-06-01 13:25 +0000","471.0","15.0","0.03184713375796178","0.0","1.0","1.0","12.0","0.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399676898670678017","https://twitter.com/LisaDeBruine/status/1399676898670678017","Happy #Pride month! https://t.co/UPRu3oVb88","2021-06-01 10:39 +0000","9695.0","235.0","0.024239298607529654","10.0","1.0","43.0","67.0","1.0","1.0","47.0","0.0","0","0","0","0","0","1434","65","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399658903194030080","https://twitter.com/LisaDeBruine/status/1399658903194030080","@bearloga @hisotalus Brilliant! Now I need to find a chapter to fit this meme into on https://t.co/abC58l0UZk","2021-06-01 09:27 +0000","2084.0","19.0","0.009117082533589251","0.0","0.0","3.0","5.0","10.0","0.0","1.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399657395782029312","https://twitter.com/LisaDeBruine/status/1399657395782029312","@HenrikSingmann What I like about lists of lists is that it makes it really easy to write your markdown like:

... the effect of angle 
(F = `r b$angle$F`, 
p = `r b$angle$p.value`) ...

Instead of having a hidden chunk prepping a bunch of one-off objects or having too-long inline R.","2021-06-01 09:21 +0000","81.0","2.0","0.024691358024691357","0.0","0.0","0.0","0.0","0.0","0.0","2.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399656271691792388","https://twitter.com/LisaDeBruine/status/1399656271691792388","@HenrikSingmann I teach students to never assume the order of things (safe for this example but not at all for other things and they aren’t experienced enough to tell the difference), so I’ll end up teaching something like:

filter(b, Effect == ""angle:noise"") %&gt;%
  pull(p.value)","2021-06-01 09:17 +0000","101.0","1.0","0.009900990099009901","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399646109451042817","https://twitter.com/LisaDeBruine/status/1399646109451042817","@HenrikSingmann I totally feel your pain here at making choices between consistency and sensibility :)

FYI, afex inspired a fair amount of the terminology in faux to make it easier to see the links between data simulation and analysis (in aov_ez) and I’m grateful your terms are sensible.","2021-06-01 08:36 +0000","62.0","4.0","0.06451612903225806","0.0","0.0","1.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399645415822303233","https://twitter.com/LisaDeBruine/status/1399645415822303233","@HenrikSingmann I guess it gives me a chance to talk about data structures with students and they can further practice their data wrangling to filter for the relevant row and pull the relevant column.

But I might write myself a helper function to return an object like that :)","2021-06-01 08:34 +0000","81.0","1.0","0.012345679012345678","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399644810336604170","https://twitter.com/LisaDeBruine/status/1399644810336604170","@HenrikSingmann It’s still a little tricky to pull out a specific value from nice(). A useful returned object for error-free access to specific values would be a list of values for each term. So you could access, say, the p-value from the A:B interaction term like this:

object$`A:B`$p.value","2021-06-01 08:31 +0000","48.0","1.0","0.020833333333333332","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399642773410697217","https://twitter.com/LisaDeBruine/status/1399642773410697217","@HenrikSingmann I didn’t know about nice(), thanks! I mainly now teach it in the context of power simulation, where they need to get the values in a data frame and process p-values as numbers, so I can’t have “p&lt;.001” in there (e.g., https://t.co/xru31f0Grj), but I’ll use that elsewhere.","2021-06-01 08:23 +0000","65.0","6.0","0.09230769230769231","0.0","1.0","2.0","0.0","0.0","0.0","3.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399637268030177280","https://twitter.com/LisaDeBruine/status/1399637268030177280","@HenrikSingmann My only wish is that it was a little more straightforward to show students how to get individual numbers out of the returned object to include in a reproducible write-up (like inline R in an Rmd). Currently, it encourages the bad habit of manually copying values.","2021-06-01 08:01 +0000","82.0","1.0","0.012195121951219513","0.0","1.0","0.0","0.0","0.0","0.0","0.0","0.0","0","0","0","0","0","0","0","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
"1399636261590216704","https://twitter.com/LisaDeBruine/status/1399636261590216704","@HenrikSingmann @CookieSci @bolkerb Henrik (and Jake &amp; Ben :), thank you so much for afex. It’s a great package for students, people transitioning from SPSS, and those who want to replicate ANOVAs from papers. https://t.co/GnghLEwHaR","2021-06-01 07:57 +0000","145.0","9.0","0.06206896551724138","0.0","1.0","3.0","1.0","0.0","0.0","2.0","0.0","0","0","0","0","0","33","2","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-","-"
